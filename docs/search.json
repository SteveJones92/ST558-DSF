[
  {
    "objectID": "homeworks/Homework_1.html",
    "href": "homeworks/Homework_1.html",
    "title": "Homework 1",
    "section": "",
    "text": "What do you think being a data scientist is about?\nA data scientist is someone who focuses on the process of integrating computers with statistics and business needs. They have a specialization of computing software to be able to gain insights from data, many times in an automated fashion for use with software.\n\n\nWhat differences/similarities do you see between data scientists and statisticians?\nI view it as starting on the same path and diverging at some point. The root is in statistics, but a statistician will continue with more of the rigor of the field directly, whereas a data scientist will begin to branch off more into the software/development process and application side of things.\nSimilarities:\n\nFoundational Knowledge\nTool Use\n\nDifferences:\n\nSpecialized Knowledge\nDevelopment Process\n\n\n\nHow do you view yourself in relation to these two areas?\nI am much closer to a data scientist. I have exposure to statistics, but as portions of CSC courses. I have had many courses on directly attributed data science topics and I work in software.\n\n\nSetting y variable using a column of the iris dataset and density function\n\ny &lt;- density(iris$Petal.Width)\n\n\n\n\nChecking the class, type, and structure of y\n\nclass(y)\n\n[1] \"density\"\n\ntypeof(y)\n\n[1] \"list\"\n\nstr(y)\n\nList of 8\n $ x         : num [1:512] -0.656 -0.648 -0.64 -0.633 -0.625 ...\n $ y         : num [1:512] 0.00161 0.00178 0.00197 0.00217 0.00239 ...\n $ bw        : num 0.252\n $ n         : int 150\n $ old.coords: logi FALSE\n $ call      : language density.default(x = iris$Petal.Width)\n $ data.name : chr \"iris$Petal.Width\"\n $ has.na    : logi FALSE\n - attr(*, \"class\")= chr \"density\"\n\n\n\n\n\nPlotting y, with code hidden with echo=FALSE"
  },
  {
    "objectID": "homeworks/Homework_3.html#load-data-from-data-folder",
    "href": "homeworks/Homework_3.html#load-data-from-data-folder",
    "title": "Homework 3",
    "section": "Load data from data folder",
    "text": "Load data from data folder\n\nload(\"../data/hw3/hw2_list.rda\")"
  },
  {
    "objectID": "homeworks/Homework_3.html#task-1-control-flow-practice",
    "href": "homeworks/Homework_3.html#task-1-control-flow-practice",
    "title": "Homework 3",
    "section": "Task 1: Control Flow Practice",
    "text": "Task 1: Control Flow Practice\n\nCreate the status column in both.\n\nbp_list$treatment$status &lt;- character(nrow(bp_list$treatment))\nbp_list$placebo$status &lt;- character(nrow(bp_list$placebo))\n\n\n\nFill the treatment with appropriate strings for status\n\nfor (i in 1:nrow(bp_list$treatment)) {\n  val &lt;- bp_list$treatment[i, \"post_bp\"]\n  bp_str &lt;- \"\"\n  if (val &lt;= 120) {\n    bp_str &lt;- \"optimal\"\n  } else if (val &lt;= 130) {\n    bp_str &lt;- \"borderline\"\n  } else {\n    bp_str &lt;- \"high\"\n  }\n  bp_list$treatment[i, \"status\"] &lt;- bp_str\n}\nbp_list$treatment$status\n\n [1] \"borderline\" \"high\"       \"high\"       \"borderline\" \"optimal\"   \n [6] \"borderline\" \"borderline\" \"borderline\" \"borderline\" \"borderline\"\n[11] \"high\"       \"high\"       \"optimal\"    \"optimal\"    \"borderline\"\n[16] \"optimal\"    \"borderline\" \"optimal\"    \"high\"       \"optimal\"   \n\n\n\n\nFill the placebo with the appropriate string for status\n\nbp_list$placebo$status &lt;- ifelse(bp_list$placebo$post_bp &lt;= 120, \"optimal\", ifelse(bp_list$placebo$post_bp &lt;= 130, \"borderline\", \"high\"))\nbp_list$placebo$status\n\n [1] \"optimal\"    \"high\"       \"borderline\" \"borderline\" \"high\"      \n [6] \"high\"       \"high\"       \"high\"       \"optimal\"    \"borderline\""
  },
  {
    "objectID": "homeworks/Homework_3.html#task-2-function-writing",
    "href": "homeworks/Homework_3.html#task-2-function-writing",
    "title": "Homework 3",
    "section": "Task 2: Function Writing",
    "text": "Task 2: Function Writing\n\nBuild a useful function for the previous usage\n\nmy_func &lt;- function(lst, summary_func=\"mean\") {\n  # lst needs to be a list with 2 dataframes\n  if (!all(is.list(lst), length(lst) == 2, all(sapply(lst, is.data.frame)))) {\n    stop(\"Not a list of 2 data frames\")\n  }\n  # summary_func needs to be one of a set of summary functions (var, sd, min, max, mean)\n  summary_funcs &lt;- c(\"var\", \"sd\", \"min\", \"max\", \"mean\")\n  if (!(summary_func %in% summary_funcs)) {\n    stop(\"Not a function\")\n  }\n  summary_function &lt;- get(summary_func)\n  \n  # lists need to contain pre, post, and diff columns\n  cols &lt;- c(\"pre_bp\", \"post_bp\", \"diff_bp\")\n  if (!all(sapply(lst, function(df) all(cols %in% colnames(df))))) {\n    stop(\"Dataframes don't have the required columns of pre_bp, post_bp, and diff_bp\")\n  }\n  \n  return(lapply(lst, function(df) {\n    result &lt;-sapply(df[cols], summary_function)\n    names(result) &lt;- paste(names(result), summary_func, sep=\"_\")\n    return(result)\n  }))\n}\n\n\n\nApply the function to bp_list with default param, and the other summary funcs\n\nprint(\"default: mean\")\n\n[1] \"default: mean\"\n\nmy_func(bp_list)\n\n$treatment\n pre_bp_mean post_bp_mean diff_bp_mean \n      131.60       125.95         5.65 \n\n$placebo\n pre_bp_mean post_bp_mean diff_bp_mean \n       131.9        128.9          3.0 \n\nfor (summary_func in c(\"var\", \"sd\", \"min\", \"max\")) {\n  print(summary_func)\n  print(my_func(bp_list, summary_func))\n}\n\n[1] \"var\"\n$treatment\n pre_bp_var post_bp_var diff_bp_var \n   75.72632    78.99737   117.81842 \n\n$placebo\n pre_bp_var post_bp_var diff_bp_var \n   149.8778    124.9889    341.3333 \n\n[1] \"sd\"\n$treatment\n pre_bp_sd post_bp_sd diff_bp_sd \n  8.702087   8.888046  10.854419 \n\n$placebo\n pre_bp_sd post_bp_sd diff_bp_sd \n  12.24246   11.17984   18.47521 \n\n[1] \"min\"\n$treatment\n pre_bp_min post_bp_min diff_bp_min \n        115         114         -24 \n\n$placebo\n pre_bp_min post_bp_min diff_bp_min \n        114         105         -21 \n\n[1] \"max\"\n$treatment\n pre_bp_max post_bp_max diff_bp_max \n        151         146          21 \n\n$placebo\n pre_bp_max post_bp_max diff_bp_max \n        152         143          33"
  },
  {
    "objectID": "homeworks/Homework_6.html#task-1-conceptual-questions",
    "href": "homeworks/Homework_6.html#task-1-conceptual-questions",
    "title": "Homework 6",
    "section": "Task 1: Conceptual Questions",
    "text": "Task 1: Conceptual Questions\n\nWhat is the purpose of the lapply() function? What is the equivalent purrr function?\n\n\nlapply stands for list apply. It is used to apply a function to each list item, similar to having a for loop and running the function over each element in a list. The equivalent purrr function is map.\n\n\nSuppose we have a list called my_list. Each element of the list is a numeric data frame (all columns are numeric). We want to use lapply() to run the code cor(numeric_matrix, method = \"kendall\") on each element of the list. Write code to do this below! (I’m really trying to ask you how you specify method = \"kendall\" when calling lapply())\n\n\nlapply(my_list, cor, method = “kendall”)\n\n\nWhat are two advantages of using purrr functions instead of the BaseR apply family?\n\n\npurrr functions allow shorthand notation and are more consistent in their input/output.\n\n\nWhat is a side-effect function?\n\n\nA side-effect function is one that performs an operation, some thing, but isn’t really about manipulating data. A good example is simply printing something out. It wouldn’t return data, but it uses the data. This is not very useful for chaining.\n\n\nWhy can you name a variable sd in a function and not cause any issues with the sd function?\n\n\nThe scope inside the function is local to that function."
  },
  {
    "objectID": "homeworks/Homework_6.html#task-2-writing-r-functions",
    "href": "homeworks/Homework_6.html#task-2-writing-r-functions",
    "title": "Homework 6",
    "section": "Task 2: Writing R Functions",
    "text": "Task 2: Writing R Functions\n\nNote* - Provided code will be used for multiple steps of Task 2\n\n\n# provided code for hw6 Task 2\nset.seed(10)\nn &lt;- 100\nx &lt;- runif(n)\nresp &lt;- 3 + 10 * x + rnorm(n)\npred &lt;- predict(lm(resp ~ x), data.frame(x))\n\n\n# show results of provided code\nn\nhead(resp, 5)\nhead(pred, 5)\n\n[1] 100\n[1]  7.674144  5.733128  8.637031 12.068788  4.357179\n        1         2         3         4         5 \n 8.148104  6.053163  7.307135 10.085585  3.739836 \n\n\n\n# copy resp from provided code and put 2 NA_real_ values into the vector\nrand_idx &lt;- sample(seq_along(resp), 2)\nresp_with_na &lt;- resp\nresp_with_na[rand_idx] &lt;- NA_real_\nresp\nresp_with_na\n\n  [1]  7.674144  5.733128  8.637031 12.068788  4.357179  6.040709  4.843093\n  [8]  6.255948  8.512399  7.587703  8.278962  8.221201  3.304767  9.299369\n [15]  7.646876  8.504220  4.254724  5.160568  7.550652 10.115022 12.028134\n [22]  7.723097  9.702653  6.337183  5.568563 11.239175  9.903050  4.965503\n [29]  9.656077  8.081564  8.948798  3.708220  5.410925 12.714925  7.666618\n [36] 10.636295 11.886290 14.767056  8.670500  7.931076  5.338484  5.097557\n [43]  3.213884 11.444994  6.093762  3.192188  1.563749  8.753929  4.177170\n [50] 12.242498  5.781476 12.783701  4.418721  8.442989  4.282396  9.395394\n [57]  8.255719  6.016290  8.026494  9.180810  2.038727  5.273544  7.225220\n [64]  6.654107 12.260485 10.688362  9.773488  8.216967  5.093565  6.142304\n [71]  3.274337  8.547150  9.381826  7.061813  4.016495  7.543794  6.976389\n [78] 11.550401  5.209433  3.872522 13.043037  8.277356  3.231859  8.553664\n [85]  4.576422  2.213665 11.475262  6.469006  5.333390  5.656304  6.209727\n [92]  8.908905  6.956097  9.642321  7.188749 12.413663  6.020730  8.507994\n [99] 11.776177  3.387353\n  [1]  7.674144  5.733128  8.637031 12.068788  4.357179  6.040709  4.843093\n  [8]  6.255948  8.512399  7.587703  8.278962        NA  3.304767        NA\n [15]  7.646876  8.504220  4.254724  5.160568  7.550652 10.115022 12.028134\n [22]  7.723097  9.702653  6.337183  5.568563 11.239175  9.903050  4.965503\n [29]  9.656077  8.081564  8.948798  3.708220  5.410925 12.714925  7.666618\n [36] 10.636295 11.886290 14.767056  8.670500  7.931076  5.338484  5.097557\n [43]  3.213884 11.444994  6.093762  3.192188  1.563749  8.753929  4.177170\n [50] 12.242498  5.781476 12.783701  4.418721  8.442989  4.282396  9.395394\n [57]  8.255719  6.016290  8.026494  9.180810  2.038727  5.273544  7.225220\n [64]  6.654107 12.260485 10.688362  9.773488  8.216967  5.093565  6.142304\n [71]  3.274337  8.547150  9.381826  7.061813  4.016495  7.543794  6.976389\n [78] 11.550401  5.209433  3.872522 13.043037  8.277356  3.231859  8.553664\n [85]  4.576422  2.213665 11.475262  6.469006  5.333390  5.656304  6.209727\n [92]  8.908905  6.956097  9.642321  7.188749 12.413663  6.020730  8.507994\n [99] 11.776177  3.387353\n\n\n\n\nTASKS\n\nRMSE function and simple test usage.\n\n\ngetRMSE\n\nfunction(responses, predictions, ...) {\n  # takes in a vector of responses and predictions and returns RMSE\n  if (!is.vector(responses) | !is.vector(predictions)) {\n    stop(\"Both inputs must be vectors\")\n  }\n  RMSE &lt;- sqrt(mean((responses - predictions)^2, ...))\n  return (RMSE)\n}\n\n\n\nvec1 &lt;- c(1, 2, 3, 4, 5)\nvec2 &lt;- c(2, 3, 4, 5, 6)\nvec1_with_na &lt;- c(1, 2, 3, 4, NA)\nvec2_with_na &lt;- c(2, 3, NA, 5, 6)\ngetRMSE(vec1, vec2)\ngetRMSE(vec1_with_na, vec2_with_na, na.rm=TRUE)\n\n[1] 1\n[1] 1\n\n\n\nRun provided code (already prepared) and test RMSE on resp and resp with NA’s.\n\n\ngetRMSE(resp, pred)\ngetRMSE(resp_with_na, pred)\ngetRMSE(resp_with_na, pred, na.rm=TRUE)\n\n[1] 0.9581677\n[1] NA\n[1] 0.9659906\n\n\n\nMAE function and simple test usage (reuse prior).\n\n\ngetMAE\n\nfunction(responses, predictions, ...) {\n  # takes in a vector of responses and predictions and returns MAE\n  if (!is.vector(responses) | !is.vector(predictions)) {\n    stop(\"Both inputs must be vectors\")\n  }\n\n  MAE &lt;- mean(abs(responses - predictions), ...)\n  return (MAE)\n}\n\n\n\ngetMAE(vec1, vec2)\ngetMAE(vec1_with_na, vec2_with_na, na.rm=TRUE)\n\n[1] 1\n[1] 1\n\n\n\nRun the provided code (reuse already prepared) and test MAE on resp and resp with NA’s.\n\n\ngetMAE(resp, pred)\ngetMAE(resp_with_na, pred)\ngetMAE(resp_with_na, pred, na.rm=TRUE)\n\n[1] 0.8155776\n[1] NA\n[1] 0.8242225\n\n\n\nWrapper function for either/both of MAE and RMSE and extra validation.\n\n\nget_metrics\n\nfunction(responses, predictions, metrics=\"rmse,mae\", ...) {\n  # takes in a numeric atomic vector of responses and predictions and returns a list of metrics (RMSE, MAE) as optionsgit\n  if (!all(\n    is.numeric(responses), is.numeric(predictions),\n    is.atomic(responses), is.atomic(predictions),\n    is.vector(responses), is.vector(predictions)\n  )) {\n    stop(\"Both inputs must be atomic numeric vectors\")\n  }\n\n  ret &lt;- list()\n  # RMSE\n  if (grepl(\"rmse\", metrics, ignore.case=TRUE)) {\n    RMSE &lt;- getRMSE(responses, predictions, ...)\n    ret$RMSE &lt;- RMSE\n  }\n  # MAE\n  if (grepl(\"mae\", metrics, ignore.case=TRUE)) {\n    MAE &lt;- getMAE(responses, predictions, ...)\n    ret$MAE &lt;- MAE\n  }\n\n  return (ret)\n}\n\n\n\nRun the provided code (reuse already prepared) and test wrapper on resp, resp with NA’s, various choice metrics, and invalid input.\n\n\n# both\nget_metrics(resp, pred)\nget_metrics(resp_with_na, pred)\nget_metrics(resp_with_na, pred, na.rm=TRUE)\n\n$RMSE\n[1] 0.9581677\n\n$MAE\n[1] 0.8155776\n\n$RMSE\n[1] NA\n\n$MAE\n[1] NA\n\n$RMSE\n[1] 0.9659906\n\n$MAE\n[1] 0.8242225\n\n\n\n# RMSE\nget_metrics(resp, pred, \"rmse\")\nget_metrics(resp_with_na, pred, \"rmse\")\nget_metrics(resp_with_na, pred, \"rmse\", na.rm=TRUE)\n\n$RMSE\n[1] 0.9581677\n\n$RMSE\n[1] NA\n\n$RMSE\n[1] 0.9659906\n\n\n\n# MAE\nget_metrics(resp, pred, \"mae\")\nget_metrics(resp_with_na, pred, \"mae\")\nget_metrics(resp_with_na, pred, \"mae\", na.rm=TRUE)\n\n$MAE\n[1] 0.8155776\n\n$MAE\n[1] NA\n\n$MAE\n[1] 0.8242225\n\n\n\n# invalid input, giving dataframe\ndf &lt;- data.frame(pred, resp)\n# throws stop error, need try-to avoid error in render\ntry(get_metrics(resp, df))\ntry(get_metrics(df, pred))\n\nError in get_metrics(resp, df) : \n  Both inputs must be atomic numeric vectors\nError in get_metrics(df, pred) : \n  Both inputs must be atomic numeric vectors"
  },
  {
    "objectID": "homeworks/Homework_6.html#task-3-querying-an-api-and-a-tidy-style-function",
    "href": "homeworks/Homework_6.html#task-3-querying-an-api-and-a-tidy-style-function",
    "title": "Homework 6",
    "section": "Task 3: Querying an API and a Tidy-Style Function",
    "text": "Task 3: Querying an API and a Tidy-Style Function\n\nNote: API KEY inactive\n\nStep 1-3: Create the GET request to the news API, get articles from the response, and build make a function for the operation of searching for news.\n\n# function created, with defaults as the interesting topic\nget_news_api_data\n\nfunction(api_key, subject=\"esports\", time_period=\"2024-10-01\") {\n  BASE_URL &lt;- glue(\"https://newsapi.org/v2/everything?q={subject}&from={time_period}&sortBy=publishedAt&apiKey={api_key}\")\n\n  data &lt;- httr::GET(BASE_URL) |&gt;\n    content(\"text\") |&gt;\n    fromJSON(flatten = TRUE, simplifyDataFrame = TRUE) |&gt;\n    pluck(\"articles\")\n\n    return (data)\n}\n\n\n\n# resulting data, using default of esports articles\ndata &lt;- get_news_api_data(API_KEY)\n# print the top 5 titles\nhead(data$title, 5)\n\nNULL\n\n\n\nUse the function twice to grab some data. Summarize the source field.\n\n\ncsc_data &lt;- get_news_api_data(API_KEY, subject=\"computer%20science\")\ndata_science_data &lt;- get_news_api_data(API_KEY, subject=\"data%20science\")\n\n# csc\ntable(csc_data$source.name)\n\n&lt; table of extent 0 &gt;\n\n# data science\ntable(data_science_data$source.name)\n\n&lt; table of extent 0 &gt;\n\n\n\nConvert publishedAt columns to a date column. Sort by this column. Then create a pub_diff column that is a difference of the 2.\n\n\n# function made for doing this, also creates a better print string column for the 2\nget_dates_publish_diff\n\nfunction(data) {\n  data_with_dates_and_diff &lt;- data |&gt;\n    mutate(publishedAt = ymd_hms(publishedAt, tz=\"UTC\")) |&gt;\n    arrange(desc(publishedAt)) |&gt;\n    mutate(pub_diff = lag(publishedAt, 1) - publishedAt) |&gt;\n    mutate(publishedAt_str = as_datetime(publishedAt, tz=\"EST\"), pub_diff_str = as.character(as_hms(pub_diff)))\n\n  return (data_with_dates_and_diff)\n}\n\n\n\n# csc_data_dates &lt;- get_dates_publish_diff(csc_data)\n# ds_data_dates &lt;- get_dates_publish_diff(data_science_data)\n\n# csc_data_dates |&gt;\n#   select(source.name, publishedAt_str, pub_diff_str) |&gt;\n#   head(10)\n#\n# ds_data_dates |&gt;\n#   select(source.name, publishedAt_str, pub_diff_str) |&gt;\n#   head(10)\n\n\nInteresting, computer science results are less frequent than data science.\n\n\nSubset the variables for publishedAt and pub_diff and find the mean/med/sd of the columns using map.\n\n\n# map(csc_data_dates |&gt; select(publishedAt, pub_diff), \\(x) list(mean=mean(x, na.rm=TRUE), median=median(x, na.rm=TRUE), sd=sd(x, na.rm=TRUE)))\n# map(ds_data_dates |&gt; select(publishedAt, pub_diff), \\(x) list(mean=mean(x, na.rm=TRUE), median=median(x, na.rm=TRUE), sd=sd(x, na.rm=TRUE)))\n\n\nFrom looking at the results of the summary statistics, we see what generally looked true from the first 10 values at a glance. Data science must be more popular than computer science."
  },
  {
    "objectID": "homeworks/Homework_5.html#task-1-read-in-the-data-and-modify",
    "href": "homeworks/Homework_5.html#task-1-read-in-the-data-and-modify",
    "title": "Homework 5",
    "section": "Task 1: Read in the Data and Modify",
    "text": "Task 1: Read in the Data and Modify\n\nReading in data\n\nModify the provided code to read in the data and combine.\nRead in and combine using tidyverse and inner_join().\n\n\nlibrary(\"tidyverse\")\n\nread_method_1 &lt;- function(file1, file2) {\n  d1 &lt;- read.table(file1, sep=\";\", header=TRUE)\n  d2 &lt;- read.table(file2, sep=\";\", header=TRUE)\n\n  d3 &lt;- merge(d1,d2,by=c(\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"))\n  return (d3)\n}\n\nread_method_2 &lt;- function(file1, file2) {\n  d1 &lt;- read_delim(file1, delim=\";\", show_col_types = FALSE)\n  d2 &lt;- read_delim(file2, delim=\";\", show_col_types = FALSE)\n\n  join_on_columns &lt;- names(d1)[!names(d1) %in% c(\"G1\", \"G2\", \"G3\", \"paid\", \"absences\")]\n  d3 &lt;- inner_join(d1, d2, join_on_columns, suffix = c(\"_math\", \"_lang\"))\n  return (list(d1=d1, d2=d2, combined=d3))\n}\n\nModified code for reading in.\n\nstr(read_method_1(\"../data/hw5/student-mat.csv\", \"../data/hw5/student-por.csv\"))\n\n'data.frame':   382 obs. of  53 variables:\n $ school      : chr  \"GP\" \"GP\" \"GP\" \"GP\" ...\n $ sex         : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ age         : int  15 15 15 15 15 15 15 15 15 15 ...\n $ address     : chr  \"R\" \"R\" \"R\" \"R\" ...\n $ famsize     : chr  \"GT3\" \"GT3\" \"GT3\" \"GT3\" ...\n $ Pstatus     : chr  \"T\" \"T\" \"T\" \"T\" ...\n $ Medu        : int  1 1 2 2 3 3 3 2 3 3 ...\n $ Fedu        : int  1 1 2 4 3 4 4 2 1 3 ...\n $ Mjob        : chr  \"at_home\" \"other\" \"at_home\" \"services\" ...\n $ Fjob        : chr  \"other\" \"other\" \"other\" \"health\" ...\n $ reason      : chr  \"home\" \"reputation\" \"reputation\" \"course\" ...\n $ nursery     : chr  \"yes\" \"no\" \"yes\" \"yes\" ...\n $ internet    : chr  \"yes\" \"yes\" \"no\" \"yes\" ...\n $ guardian.x  : chr  \"mother\" \"mother\" \"mother\" \"mother\" ...\n $ traveltime.x: int  2 1 1 1 2 1 2 2 2 1 ...\n $ studytime.x : int  4 2 1 3 3 3 3 2 4 4 ...\n $ failures.x  : int  1 2 0 0 2 0 2 0 0 0 ...\n $ schoolsup.x : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ famsup.x    : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ paid.x      : chr  \"yes\" \"no\" \"yes\" \"yes\" ...\n $ activities.x: chr  \"yes\" \"no\" \"yes\" \"yes\" ...\n $ higher.x    : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ romantic.x  : chr  \"no\" \"yes\" \"no\" \"no\" ...\n $ famrel.x    : int  3 3 4 4 4 4 4 4 4 4 ...\n $ freetime.x  : int  1 3 3 3 2 3 2 1 4 3 ...\n $ goout.x     : int  2 4 1 2 1 2 2 3 2 3 ...\n $ Dalc.x      : int  1 2 1 1 2 1 2 1 2 1 ...\n $ Walc.x      : int  1 4 1 1 3 1 2 3 3 1 ...\n $ health.x    : int  1 5 2 5 3 5 5 4 3 4 ...\n $ absences.x  : int  2 2 8 2 8 2 0 2 12 10 ...\n $ G1.x        : int  7 8 14 10 10 12 12 8 16 10 ...\n $ G2.x        : int  10 6 13 9 10 12 0 9 16 11 ...\n $ G3.x        : int  10 5 13 8 10 11 0 8 16 11 ...\n $ guardian.y  : chr  \"mother\" \"mother\" \"mother\" \"mother\" ...\n $ traveltime.y: int  2 1 1 1 2 1 2 2 2 1 ...\n $ studytime.y : int  4 2 1 3 3 3 3 2 4 4 ...\n $ failures.y  : int  0 0 0 0 0 0 0 0 0 0 ...\n $ schoolsup.y : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ famsup.y    : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ paid.y      : chr  \"yes\" \"no\" \"no\" \"no\" ...\n $ activities.y: chr  \"yes\" \"no\" \"yes\" \"yes\" ...\n $ higher.y    : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ romantic.y  : chr  \"no\" \"yes\" \"no\" \"no\" ...\n $ famrel.y    : int  3 3 4 4 4 4 4 4 4 4 ...\n $ freetime.y  : int  1 3 3 3 2 3 2 1 4 3 ...\n $ goout.y     : int  2 4 1 2 1 2 2 3 2 3 ...\n $ Dalc.y      : int  1 2 1 1 2 1 2 1 2 1 ...\n $ Walc.y      : int  1 4 1 1 3 1 2 3 3 1 ...\n $ health.y    : int  1 5 2 5 3 5 5 4 3 4 ...\n $ absences.y  : int  4 2 8 2 2 2 0 0 6 10 ...\n $ G1.y        : int  13 13 14 10 13 11 10 11 15 10 ...\n $ G2.y        : int  13 11 13 11 13 12 11 10 15 10 ...\n $ G3.y        : int  13 11 12 10 13 12 12 11 15 10 ...\n\n\nUsing inner_join() with all variables other than G1, G2, G3, paid, and absences.\n\ndata &lt;- read_method_2(\"../data/hw5/student-mat.csv\", \"../data/hw5/student-por.csv\")\nstr(data$combined, give.attr = FALSE)\n\nspc_tbl_ [320 × 38] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ school       : chr [1:320] \"GP\" \"GP\" \"GP\" \"GP\" ...\n $ sex          : chr [1:320] \"F\" \"F\" \"F\" \"F\" ...\n $ age          : num [1:320] 18 17 15 16 16 16 17 15 15 15 ...\n $ address      : chr [1:320] \"U\" \"U\" \"U\" \"U\" ...\n $ famsize      : chr [1:320] \"GT3\" \"GT3\" \"GT3\" \"GT3\" ...\n $ Pstatus      : chr [1:320] \"A\" \"T\" \"T\" \"T\" ...\n $ Medu         : num [1:320] 4 1 4 3 4 2 4 3 3 4 ...\n $ Fedu         : num [1:320] 4 1 2 3 3 2 4 2 4 4 ...\n $ Mjob         : chr [1:320] \"at_home\" \"at_home\" \"health\" \"other\" ...\n $ Fjob         : chr [1:320] \"teacher\" \"other\" \"services\" \"other\" ...\n $ reason       : chr [1:320] \"course\" \"course\" \"home\" \"home\" ...\n $ guardian     : chr [1:320] \"mother\" \"father\" \"mother\" \"father\" ...\n $ traveltime   : num [1:320] 2 1 1 1 1 1 2 1 1 1 ...\n $ studytime    : num [1:320] 2 2 3 2 2 2 2 2 2 2 ...\n $ failures     : num [1:320] 0 0 0 0 0 0 0 0 0 0 ...\n $ schoolsup    : chr [1:320] \"yes\" \"no\" \"no\" \"no\" ...\n $ famsup       : chr [1:320] \"no\" \"yes\" \"yes\" \"yes\" ...\n $ paid_math    : chr [1:320] \"no\" \"no\" \"yes\" \"yes\" ...\n $ activities   : chr [1:320] \"no\" \"no\" \"yes\" \"no\" ...\n $ nursery      : chr [1:320] \"yes\" \"no\" \"yes\" \"yes\" ...\n $ higher       : chr [1:320] \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ internet     : chr [1:320] \"no\" \"yes\" \"yes\" \"no\" ...\n $ romantic     : chr [1:320] \"no\" \"no\" \"yes\" \"no\" ...\n $ famrel       : num [1:320] 4 5 3 4 5 4 4 4 5 3 ...\n $ freetime     : num [1:320] 3 3 2 3 4 4 1 2 5 3 ...\n $ goout        : num [1:320] 4 3 2 2 2 4 4 2 1 3 ...\n $ Dalc         : num [1:320] 1 1 1 1 1 1 1 1 1 1 ...\n $ Walc         : num [1:320] 1 1 1 2 2 1 1 1 1 2 ...\n $ health       : num [1:320] 3 3 5 5 5 3 1 1 5 2 ...\n $ absences_math: num [1:320] 6 4 2 4 10 0 6 0 0 0 ...\n $ G1_math      : num [1:320] 5 5 15 6 15 12 6 16 14 10 ...\n $ G2_math      : num [1:320] 6 5 14 10 15 12 5 18 15 8 ...\n $ G3_math      : num [1:320] 6 6 15 10 15 11 6 19 15 9 ...\n $ paid_lang    : chr [1:320] \"no\" \"no\" \"no\" \"no\" ...\n $ absences_lang: num [1:320] 4 2 0 0 6 0 2 0 0 2 ...\n $ G1_lang      : num [1:320] 0 9 14 11 12 13 10 15 12 14 ...\n $ G2_lang      : num [1:320] 11 11 14 13 12 12 13 16 12 14 ...\n $ G3_lang      : num [1:320] 11 11 14 13 13 13 13 17 13 14 ...\n\n\n\n\nNote: When using the same variables from the given merge code, this is warning is seen.\n\nWarning in inner_join(d1, d2, by = variables) :\n  Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 79 of `x` matches multiple rows in `y`.\nℹ Row 79 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to silence this\n  warning.\nThis inner_join() creates way more data than expected or desired. This is because the data is not unique rows for that variable set. It is matching multiple rows from the other data set. Joining the data here means the student is likely the same student found in both data sets for different classes (they have the same attributes for things like age, sex, address, etc.). The given variables are fairly specific, but not enough to make the rows unique.\n\n\n\nFor the math data, Portuguese, and combined, choose four categorical variables and convert those into factor variables.\n\nVariables: “internet”, “Pstatus”, “famsize”, “sex”\n\n\nvariables_chosen &lt;- c(\"internet\", \"Pstatus\", \"famsize\", \"sex\")\nstr(data$combined[,variables_chosen], give.attr = FALSE)\n\ntibble [320 × 4] (S3: tbl_df/tbl/data.frame)\n $ internet: chr [1:320] \"no\" \"yes\" \"yes\" \"no\" ...\n $ Pstatus : chr [1:320] \"A\" \"T\" \"T\" \"T\" ...\n $ famsize : chr [1:320] \"GT3\" \"GT3\" \"GT3\" \"GT3\" ...\n $ sex     : chr [1:320] \"F\" \"F\" \"F\" \"F\" ...\n\ndata$d1 &lt;- data$d1 |&gt; mutate(across(all_of(variables_chosen), as.factor))\ndata$d2 &lt;- data$d2 |&gt; mutate(across(all_of(variables_chosen), as.factor))\ndata$combined &lt;- data$combined |&gt; mutate(across(all_of(variables_chosen), as.factor))\nstr(data$combined[,variables_chosen], give.attr = FALSE)\n\ntibble [320 × 4] (S3: tbl_df/tbl/data.frame)\n $ internet: Factor w/ 2 levels \"no\",\"yes\": 1 2 2 1 2 2 1 2 2 2 ...\n $ Pstatus : Factor w/ 2 levels \"A\",\"T\": 1 2 2 2 2 2 1 1 2 2 ...\n $ famsize : Factor w/ 2 levels \"GT3\",\"LE3\": 1 1 1 1 2 2 1 2 1 1 ...\n $ sex     : Factor w/ 2 levels \"F\",\"M\": 1 1 1 1 2 2 1 2 2 1 ..."
  },
  {
    "objectID": "homeworks/Homework_5.html#task-2-summarize-the-data-very-basic-eda",
    "href": "homeworks/Homework_5.html#task-2-summarize-the-data-very-basic-eda",
    "title": "Homework 5",
    "section": "Task 2: Summarize the Data (Very Basic EDA)",
    "text": "Task 2: Summarize the Data (Very Basic EDA)\n\nLook at how the data is stored and see if everything makes sense.\n\nLooking at students.txt from the zip file for further descriptions of the variables, we see:\n\nstr(data$combined[c(\"Medu\",\"Fedu\",\"traveltime\",\"studytime\",\"failures\",\"famrel\",\"freetime\",\"goout\",\"Dalc\",\"Walc\",\"health\",\"G1_math\",\"G2_lang\")])\n\ntibble [320 × 13] (S3: tbl_df/tbl/data.frame)\n $ Medu      : num [1:320] 4 1 4 3 4 2 4 3 3 4 ...\n $ Fedu      : num [1:320] 4 1 2 3 3 2 4 2 4 4 ...\n $ traveltime: num [1:320] 2 1 1 1 1 1 2 1 1 1 ...\n $ studytime : num [1:320] 2 2 3 2 2 2 2 2 2 2 ...\n $ failures  : num [1:320] 0 0 0 0 0 0 0 0 0 0 ...\n $ famrel    : num [1:320] 4 5 3 4 5 4 4 4 5 3 ...\n $ freetime  : num [1:320] 3 3 2 3 4 4 1 2 5 3 ...\n $ goout     : num [1:320] 4 3 2 2 2 4 4 2 1 3 ...\n $ Dalc      : num [1:320] 1 1 1 1 1 1 1 1 1 1 ...\n $ Walc      : num [1:320] 1 1 1 2 2 1 1 1 1 2 ...\n $ health    : num [1:320] 3 3 5 5 5 3 1 1 5 2 ...\n $ G1_math   : num [1:320] 5 5 15 6 15 12 6 16 14 10 ...\n $ G2_lang   : num [1:320] 11 11 14 13 12 12 13 16 12 14 ...\n\n\n\nMedu/Fedu - Education levels that are bucketed (2 is 5th to 9th grade).\ntraveltime - Unequal bucketing of time data. It has 15 min intervals that switches to 30 minute interval, and finishes with a single value of 1 hour.\nstudytime - 1hr, 3hr, and 5hr intervals and a single value of 10hrs.\nfailures - n if 1&lt;=n&lt;3, else 4 (a lot of values are 0, so those are really 4)\nfamrel, freetime, goout, Dalc, Walc, health - these are ratings 1-5 and shouldn’t be numerically summarized (a 1 and a 5 don’t necessarily average to a 3, and two 1’s from two people aren’t necessarily the same)\nG1, G2 - No issues, but for some reason the source site lists them as categorical\n\n\n\nDocument the missing values in the data.\n\nThe data claims to have no missing values on the source site.\n\ncolSums(is.na(data$combined))\n\n       school           sex           age       address       famsize \n            0             0             0             0             0 \n      Pstatus          Medu          Fedu          Mjob          Fjob \n            0             0             0             0             0 \n       reason      guardian    traveltime     studytime      failures \n            0             0             0             0             0 \n    schoolsup        famsup     paid_math    activities       nursery \n            0             0             0             0             0 \n       higher      internet      romantic        famrel      freetime \n            0             0             0             0             0 \n        goout          Dalc          Walc        health absences_math \n            0             0             0             0             0 \n      G1_math       G2_math       G3_math     paid_lang absences_lang \n            0             0             0             0             0 \n      G1_lang       G2_lang       G3_lang \n            0             0             0 \n\n\n\nIt seems to check out, all 0’s.\n\n\n\nCategorical Variables\n\n\nVariables: “internet”, “Pstatus”, “famsize”, “sex”\n\nContingency table.\n\nOne-way\n\n\ntable(data$combined$Pstatus)\n\n\n  A   T \n 31 289 \n\n\nFor most of the data, we see that the parents live together.\n\nTwo-way\n\n\ntable(data$combined$sex, data$combined$Pstatus)\n\n   \n      A   T\n  F  18 156\n  M  13 133\n\n\nBetween sex, there seems to be little to no difference in parent’s living together or apart.\n\nThree-way\n\n\ntable(data$combined$sex, data$combined$Pstatus, data$combined$famsize)\n\n, ,  = GT3\n\n   \n      A   T\n  F  12 118\n  M   4  96\n\n, ,  = LE3\n\n   \n      A   T\n  F   6  38\n  M   9  37\n\n\nSurprisingly, the numbers for those with 3 children or greater are much higher than those 3 or less. The less than 3 children seems to have a higher ratio of parent’s not living together.\nConditional two-way table.\n\nMethod 1\n\n\ntable(data$combined$sex, data$combined$famsize, data$combined$Pstatus)[1,,]\n\n     \n        A   T\n  GT3  12 118\n  LE3   6  38\n\n\n\nMethod 2\n\n\nwith(data$combined |&gt; filter(sex == \"M\"), table(famsize, Pstatus))\n\n       Pstatus\nfamsize  A  T\n    GT3  4 96\n    LE3  9 37\n\n\nThese two methods show the Female and Male counts of family size/parental living situation. Comparing the 2, the only major difference is the GT3 and LE3 for apart living parents flips. This doesn’t necessarily mean anything, though.\n\nMethod 3\n\n\nplot_data &lt;- data$combined |&gt;\n  group_by(internet, famsize) |&gt;\n  summarize(count = n()) |&gt;\n  pivot_wider(names_from=internet, values_from=count)\n\n`summarise()` has grouped output by 'internet'. You can override using the\n`.groups` argument.\n\n\nThe ratio of larger families having internet is much larger than that of smaller families.\nStacked bar graph.\n\nggplot(data$combined, aes(x = famsize, fill = internet)) + geom_bar() + labs(x=\"Family Size\", y=\"Has Internet\", title=\"Family Size to Internet Ratios\", fill=\"Has Internet\")\n\n\n\n\n\n\n\n\nThis graphically displays the previous comparison of family size and internet.\n\nggplot(data$combined, aes(x = famsize, fill = internet)) + geom_bar(position=\"dodge\") + labs(x=\"Family Size\", y=\"Has Internet\", title=\"Family Size to Internet Ratios\", fill=\"Has Internet\")\n\n\n\n\n\n\n\n\nFinally a non-stacked version of the plot is shown.\n\n\nNumerical Variables\n\n\nVariables: “age”, “absences”, “G1”, “G2”, “G3”\n\n\nMeasures of center and spread\n\n\ndata$combined |&gt;\n  select(age, starts_with(\"absences\"), starts_with(\"G3\")) |&gt;\n  summarize(across(everything(), list(\"mean\"=mean, \"med\"=median, \"sd\"=sd, \"IQR\"=IQR), .names = \"{.fn}_{.col}\")) |&gt;\n  str()\n\ntibble [1 × 20] (S3: tbl_df/tbl/data.frame)\n $ mean_age          : num 16.5\n $ med_age           : num 16\n $ sd_age            : num 1.14\n $ IQR_age           : num 1\n $ mean_absences_math: num 5.41\n $ med_absences_math : num 4\n $ sd_absences_math  : num 7.84\n $ IQR_absences_math : num 7.25\n $ mean_absences_lang: num 3.25\n $ med_absences_lang : num 2\n $ sd_absences_lang  : num 4.56\n $ IQR_absences_lang : num 4\n $ mean_G3_math      : num 11\n $ med_G3_math       : num 11\n $ sd_G3_math        : num 4.3\n $ IQR_G3_math       : num 5\n $ mean_G3_lang      : num 12.9\n $ med_G3_lang       : num 13\n $ sd_G3_lang        : num 2.89\n $ IQR_G3_lang       : num 4\n\n\nThis shows the mean, sd, and IQR of each numeric variable. The language class has a higher mean and smaller standard deviation than the math class for final grade.\n\nRepeated with subset of not having internet.\n\n\ndata$combined |&gt;\n  filter(internet == \"no\") |&gt;\n  select(age, starts_with(\"absences\"), starts_with(\"G3\")) |&gt;\n  summarize(across(everything(), list(\"mean\"=mean, \"med\"=median, \"sd\"=sd, \"IQR\"=IQR), .names = \"{.fn}_{.col}\")) |&gt;\n  str()\n\ntibble [1 × 20] (S3: tbl_df/tbl/data.frame)\n $ mean_age          : num 16.6\n $ med_age           : num 17\n $ sd_age            : num 1.06\n $ IQR_age           : num 1\n $ mean_absences_math: num 4.02\n $ med_absences_math : num 3.5\n $ sd_absences_math  : num 3.99\n $ IQR_absences_math : num 4.25\n $ mean_absences_lang: num 2.75\n $ med_absences_lang : num 2\n $ sd_absences_lang  : num 2.76\n $ IQR_absences_lang : num 4\n $ mean_G3_math      : num 9.69\n $ med_G3_math       : num 10\n $ sd_G3_math        : num 4.12\n $ IQR_G3_math       : num 4\n $ mean_G3_lang      : num 12.2\n $ med_G3_lang       : num 12.5\n $ sd_G3_lang        : num 3.53\n $ IQR_G3_lang       : num 3\n\n\nWe see not having internet has had a negative effect. The means have gone down. The spread is wider.\n\nCenter and spread for a grouping of those with parents separated or not.\n\n\ndata$combined |&gt;\n  select(age, starts_with(\"absences\"), starts_with(\"G3\"), Pstatus) |&gt;\n  group_by(Pstatus) |&gt;\n  summarize(across(everything(), list(\"mean\"=mean, \"med\"=median, \"sd\"=sd, \"IQR\"=IQR), .names = \"{.fn}_{.col}\")) |&gt;\n  str()\n\ntibble [2 × 21] (S3: tbl_df/tbl/data.frame)\n $ Pstatus           : Factor w/ 2 levels \"A\",\"T\": 1 2\n $ mean_age          : num [1:2] 16.4 16.5\n $ med_age           : num [1:2] 16 16\n $ sd_age            : num [1:2] 1.2 1.14\n $ IQR_age           : num [1:2] 2 1\n $ mean_absences_math: num [1:2] 10.03 4.92\n $ med_absences_math : num [1:2] 6 3\n $ sd_absences_math  : num [1:2] 13.98 6.72\n $ IQR_absences_math : num [1:2] 9 6\n $ mean_absences_lang: num [1:2] 4.1 3.16\n $ med_absences_lang : num [1:2] 2 2\n $ sd_absences_lang  : num [1:2] 5.56 4.44\n $ IQR_absences_lang : num [1:2] 6 4\n $ mean_G3_math      : num [1:2] 11.9 10.9\n $ med_G3_math       : num [1:2] 11 11\n $ sd_G3_math        : num [1:2] 3.61 4.37\n $ IQR_G3_math       : num [1:2] 4.5 5\n $ mean_G3_lang      : num [1:2] 13.5 12.8\n $ med_G3_lang       : num [1:2] 13 13\n $ sd_G3_lang        : num [1:2] 2.22 2.95\n $ IQR_G3_lang       : num [1:2] 3 4\n\n\nIt looks like parents separated or not has little effect on means but seems to increase the variability.\n\nCenter and spread, two grouping of internet (y/n) and parents (together,apart)\n\n\ndata$combined |&gt;\n  select(age, starts_with(\"absences\"), starts_with(\"G3\"), Pstatus, internet) |&gt;\n  group_by(Pstatus, internet) |&gt;\n  summarize(across(everything(), list(\"mean\"=mean, \"sd\"=sd, \"IQR\"=IQR), .names = \"{.fn}_{.col}\")) |&gt;\n  str()\n\n`summarise()` has grouped output by 'Pstatus'. You can override using the\n`.groups` argument.\n\n\ngropd_df [4 × 17] (S3: grouped_df/tbl_df/tbl/data.frame)\n $ Pstatus           : Factor w/ 2 levels \"A\",\"T\": 1 1 2 2\n $ internet          : Factor w/ 2 levels \"no\",\"yes\": 1 2 1 2\n $ mean_age          : num [1:4] 16.6 16.3 16.7 16.5\n $ sd_age            : num [1:4] 1.14 1.23 1.07 1.15\n $ IQR_age           : num [1:4] 1 2 1 1\n $ mean_absences_math: num [1:4] 8.4 10.35 3.51 5.16\n $ sd_absences_math  : num [1:4] 6.07 15.1 3.43 7.11\n $ IQR_absences_math : num [1:4] 4 9.5 4 7\n $ mean_absences_lang: num [1:4] 4.4 4.04 2.56 3.26\n $ sd_absences_lang  : num [1:4] 3.85 5.9 2.59 4.68\n $ IQR_absences_lang : num [1:4] 4 5.5 4 4\n $ mean_G3_math      : num [1:4] 8.2 12.62 9.86 11.14\n $ sd_G3_math        : num [1:4] 2.59 3.36 4.25 4.37\n $ IQR_G3_math       : num [1:4] 5 4 3.5 5\n $ mean_G3_lang      : num [1:4] 11.8 13.8 12.3 12.9\n $ sd_G3_lang        : num [1:4] 2.17 2.12 3.67 2.8\n $ IQR_G3_lang       : num [1:4] 3 3.5 3 4\n - attr(*, \"groups\")= tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ Pstatus: Factor w/ 2 levels \"A\",\"T\": 1 2\n  ..$ .rows  : list&lt;int&gt; [1:2] \n  .. ..$ : int [1:2] 1 2\n  .. ..$ : int [1:2] 3 4\n  .. ..@ ptype: int(0) \n  ..- attr(*, \".drop\")= logi TRUE\n\n\nThe highest mean outcome seems to be parents apart and with internet. The variability generally goes down a bit too, but it depends on math vs language course.\n\nCorrelation matrix\n\n\ndata$combined |&gt;\n  select(age, starts_with(\"absences\"), starts_with(\"G3\")) |&gt;\n  cor() |&gt;\n  round(3)\n\n                 age absences_math absences_lang G3_math G3_lang\nage            1.000         0.144         0.047  -0.206  -0.009\nabsences_math  0.144         1.000         0.564  -0.028  -0.136\nabsences_lang  0.047         0.564         1.000  -0.117  -0.071\nG3_math       -0.206        -0.028        -0.117   1.000   0.476\nG3_lang       -0.009        -0.136        -0.071   0.476   1.000\n\n\nThe largest correlation effect to a final grade is age, but it is a minor negative correlation.\n\nPlots\n\nHistogram\n\n\n\nggplot(data$combined) +\n  geom_histogram(aes(x=G1_math, fill=internet), binwidth=1) +\n  labs(title=\"Math Score by Internet\", x=\"Math Score\", y=\"Count\", fill=\"Internet\")\n\n\n\n\n\n\n\nggplot(data$combined) +\n  geom_histogram(aes(x=G1_lang, fill=internet), binwidth=1) +\n  labs(title=\"Language Score by Internet\", x=\"Language Score\", y=\"Count\", fill=\"Internet\")\n\n\n\n\n\n\n\n\nBetween the two plots of math and language, it looks like generally the scores are higher in language. It’s hard to tell if internet had any effect.\n\nKernel Density\n\n\nggplot(data$combined) +\n  geom_density(aes(x=G2_math, fill=internet)) +\n  labs(title=\"Math Score by Internet\", x=\"Math Score\", y=\"Density\", fill=\"Internet\")\n\n\n\n\n\n\n\nggplot(data$combined) +\n  geom_density(aes(x=G2_lang, fill=internet)) +\n  labs(title=\"Language Score by Internet\", x=\"Language Score\", y=\"Density\", fill=\"Internet\")\n\n\n\n\n\n\n\n\nThe same density plot of math vs language tell sthe same story (the axis shifted some). It’s a little more clear from this plot that internet had a negative effect on math, but no clear effect on language.\n\nBoxplot\n\n\nggplot(data$combined) +\n  geom_boxplot(aes(y=G3_math, fill=internet)) +\n  labs(title=\"Math Score by Internet\", x=NULL, y=\"Math Score\", fill=\"Internet\")\n\n\n\n\n\n\n\nggplot(data$combined) +\n  geom_boxplot(aes(y=G3_lang, fill=internet)) +\n  labs(title=\"Language Score by Internet\", x=NULL, y=\"Language Score\", fill=\"Internet\")\n\n\n\n\n\n\n\n\nThe boxplots show the same story, but a little better for language to see some slight negative effect of no internet and decreased variability.\n\nScatterPlots\n\nOne - Absences in math to math score, colored by internet (y/n)\n\n\n\nggplot(data$combined) +\n  geom_point(aes(x=absences_math, y=G3_math, color=internet), position=\"jitter\") +\n  labs(title=\"Absences vs Math Score by (internet)\", x=\"Absences\", y=\"Math Score\")\n\n\n\n\n\n\n\n\nIt does look like the higher absences may tend to be those with internet, but it’s unclear from this what the score effect would be.\n\nTwo - The same, but for language.\n\n\nggplot(data$combined) +\n  geom_point(aes(x=absences_lang, y=G3_lang, color=internet), position=\"jitter\") +\n  labs(title=\"Absences vs Language Score by (internet)\", x=\"Absences\", y=\"Language Score\")\n\n\n\n\n\n\n\n\nThis agrees well with the previous view of higher absence holders are those with internet.\n\nFaceting\n\nOne - This takes a look at study time effect on score, covered over sex.\n\n\n\nggplot(data$combined, aes(x=studytime, y=G3_math)) +\n  geom_point(position=\"jitter\") +\n  geom_smooth(method=\"lm\") +\n  facet_wrap(~ sex) +\n  labs(title=\"Study Time vs Math Score by (sex)\", x=\"Study Time\", y=\"Math Score\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThere is not a clear effect either way. It’s surprising to see study time is having such little effect.\n\nTwo - The same as previous, but for language.\n\n\nggplot(data$combined, aes(x=studytime, y=G3_lang)) +\n  geom_point(position=\"jitter\") +\n  geom_smooth(method=\"lm\") +\n  facet_wrap(~ sex) +\n  labs(title=\"Study Time vs Language Score by (sex)\", x=\"Study Time\", y=\"Language Score\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThere seems to be a small positive effect of study time on language, but it does not visibly differ between sex.\n\nFaceting again, but over 2 variables.\n\nThe effect of having school support (y/n), and whether the address is urban/rural (U/R).\n\n\n\nggplot(data$combined, aes(x=age, y=G3_math)) +\n  geom_point(position=\"jitter\") +\n  geom_smooth(method=\"lm\") +\n  facet_wrap(~ schoolsup + address) +\n  labs(title=\"Age vs Math Score by (school support and address)\", x=\"Age\", y=\"Math Score\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThere seems to be a general downward trend on age. But having school support can help somewhat. The low data points item is unreliable (rural with support).\n\nThe same as previous but for language.\n\n\nggplot(data$combined, aes(x=age, y=G3_lang)) +\n  geom_point(position=\"jitter\") +\n  geom_smooth(method=\"lm\") +\n  facet_wrap(~ schoolsup + address) +\n  labs(title=\"Age vs Language Score by (school support and address)\", x=\"Age\", y=\"Language Score\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFor language, it seems there may be a positive effect of urban vs rural, but not so much from school support."
  },
  {
    "objectID": "homeworks/Homework_9.html#hw8-outcome",
    "href": "homeworks/Homework_9.html#hw8-outcome",
    "title": "Homework 9",
    "section": "HW8 Outcome",
    "text": "HW8 Outcome\n\nfinal_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy() |&gt;\n  print(n=Inf)\n\n# A tibble: 28 × 5\n   term                                 estimate std.error statistic  p.value\n   &lt;chr&gt;                                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                          22502.       1533.  14.7     4.55e-35\n 2 humidity                             -2138.       1434.  -1.49    1.37e- 1\n 3 seasons_Spring                       -1984.        238.  -8.33    6.67e-15\n 4 seasons_Summer                        8057.        921.   8.75    4.20e-16\n 5 seasons_Winter                       -4114.        994.  -4.14    4.88e- 5\n 6 holiday_No.Holiday                     894.        191.   4.69    4.61e- 6\n 7 day_type_Weekend                     -1098.        169.  -6.50    4.66e-10\n 8 seasons_Spring_x_holiday_No.Holiday     -2.41      256.  -0.00942 9.92e- 1\n 9 seasons_Summer_x_holiday_No.Holiday   -126.        239.  -0.529   5.97e- 1\n10 seasons_Winter_x_holiday_No.Holiday   -314.        188.  -1.67    9.63e- 2\n11 seasons_Spring_x_temp_c               1826.        479.   3.81    1.77e- 4\n12 seasons_Summer_x_temp_c              -8357.       1031.  -8.11    2.82e-14\n13 seasons_Winter_x_temp_c              -1376.       1254.  -1.10    2.74e- 1\n14 temp_c_x_rainfall_mm                 -1428.        536.  -2.66    8.30e- 3\n15 temp_c_poly_1                       -63160.      62341.  -1.01    3.12e- 1\n16 temp_c_poly_2                        -6383.      16664.  -0.383   7.02e- 1\n17 wind_speed_m_s_poly_1                -4680.       3139.  -1.49    1.37e- 1\n18 wind_speed_m_s_poly_2                 4302.       3124.   1.38    1.70e- 1\n19 visibility_10m_poly_1                 6893.       4071.   1.69    9.17e- 2\n20 visibility_10m_poly_2                 -998.       2837.  -0.352   7.25e- 1\n21 dew_point_temp_c_poly_1             105158.      74033.   1.42    1.57e- 1\n22 dew_point_temp_c_poly_2              -4659.       9658.  -0.482   6.30e- 1\n23 solar_radiation_mj_m2_poly_1         41217.       5554.   7.42    2.11e-12\n24 solar_radiation_mj_m2_poly_2         -2739.       3307.  -0.828   4.08e- 1\n25 rainfall_mm_poly_1                  -31120.       7046.  -4.42    1.53e- 5\n26 rainfall_mm_poly_2                   15231.       3516.   4.33    2.19e- 5\n27 snowfall_cm_poly_1                   -2736.       3264.  -0.838   4.03e- 1\n28 snowfall_cm_poly_2                    -675.       3046.  -0.222   8.25e- 1\n\nfinal_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    3285.    Preprocessor1_Model1\n2 rsq     standard       0.895 Preprocessor1_Model1"
  },
  {
    "objectID": "homeworks/Homework_9.html#lasso",
    "href": "homeworks/Homework_9.html#lasso",
    "title": "Homework 9",
    "section": "LASSO",
    "text": "LASSO\n\nLASSO engine - Mixture of 1 for LASSO\n\nLASSO_spec &lt;- linear_reg(penalty = tune(), mixture=1) |&gt;\n  set_engine(\"glmnet\")\n\n\n\nReuse HW8 recipe 1 (all predictors, no interaction, no poly terms)\n\nLASSO_wkf &lt;- workflow() |&gt;\n  add_recipe(MLR_1) |&gt;\n  add_model(LASSO_spec)\nLASSO_wkf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\nTune the model, selecting the lowest RMSE found.\n\nLASSO_grid &lt;- LASSO_wkf |&gt;\n  tune_grid(resamples=bike_10_fold, grid=grid_regular(penalty(range=c(-4, 2)), levels=100))\n\nLASSO_grid |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"rmse\") |&gt;\n  ggplot(aes(penalty, mean, color= .metric)) +\n  geom_line()\n\n\n\n\n\n\n\nlowest_rmse &lt;- LASSO_grid |&gt;\n  select_best(metric = \"rmse\")\nlowest_rmse\n\n# A tibble: 1 × 2\n  penalty .config               \n    &lt;dbl&gt; &lt;chr&gt;                 \n1    57.2 Preprocessor1_Model096\n\n\n\n\nGet the final outcome with the lowest RMSE value\n\nLASSO_final_fit &lt;- LASSO_wkf |&gt;\n  finalize_workflow(lowest_rmse) |&gt;\n  last_fit(bike_split, metrics = metric_set(rmse, mae, rsq))\n\nLASSO_final_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy()\n\n# A tibble: 14 × 3\n   term                  estimate penalty\n   &lt;chr&gt;                    &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)             17446.    57.2\n 2 temp_c                   3037.    57.2\n 3 humidity                    0     57.2\n 4 wind_speed_m_s           -484.    57.2\n 5 visibility_10m              0     57.2\n 6 dew_point_temp_c          442.    57.2\n 7 solar_radiation_mj_m2    3928.    57.2\n 8 rainfall_mm             -1850.    57.2\n 9 snowfall_cm              -306.    57.2\n10 seasons_Spring          -2339.    57.2\n11 seasons_Summer          -1283.    57.2\n12 seasons_Winter          -3640.    57.2\n13 holiday_No.Holiday        745.    57.2\n14 day_type_Weekend        -1011.    57.2\n\nLASSO_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    4031.    Preprocessor1_Model1\n2 mae     standard    3079.    Preprocessor1_Model1\n3 rsq     standard       0.842 Preprocessor1_Model1"
  },
  {
    "objectID": "homeworks/Homework_9.html#regression-tree",
    "href": "homeworks/Homework_9.html#regression-tree",
    "title": "Homework 9",
    "section": "Regression Tree",
    "text": "Regression Tree\n\nSame as before, select the model, then add it, using MLR_1\n\nREG_TREE_spec &lt;- decision_tree(tree_depth = tune(), min_n = 20, cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode (\"regression\")\n\nREG_TREE_wkf &lt;- workflow() |&gt;\n  add_recipe(MLR_1) |&gt;\n  add_model(REG_TREE_spec)\n\n\n\nTune on depth and cost complexity, plot both.\n\nREG_TREE_grid &lt;- REG_TREE_wkf |&gt;\n  tune_grid(resamples=bike_10_fold, grid=grid_regular(cost_complexity(), tree_depth(), levels=c(10, 10)))\n\nREG_TREE_grid |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"rmse\") |&gt;\n  ggplot(aes(x=tree_depth, y=mean, color=.metric)) +\n  geom_line()\n\n\n\n\n\n\n\nREG_TREE_grid |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"rmse\") |&gt;\n  ggplot(aes(x=cost_complexity, y=mean, color=.metric)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\nSelect lowest of both\n\nlowest_rmse &lt;- REG_TREE_grid |&gt;\n    select_best(metric = \"rmse\")\nlowest_rmse\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config               \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                 \n1           0.001         10 Preprocessor1_Model068\n\n\n\n\nFinal fit\n\nREG_TREE_final_fit &lt;- REG_TREE_wkf |&gt;\n    finalize_workflow(lowest_rmse) |&gt;\n    last_fit(bike_split, metrics = metric_set(rmse, mae, rsq))\n\n\n\nOutcome\n\ntree_final_model &lt;- extract_workflow(REG_TREE_final_fit)\ntree_final_model |&gt;\n  extract_fit_engine() |&gt;\n  rpart.plot::rpart.plot(roundint = FALSE)\n\n\n\n\n\n\n\nREG_TREE_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    3096.    Preprocessor1_Model1\n2 mae     standard    2362.    Preprocessor1_Model1\n3 rsq     standard       0.905 Preprocessor1_Model1"
  },
  {
    "objectID": "homeworks/Homework_9.html#bagged-tree",
    "href": "homeworks/Homework_9.html#bagged-tree",
    "title": "Homework 9",
    "section": "Bagged Tree",
    "text": "Bagged Tree\n\nSame as before, select the model, then add it, using MLR_1\n\nBAG_TREE_spec &lt;- bag_tree(tree_depth = 5, min_n = 10, cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"regression\")\n\nBAG_TREE_wkf &lt;- workflow() |&gt;\n  add_recipe(MLR_1) |&gt;\n  add_model(BAG_TREE_spec)\n\n\n\nTune on cost complexity, plot both.\n\nBAG_TREE_grid &lt;- BAG_TREE_wkf |&gt;\n  tune_grid(resamples = bike_10_fold, grid=grid_regular(cost_complexity(range = c(-5, -1)), levels=15), metrics = metric_set(rmse))\n\nBAG_TREE_grid |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"rmse\") |&gt;\n  ggplot(aes(x=cost_complexity, y=mean, color=.metric)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\nSelect lowest\n\nlowest_rmse &lt;- BAG_TREE_grid |&gt;\n  select_best(metric = \"rmse\")\n\nlowest_rmse\n\n# A tibble: 1 × 2\n  cost_complexity .config              \n            &lt;dbl&gt; &lt;chr&gt;                \n1           0.001 Preprocessor1_Model08\n\n\n\n\nFinal fit\n\nBAG_TREE_final_fit &lt;- BAG_TREE_wkf |&gt;\n    finalize_workflow(lowest_rmse) |&gt;\n    last_fit(bike_split, metrics = metric_set(rmse, mae, rsq))\n\n\n\nOutcome - The temperatures are the most important, followed by solar radiation, season, then humidity.\n\nBAG_TREE_final_model &lt;- extract_fit_engine(BAG_TREE_final_fit)\nBAG_TREE_final_model$imp |&gt;\n  mutate(term = factor(term, levels = term)) |&gt;\n  ggplot(aes(x=term, y=value)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip()\n\n\n\n\n\n\n\nBAG_TREE_final_fit |&gt;\n    collect_metrics()\n\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    2948.    Preprocessor1_Model1\n2 mae     standard    2344.    Preprocessor1_Model1\n3 rsq     standard       0.916 Preprocessor1_Model1"
  },
  {
    "objectID": "homeworks/Homework_9.html#random-forest",
    "href": "homeworks/Homework_9.html#random-forest",
    "title": "Homework 9",
    "section": "Random Forest",
    "text": "Random Forest\n\nSame as before, select the model, then add it, using MLR_1\n\nRF_spec &lt;- rand_forest(mtry = tune()) |&gt;\n  set_engine(\"ranger\", importance=\"impurity\") |&gt;\n  set_mode(\"regression\")\n\nRF_wkf &lt;- workflow() |&gt;\n  add_recipe(MLR_1) |&gt;\n  add_model(RF_spec)\n\n\n\nTune on cost complexity, plot both.\n\nRF_grid &lt;- RF_wkf |&gt;\n    tune_grid(resamples = bike_10_fold, grid = 10, metrics = metric_set(rmse))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\nRF_grid |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"rmse\") |&gt;\n  ggplot(aes(x=mtry, y=mean, color=.metric)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\nSelect lowest\n\nlowest_rmse &lt;- RF_grid |&gt;\n    select_best(metric = \"rmse\")\nlowest_rmse\n\n# A tibble: 1 × 2\n   mtry .config             \n  &lt;int&gt; &lt;chr&gt;               \n1     9 Preprocessor1_Model3\n\n\n\n\nFinal fit\n\nRF_final_fit &lt;- RF_wkf |&gt;\n    finalize_workflow(lowest_rmse) |&gt;\n    last_fit(bike_split, metrics = metric_set(rmse, mae, rsq))\n\n\n\nOutcome - Interestingly here, the correlated temps are separated. Random forest does better about not choosing only the highest correlated items. Now it is temp, solar radiation, winter, and then dew_point_temp.\n\nRF_final_model &lt;- extract_fit_engine(RF_final_fit)\nimportance_values &lt;- RF_final_model$variable.importance\nimportance_df &lt;- data.frame(\n  term = names(importance_values),\n  value = importance_values\n) |&gt;\n  as_tibble() |&gt;\n  arrange(desc(value))\n\nimportance_df |&gt;\n  mutate(term = factor(term, levels = term)) |&gt;\n  ggplot(aes(x=term, y=value)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip()\n\n\n\n\n\n\n\nRF_final_fit |&gt;\n    collect_metrics()\n\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    2704.    Preprocessor1_Model1\n2 mae     standard    2184.    Preprocessor1_Model1\n3 rsq     standard       0.931 Preprocessor1_Model1"
  },
  {
    "objectID": "homeworks/Homework_9.html#compare-all",
    "href": "homeworks/Homework_9.html#compare-all",
    "title": "Homework 9",
    "section": "Compare All",
    "text": "Compare All\n\nPrint all the metrics together\n\n# MLR\nfinal_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    3285.    Preprocessor1_Model1\n2 rsq     standard       0.895 Preprocessor1_Model1\n\nLASSO_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    4031.    Preprocessor1_Model1\n2 mae     standard    3079.    Preprocessor1_Model1\n3 rsq     standard       0.842 Preprocessor1_Model1\n\nREG_TREE_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    3096.    Preprocessor1_Model1\n2 mae     standard    2362.    Preprocessor1_Model1\n3 rsq     standard       0.905 Preprocessor1_Model1\n\nBAG_TREE_final_fit |&gt;\n    collect_metrics()\n\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    2948.    Preprocessor1_Model1\n2 mae     standard    2344.    Preprocessor1_Model1\n3 rsq     standard       0.916 Preprocessor1_Model1\n\nRF_final_fit |&gt;\n    collect_metrics()\n\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    2704.    Preprocessor1_Model1\n2 mae     standard    2184.    Preprocessor1_Model1\n3 rsq     standard       0.931 Preprocessor1_Model1\n\n\n\n\nRandom forest is the best model. It has the lowest RMSE and MAE, and also the highest R^2. Fit the final overall model using the random forest.\n\nfinal_model &lt;- workflow() |&gt;\n  add_recipe(MLR_1) |&gt;\n  add_model(RF_spec) |&gt;\n  finalize_workflow(lowest_rmse) |&gt;\n  fit(bike_data)\nfinal_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~9L,      x), importance = ~\"impurity\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1)) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      353 \nNumber of independent variables:  13 \nMtry:                             9 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       7403270 \nR squared (OOB):                  0.9250281"
  },
  {
    "objectID": "homeworks/Homework_8.html#reading-data",
    "href": "homeworks/Homework_8.html#reading-data",
    "title": "Homework 8",
    "section": "Reading Data",
    "text": "Reading Data\n\nURL &lt;- \"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\"\ndata &lt;- read.csv(URL, header = TRUE, fileEncoding=\"latin1\")"
  },
  {
    "objectID": "homeworks/Homework_8.html#basic-eda",
    "href": "homeworks/Homework_8.html#basic-eda",
    "title": "Homework 8",
    "section": "Basic EDA",
    "text": "Basic EDA\n\nCount of NA values (looks good)\n\nsum(is.na(data))\n\n[1] 0\n\n\n\n\nFix data, everything is numeric except for Date (Date), Seasons (factor), Holiday (factor), Functioning.Day (factor)\n\ndata_fixed &lt;- data |&gt;\n  mutate(\n    Date = lubridate::dmy(Date),\n    across(where(is.character), as.factor)\n  ) |&gt;\n  rename(\n    date = Date,\n    rented_bike_count = Rented.Bike.Count,\n    hour = Hour,\n    temp_c = Temperature..C.,\n    humidity = Humidity...,\n    wind_speed_m_s = Wind.speed..m.s.,\n    visibility_10m = Visibility..10m.,\n    dew_point_temp_c = Dew.point.temperature..C.,\n    solar_radiation_mj_m2 = Solar.Radiation..MJ.m2.,\n    rainfall_mm = Rainfall.mm.,\n    snowfall_cm = Snowfall..cm.,\n    seasons = Seasons,\n    holiday = Holiday,\n    functioning_day = Functioning.Day\n  ) |&gt;\n  filter(functioning_day == \"Yes\") |&gt;\n  select(-functioning_day)\n\n\n\nMake sure there are no issues left over. Look at summary values.\n\nstr(data_fixed)\n\n'data.frame':   8465 obs. of  13 variables:\n $ date                 : Date, format: \"2017-12-01\" \"2017-12-01\" ...\n $ rented_bike_count    : int  254 204 173 107 78 100 181 460 930 490 ...\n $ hour                 : int  0 1 2 3 4 5 6 7 8 9 ...\n $ temp_c               : num  -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ humidity             : int  37 38 39 40 36 37 35 38 37 27 ...\n $ wind_speed_m_s       : num  2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ visibility_10m       : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 1928 ...\n $ dew_point_temp_c     : num  -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ solar_radiation_mj_m2: num  0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ rainfall_mm          : num  0 0 0 0 0 0 0 0 0 0 ...\n $ snowfall_cm          : num  0 0 0 0 0 0 0 0 0 0 ...\n $ seasons              : Factor w/ 4 levels \"Autumn\",\"Spring\",..: 4 4 4 4 4 4 4 4 4 4 ...\n $ holiday              : Factor w/ 2 levels \"Holiday\",\"No Holiday\": 2 2 2 2 2 2 2 2 2 2 ...\n\nsummary(data_fixed)\n\n      date            rented_bike_count      hour           temp_c      \n Min.   :2017-12-01   Min.   :   2.0    Min.   : 0.00   Min.   :-17.80  \n 1st Qu.:2018-02-27   1st Qu.: 214.0    1st Qu.: 6.00   1st Qu.:  3.00  \n Median :2018-05-28   Median : 542.0    Median :12.00   Median : 13.50  \n Mean   :2018-05-28   Mean   : 729.2    Mean   :11.51   Mean   : 12.77  \n 3rd Qu.:2018-08-24   3rd Qu.:1084.0    3rd Qu.:18.00   3rd Qu.: 22.70  \n Max.   :2018-11-30   Max.   :3556.0    Max.   :23.00   Max.   : 39.40  \n    humidity     wind_speed_m_s  visibility_10m dew_point_temp_c \n Min.   : 0.00   Min.   :0.000   Min.   :  27   Min.   :-30.600  \n 1st Qu.:42.00   1st Qu.:0.900   1st Qu.: 935   1st Qu.: -5.100  \n Median :57.00   Median :1.500   Median :1690   Median :  4.700  \n Mean   :58.15   Mean   :1.726   Mean   :1434   Mean   :  3.945  \n 3rd Qu.:74.00   3rd Qu.:2.300   3rd Qu.:2000   3rd Qu.: 15.200  \n Max.   :98.00   Max.   :7.400   Max.   :2000   Max.   : 27.200  \n solar_radiation_mj_m2  rainfall_mm       snowfall_cm        seasons    \n Min.   :0.0000        Min.   : 0.0000   Min.   :0.00000   Autumn:1937  \n 1st Qu.:0.0000        1st Qu.: 0.0000   1st Qu.:0.00000   Spring:2160  \n Median :0.0100        Median : 0.0000   Median :0.00000   Summer:2208  \n Mean   :0.5679        Mean   : 0.1491   Mean   :0.07769   Winter:2160  \n 3rd Qu.:0.9300        3rd Qu.: 0.0000   3rd Qu.:0.00000                \n Max.   :3.5200        Max.   :35.0000   Max.   :8.80000                \n       holiday    \n Holiday   : 408  \n No Holiday:8057  \n                  \n                  \n                  \n                  \n\n\n\n\nCapture all the values as days grouped, which will be the final used data.\n\nbike_data &lt;- data_fixed |&gt;\n  group_by(date, seasons, holiday) |&gt;\n  summarize(\n    rented_bike_count = sum(rented_bike_count),\n    temp_c = mean(temp_c),\n    humidity = mean(humidity),\n    wind_speed_m_s = mean(wind_speed_m_s),\n    visibility_10m = mean(visibility_10m),\n    dew_point_temp_c = mean(dew_point_temp_c),\n    solar_radiation_mj_m2 = mean(solar_radiation_mj_m2),\n    rainfall_mm = sum(rainfall_mm),\n    snowfall_cm = sum(snowfall_cm)\n  ) |&gt;\n  ungroup()\n\n`summarise()` has grouped output by 'date', 'seasons'. You can override using\nthe `.groups` argument.\n\nstr(bike_data)\n\ntibble [353 × 12] (S3: tbl_df/tbl/data.frame)\n $ date                 : Date[1:353], format: \"2017-12-01\" \"2017-12-02\" ...\n $ seasons              : Factor w/ 4 levels \"Autumn\",\"Spring\",..: 4 4 4 4 4 4 4 4 4 4 ...\n $ holiday              : Factor w/ 2 levels \"Holiday\",\"No Holiday\": 2 2 2 2 2 2 2 2 2 2 ...\n $ rented_bike_count    : int [1:353] 9539 8523 7222 8729 8307 6669 8549 8032 7233 3453 ...\n $ temp_c               : num [1:353] -2.454 1.325 4.875 -0.304 -4.458 ...\n $ humidity             : num [1:353] 45.9 62 81.5 52.5 36.4 ...\n $ wind_speed_m_s       : num [1:353] 1.54 1.71 1.61 3.45 1.11 ...\n $ visibility_10m       : num [1:353] 1871 1471 456 1363 1959 ...\n $ dew_point_temp_c     : num [1:353] -13.55 -5.72 1.88 -9.93 -17.43 ...\n $ solar_radiation_mj_m2: num [1:353] 0.2488 0.2638 0.1254 0.2829 0.0358 ...\n $ rainfall_mm          : num [1:353] 0 0 4 0.1 0 1.3 0 0 0 4.1 ...\n $ snowfall_cm          : num [1:353] 0 0 0 0 0 8.6 10.4 0 0 32.5 ...\n\nsummary(bike_data)\n\n      date              seasons         holiday    rented_bike_count\n Min.   :2017-12-01   Autumn:81   Holiday   : 17   Min.   :  977    \n 1st Qu.:2018-02-27   Spring:90   No Holiday:336   1st Qu.: 6967    \n Median :2018-05-28   Summer:92                    Median :18563    \n Mean   :2018-05-28   Winter:90                    Mean   :17485    \n 3rd Qu.:2018-08-24                                3rd Qu.:26285    \n Max.   :2018-11-30                                Max.   :36149    \n     temp_c           humidity     wind_speed_m_s   visibility_10m  \n Min.   :-14.738   Min.   :22.25   Min.   :0.6625   Min.   : 214.3  \n 1st Qu.:  3.304   1st Qu.:47.58   1st Qu.:1.3042   1st Qu.:1087.0  \n Median : 13.738   Median :57.17   Median :1.6583   Median :1557.8  \n Mean   : 12.776   Mean   :58.17   Mean   :1.7261   Mean   :1434.0  \n 3rd Qu.: 22.592   3rd Qu.:67.71   3rd Qu.:1.9542   3rd Qu.:1874.3  \n Max.   : 33.742   Max.   :95.88   Max.   :4.0000   Max.   :2000.0  \n dew_point_temp_c  solar_radiation_mj_m2  rainfall_mm      snowfall_cm    \n Min.   :-27.750   Min.   :0.02917       Min.   : 0.000   Min.   : 0.000  \n 1st Qu.: -5.188   1st Qu.:0.28333       1st Qu.: 0.000   1st Qu.: 0.000  \n Median :  4.612   Median :0.56500       Median : 0.000   Median : 0.000  \n Mean   :  3.954   Mean   :0.56773       Mean   : 3.576   Mean   : 1.863  \n 3rd Qu.: 14.921   3rd Qu.:0.82000       3rd Qu.: 0.500   3rd Qu.: 0.000  \n Max.   : 25.038   Max.   :1.21667       Max.   :95.500   Max.   :78.700"
  },
  {
    "objectID": "homeworks/Homework_8.html#splitting-data",
    "href": "homeworks/Homework_8.html#splitting-data",
    "title": "Homework 8",
    "section": "Splitting Data",
    "text": "Splitting Data\n\nSet up the splits, additinally add the strata for the split to the folds themselves.\n\nset.seed(11)\nbike_split &lt;- initial_split(bike_data, prop = 0.75, strata = seasons)\nbike_train &lt;- training(bike_split)\nbike_test &lt;- testing(bike_split)\nbike_10_fold &lt;- vfold_cv(bike_train, v = 10, strata = seasons)"
  },
  {
    "objectID": "homeworks/Homework_8.html#linear-regression",
    "href": "homeworks/Homework_8.html#linear-regression",
    "title": "Homework 8",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nFirst recipe - using all predictor values, using date as weekday and weekend.\n\nMLR_1 &lt;- recipe(rented_bike_count ~ ., data = bike_train) |&gt;\n  step_date(date, features = \"dow\") |&gt;\n  step_mutate(day_type = factor(ifelse(date_dow %in% c(\"Sat\", \"Sun\"), \"Weekend\", \"Weekday\"))) |&gt;\n  step_rm(date, date_dow) |&gt;\n  step_dummy(seasons, holiday, day_type) |&gt;\n  step_normalize(all_numeric(), -rented_bike_count)\n\n\n\nSecond recipe - adding in interaction terms.\n\nMLR_2 &lt;- MLR_1 |&gt;\n  step_interact(\n    terms = ~starts_with(\"seasons\") * starts_with(\"holiday\") +\n    starts_with(\"seasons\") * temp_c + rainfall_mm * temp_c)\n\n\n\nThird recipe - adding in polynomial terms.\n\nMLR_3 &lt;- MLR_2 |&gt;\n  step_poly(temp_c, wind_speed_m_s, visibility_10m, dew_point_temp_c, solar_radiation_mj_m2, rainfall_mm, snowfall_cm, degree = 2)\n\n\n\nSetting engine for MLR\n\nMLR_spec &lt;- linear_reg() |&gt;\n  set_engine(\"lm\")"
  },
  {
    "objectID": "homeworks/Homework_8.html#fitting-model-predicting-rmse",
    "href": "homeworks/Homework_8.html#fitting-model-predicting-rmse",
    "title": "Homework 8",
    "section": "Fitting Model, Predicting, RMSE",
    "text": "Fitting Model, Predicting, RMSE\n\nCV for all models\n\nMLR_CV_fit1 &lt;- workflow() |&gt;\n  add_recipe(MLR_1) |&gt;\n  add_model(MLR_spec) |&gt;\n  fit_resamples(resamples = bike_10_fold)\n\nMLR_CV_fit2 &lt;- workflow() |&gt;\n  add_recipe(MLR_2) |&gt;\n  add_model(MLR_spec) |&gt;\n  fit_resamples(resamples = bike_10_fold)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\nMLR_CV_fit3 &lt;- workflow() |&gt;\n  add_recipe(MLR_3) |&gt;\n  add_model(MLR_spec) |&gt;\n  fit_resamples(resamples = bike_10_fold)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\n\n\nMetrics between them.\n\nrbind(\n  MLR_CV_fit1 |&gt; collect_metrics(),\n  MLR_CV_fit2 |&gt; collect_metrics(),\n  MLR_CV_fit3 |&gt; collect_metrics()\n)\n\n# A tibble: 6 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   4161.       10 168.     Preprocessor1_Model1\n2 rsq     standard      0.823    10   0.0221 Preprocessor1_Model1\n3 rmse    standard   3043.       10 181.     Preprocessor1_Model1\n4 rsq     standard      0.901    10   0.0163 Preprocessor1_Model1\n5 rmse    standard   2932.       10 142.     Preprocessor1_Model1\n6 rsq     standard      0.910    10   0.0131 Preprocessor1_Model1\n\n\n\n\nLast metric for model 3, interactions and poly terms, has lowest RMSE and highest R^2\n\nfinal_fit &lt;- workflow() |&gt;\n  add_recipe(MLR_3) |&gt;\n  add_model(MLR_spec) |&gt;\n  last_fit(bike_split)\nfinal_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    3285.    Preprocessor1_Model1\n2 rsq     standard       0.895 Preprocessor1_Model1\n\n\n\n\nSummary\n\nfinal_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy() |&gt;\n  print(n=Inf)\n\n# A tibble: 28 × 5\n   term                                 estimate std.error statistic  p.value\n   &lt;chr&gt;                                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                          22502.       1533.  14.7     4.55e-35\n 2 humidity                             -2138.       1434.  -1.49    1.37e- 1\n 3 seasons_Spring                       -1984.        238.  -8.33    6.67e-15\n 4 seasons_Summer                        8057.        921.   8.75    4.20e-16\n 5 seasons_Winter                       -4114.        994.  -4.14    4.88e- 5\n 6 holiday_No.Holiday                     894.        191.   4.69    4.61e- 6\n 7 day_type_Weekend                     -1098.        169.  -6.50    4.66e-10\n 8 seasons_Spring_x_holiday_No.Holiday     -2.41      256.  -0.00942 9.92e- 1\n 9 seasons_Summer_x_holiday_No.Holiday   -126.        239.  -0.529   5.97e- 1\n10 seasons_Winter_x_holiday_No.Holiday   -314.        188.  -1.67    9.63e- 2\n11 seasons_Spring_x_temp_c               1826.        479.   3.81    1.77e- 4\n12 seasons_Summer_x_temp_c              -8357.       1031.  -8.11    2.82e-14\n13 seasons_Winter_x_temp_c              -1376.       1254.  -1.10    2.74e- 1\n14 temp_c_x_rainfall_mm                 -1428.        536.  -2.66    8.30e- 3\n15 temp_c_poly_1                       -63160.      62341.  -1.01    3.12e- 1\n16 temp_c_poly_2                        -6383.      16664.  -0.383   7.02e- 1\n17 wind_speed_m_s_poly_1                -4680.       3139.  -1.49    1.37e- 1\n18 wind_speed_m_s_poly_2                 4302.       3124.   1.38    1.70e- 1\n19 visibility_10m_poly_1                 6893.       4071.   1.69    9.17e- 2\n20 visibility_10m_poly_2                 -998.       2837.  -0.352   7.25e- 1\n21 dew_point_temp_c_poly_1             105158.      74033.   1.42    1.57e- 1\n22 dew_point_temp_c_poly_2              -4659.       9658.  -0.482   6.30e- 1\n23 solar_radiation_mj_m2_poly_1         41217.       5554.   7.42    2.11e-12\n24 solar_radiation_mj_m2_poly_2         -2739.       3307.  -0.828   4.08e- 1\n25 rainfall_mm_poly_1                  -31120.       7046.  -4.42    1.53e- 5\n26 rainfall_mm_poly_2                   15231.       3516.   4.33    2.19e- 5\n27 snowfall_cm_poly_1                   -2736.       3264.  -0.838   4.03e- 1\n28 snowfall_cm_poly_2                    -675.       3046.  -0.222   8.25e- 1"
  },
  {
    "objectID": "homeworks/Homework_4.html",
    "href": "homeworks/Homework_4.html",
    "title": "Homework 4",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "homeworks/Homework_4.html#task-1-conceptual-questions",
    "href": "homeworks/Homework_4.html#task-1-conceptual-questions",
    "title": "Homework 4",
    "section": "Task 1: Conceptual Questions",
    "text": "Task 1: Conceptual Questions\n\nIf your working directory is myfolder/homework/, what relative path would you specify to get the file located at myfolder/MyDate.csv?\n\n\nYou would back out of the /homework/ folder with .. and you would be looking at the myfolder directory where MyData.csv is located.\n\n\nWhat are the major benefits of using R projects?\n\n\nAn R project allows creating a structured R directory that can be easier to work with and share with others. The entire directory can simply be loaded and ran by others.\n\n\nWhat is git and what is github?\n\n\ngit is version control. github is an online repository that uses git for version control. This allows for much better code and file editing that will preserve prior work and also allows collaborating with others much easier.\n\n\nWhat are the two main differences between a tibble and a data.frame?\n\n\nA data.frame is a BaseR structure. A tibble is tidyverse structure that is like a dataframe, but has more complaining and more limitations.\n\n\nRewrite the following nested function call, using BaseR’s chaining operator:\n\narrange(filter(select(as_tibble(iris), starts_with(\"Petal\"), Species), Petal.Length &lt; 1.55), Species)\n\niris |&gt;\n  as_tibble() |&gt;\n  select(starts_with(\"Petal\"), Species) |&gt;\n  filter(Petal.Length &lt; 1.55) |&gt;\n  arrange(Species)\n\n# A tibble: 37 × 3\n   Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          1.4         0.2 setosa \n 2          1.4         0.2 setosa \n 3          1.3         0.2 setosa \n 4          1.5         0.2 setosa \n 5          1.4         0.2 setosa \n 6          1.4         0.3 setosa \n 7          1.5         0.2 setosa \n 8          1.4         0.2 setosa \n 9          1.5         0.1 setosa \n10          1.5         0.2 setosa \n# ℹ 27 more rows"
  },
  {
    "objectID": "homeworks/Homework_4.html#task-2-reading-delimited-data",
    "href": "homeworks/Homework_4.html#task-2-reading-delimited-data",
    "title": "Homework 4",
    "section": "Task 2: Reading Delimited Data",
    "text": "Task 2: Reading Delimited Data\n\nGlass Data\nRead in the csv file, adding the given column names.\n\n# glass_data &lt;- read_csv(\"../data/hw4/glass.data\", col_names = c(\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\"))\nglass_data &lt;- read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/glass.data\", col_names = c(\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"Type\"), show_col_types = FALSE)\nglass_data\n\n# A tibble: 214 × 11\n      Id    RI    Na    Mg    Al    Si     K    Ca    Ba    Fe  Type\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1  1.52  13.6  4.49  1.1   71.8  0.06  8.75     0  0        1\n 2     2  1.52  13.9  3.6   1.36  72.7  0.48  7.83     0  0        1\n 3     3  1.52  13.5  3.55  1.54  73.0  0.39  7.78     0  0        1\n 4     4  1.52  13.2  3.69  1.29  72.6  0.57  8.22     0  0        1\n 5     5  1.52  13.3  3.62  1.24  73.1  0.55  8.07     0  0        1\n 6     6  1.52  12.8  3.61  1.62  73.0  0.64  8.07     0  0.26     1\n 7     7  1.52  13.3  3.6   1.14  73.1  0.58  8.17     0  0        1\n 8     8  1.52  13.2  3.61  1.05  73.2  0.57  8.24     0  0        1\n 9     9  1.52  14.0  3.58  1.37  72.1  0.56  8.3      0  0        1\n10    10  1.52  13    3.6   1.36  73.0  0.57  8.4      0  0.11     1\n# ℹ 204 more rows\n\n\nChain update the glass_data.\n\nglass_data_updated &lt;- glass_data |&gt;\n  mutate(Type = case_when(\n    Type == 1 ~ \"building_windows_float_processed\",\n    Type == 2 ~ \"building_windows_non_float_processed\",\n    Type == 3 ~ \"vehicle_windows_float_processed\",\n    Type == 4 ~ \"vehicle_windows_non_float_processed\",\n    Type == 5 ~ \"containers\",\n    Type == 6 ~ \"tableware\",\n    Type == 7 ~ \"headlamps\"\n  )) |&gt;\n  filter(Fe &lt; 0.2, Type %in% c(\"tableware\", \"headlamps\"))\nglass_data_updated\n\n# A tibble: 38 × 11\n      Id    RI    Na    Mg    Al    Si     K    Ca    Ba    Fe Type     \n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    \n 1   177  1.52  14    2.39  1.56  72.4  0     9.57  0        0 tableware\n 2   178  1.52  13.8  2.41  1.19  72.8  0     9.77  0        0 tableware\n 3   179  1.52  14.5  2.24  1.62  72.4  0     9.26  0        0 tableware\n 4   180  1.52  14.1  2.19  1.66  72.7  0     9.32  0        0 tableware\n 5   181  1.51  14.4  1.74  1.54  74.6  0     7.59  0        0 tableware\n 6   182  1.52  15.0  0.78  1.74  72.5  0     9.95  0        0 tableware\n 7   183  1.52  14.2  0     2.09  72.7  0    10.9   0        0 tableware\n 8   184  1.52  14.6  0     0.56  73.5  0    11.2   0        0 tableware\n 9   185  1.51  17.4  0     0.34  75.4  0     6.65  0        0 tableware\n10   186  1.51  13.7  3.2   1.81  72.8  1.76  5.43  1.19     0 headlamps\n# ℹ 28 more rows\n\n\n\n\nYeast Data\nRead in the fixed width file, adding given column names.\n\n# yeast_data &lt;- read_fwf(\"../data/hw4/yeast.data\", fwf_widths(c(12,6,6,6,6,6,6,6,6,6), c(\"seq_nam\", \"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\", \"class\")))\nyeast_data &lt;- read_fwf(\"https://www4.stat.ncsu.edu/~online/datasets/yeast.data\", fwf_widths(c(12,6,6,6,6,6,6,6,6,6), c(\"seq_nam\", \"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\", \"class\")), show_col_types = FALSE)\nyeast_data\n\n# A tibble: 1,484 × 10\n   seq_nam      mcg   gvh   alm   mit   erl   pox   vac   nuc class\n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n 1 ADT1_YEAST  0.58  0.61  0.47  0.13   0.5   0    0.48  0.22 MIT  \n 2 ADT2_YEAST  0.43  0.67  0.48  0.27   0.5   0    0.53  0.22 MIT  \n 3 ADT3_YEAST  0.64  0.62  0.49  0.15   0.5   0    0.53  0.22 MIT  \n 4 AAR2_YEAST  0.58  0.44  0.57  0.13   0.5   0    0.54  0.22 NUC  \n 5 AATM_YEAST  0.42  0.44  0.48  0.54   0.5   0    0.48  0.22 MIT  \n 6 AATC_YEAST  0.51  0.4   0.56  0.17   0.5   0.5  0.49  0.22 CYT  \n 7 ABC1_YEAST  0.5   0.54  0.48  0.65   0.5   0    0.53  0.22 MIT  \n 8 BAF1_YEAST  0.48  0.45  0.59  0.2    0.5   0    0.58  0.34 NUC  \n 9 ABF2_YEAST  0.55  0.5   0.66  0.36   0.5   0    0.49  0.22 MIT  \n10 ABP1_YEAST  0.4   0.39  0.6   0.15   0.5   0    0.58  0.3  CYT  \n# ℹ 1,474 more rows\n\n\nChain update the yeast_data.\n\nyeast_data_updated &lt;- yeast_data |&gt;\n  select(-seq_nam & -nuc) |&gt;\n  group_by(class) |&gt;\n  mutate(across(where(is.numeric), list(mean=mean, median=median), .names = \"{.col}_{.fn}\"))\nyeast_data_updated\n\n# A tibble: 1,484 × 22\n# Groups:   class [10]\n     mcg   gvh   alm   mit   erl   pox   vac class mcg_mean mcg_median gvh_mean\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.58  0.61  0.47  0.13   0.5   0    0.48 MIT      0.521       0.51    0.533\n 2  0.43  0.67  0.48  0.27   0.5   0    0.53 MIT      0.521       0.51    0.533\n 3  0.64  0.62  0.49  0.15   0.5   0    0.53 MIT      0.521       0.51    0.533\n 4  0.58  0.44  0.57  0.13   0.5   0    0.54 NUC      0.452       0.45    0.456\n 5  0.42  0.44  0.48  0.54   0.5   0    0.48 MIT      0.521       0.51    0.533\n 6  0.51  0.4   0.56  0.17   0.5   0.5  0.49 CYT      0.481       0.48    0.470\n 7  0.5   0.54  0.48  0.65   0.5   0    0.53 MIT      0.521       0.51    0.533\n 8  0.48  0.45  0.59  0.2    0.5   0    0.58 NUC      0.452       0.45    0.456\n 9  0.55  0.5   0.66  0.36   0.5   0    0.49 MIT      0.521       0.51    0.533\n10  0.4   0.39  0.6   0.15   0.5   0    0.58 CYT      0.481       0.48    0.470\n# ℹ 1,474 more rows\n# ℹ 11 more variables: gvh_median &lt;dbl&gt;, alm_mean &lt;dbl&gt;, alm_median &lt;dbl&gt;,\n#   mit_mean &lt;dbl&gt;, mit_median &lt;dbl&gt;, erl_mean &lt;dbl&gt;, erl_median &lt;dbl&gt;,\n#   pox_mean &lt;dbl&gt;, pox_median &lt;dbl&gt;, vac_mean &lt;dbl&gt;, vac_median &lt;dbl&gt;"
  },
  {
    "objectID": "homeworks/Homework_4.html#task-3-combining-excel-and-delimited-data",
    "href": "homeworks/Homework_4.html#task-3-combining-excel-and-delimited-data",
    "title": "Homework 4",
    "section": "Task 3: Combining Excel and Delimited Data",
    "text": "Task 3: Combining Excel and Delimited Data\nRead in the excel first sheet for white wine.\n\nwhite_wine_data &lt;- read_excel(\"../data/hw4/white-wine.xlsx\", sheet = 1)\nwhite_wine_data\n\n# A tibble: 4,898 × 12\n   `fixed acidity` `volatile acidity` `citric acid` `residual sugar` chlorides\n             &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1               7               0.27          0.36             20.7     0.045\n 2              63               0.3           0.34              1.6     0.049\n 3              81               0.28          0.4               6.9     0.05 \n 4              72               0.23          0.32              8.5     0.058\n 5              72               0.23          0.32              8.5     0.058\n 6              81               0.28          0.4               6.9     0.05 \n 7              62               0.32          0.16              7       0.045\n 8               7               0.27          0.36             20.7     0.045\n 9              63               0.3           0.34              1.6     0.049\n10              81               0.22          0.43              1.5     0.044\n# ℹ 4,888 more rows\n# ℹ 7 more variables: `free sulfur dioxide` &lt;dbl&gt;,\n#   `total sulfur dioxide` &lt;dbl&gt;, density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;,\n#   alcohol &lt;dbl&gt;, quality &lt;dbl&gt;\n\n\nFix the column names from the second sheet.\n\ncol_names &lt;- read_excel(\"../data/hw4/white-wine.xlsx\", sheet = 2) |&gt; pull()\ncolnames(white_wine_data) &lt;- col_names\nwhite_wine_data\n\n# A tibble: 4,898 × 12\n   fixed_acidity volatile_acidity citric_acid residual_sugar chlorides\n           &lt;dbl&gt;            &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1             7             0.27        0.36           20.7     0.045\n 2            63             0.3         0.34            1.6     0.049\n 3            81             0.28        0.4             6.9     0.05 \n 4            72             0.23        0.32            8.5     0.058\n 5            72             0.23        0.32            8.5     0.058\n 6            81             0.28        0.4             6.9     0.05 \n 7            62             0.32        0.16            7       0.045\n 8             7             0.27        0.36           20.7     0.045\n 9            63             0.3         0.34            1.6     0.049\n10            81             0.22        0.43            1.5     0.044\n# ℹ 4,888 more rows\n# ℹ 7 more variables: free_sulfur_dioxide &lt;dbl&gt;, total_sulfur_dioxide &lt;dbl&gt;,\n#   density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;, alcohol &lt;dbl&gt;, quality &lt;dbl&gt;\n\n\nAdd white column.\n\nwhite_wine_data$wine_type &lt;- \"white\"\n\nRead in delimited data for red wine.\n\nred_wine_data &lt;- readr::read_delim(\"../data/hw4/red-wine.csv\", delim=';', show_col_types = FALSE)\nred_wine_data\n\n# A tibble: 1,599 × 12\n   `fixed acidity` `volatile acidity` `citric acid` `residual sugar` chlorides\n             &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1             7.4               0.7           0                 1.9     0.076\n 2             7.8               0.88          0                 2.6     0.098\n 3             7.8               0.76          0.04              2.3     0.092\n 4            11.2               0.28          0.56              1.9     0.075\n 5             7.4               0.7           0                 1.9     0.076\n 6             7.4               0.66          0                 1.8     0.075\n 7             7.9               0.6           0.06              1.6     0.069\n 8             7.3               0.65          0                 1.2     0.065\n 9             7.8               0.58          0.02              2       0.073\n10             7.5               0.5           0.36              6.1     0.071\n# ℹ 1,589 more rows\n# ℹ 7 more variables: `free sulfur dioxide` &lt;dbl&gt;,\n#   `total sulfur dioxide` &lt;dbl&gt;, density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;,\n#   alcohol &lt;dbl&gt;, quality &lt;dbl&gt;\n\n\nUpdate the column names and add the red column.\n\ncolnames(red_wine_data) &lt;- col_names\nred_wine_data$wine_type &lt;- \"red\"\nred_wine_data\n\n# A tibble: 1,599 × 13\n   fixed_acidity volatile_acidity citric_acid residual_sugar chlorides\n           &lt;dbl&gt;            &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1           7.4             0.7         0               1.9     0.076\n 2           7.8             0.88        0               2.6     0.098\n 3           7.8             0.76        0.04            2.3     0.092\n 4          11.2             0.28        0.56            1.9     0.075\n 5           7.4             0.7         0               1.9     0.076\n 6           7.4             0.66        0               1.8     0.075\n 7           7.9             0.6         0.06            1.6     0.069\n 8           7.3             0.65        0               1.2     0.065\n 9           7.8             0.58        0.02            2       0.073\n10           7.5             0.5         0.36            6.1     0.071\n# ℹ 1,589 more rows\n# ℹ 8 more variables: free_sulfur_dioxide &lt;dbl&gt;, total_sulfur_dioxide &lt;dbl&gt;,\n#   density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;, alcohol &lt;dbl&gt;, quality &lt;dbl&gt;,\n#   wine_type &lt;chr&gt;\n\n\nCombine the datasets into one wine dataset.\n\nwine_data &lt;- dplyr::bind_rows(white_wine_data, red_wine_data)\nwine_data\n\n# A tibble: 6,497 × 13\n   fixed_acidity volatile_acidity citric_acid residual_sugar chlorides\n           &lt;dbl&gt;            &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1             7             0.27        0.36           20.7     0.045\n 2            63             0.3         0.34            1.6     0.049\n 3            81             0.28        0.4             6.9     0.05 \n 4            72             0.23        0.32            8.5     0.058\n 5            72             0.23        0.32            8.5     0.058\n 6            81             0.28        0.4             6.9     0.05 \n 7            62             0.32        0.16            7       0.045\n 8             7             0.27        0.36           20.7     0.045\n 9            63             0.3         0.34            1.6     0.049\n10            81             0.22        0.43            1.5     0.044\n# ℹ 6,487 more rows\n# ℹ 8 more variables: free_sulfur_dioxide &lt;dbl&gt;, total_sulfur_dioxide &lt;dbl&gt;,\n#   density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;, alcohol &lt;dbl&gt;, quality &lt;dbl&gt;,\n#   wine_type &lt;chr&gt;\n\n\nChain update new wine data.\n\nwine_data_updated &lt;- wine_data |&gt;\n  filter(quality &gt; 6.5, alcohol &lt; 132) |&gt;\n  arrange(desc(quality)) |&gt;\n  select(contains(\"acid\"), alcohol, wine_type, quality) |&gt;\n  group_by(quality) |&gt;\n  mutate(across(where(is.numeric), list(mean=mean, stdev=sd), .names = \"{.col}_{.fn}\"))\nwine_data_updated\n\n# A tibble: 1,206 × 14\n# Groups:   quality [3]\n   fixed_acidity volatile_acidity citric_acid alcohol wine_type quality\n           &lt;dbl&gt;            &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1            91             0.27        0.45     104 white           9\n 2            66             0.36        0.29     124 white           9\n 3            74             0.24        0.36     125 white           9\n 4            69             0.36        0.34     127 white           9\n 5            71             0.26        0.49     129 white           9\n 6            62             0.66        0.48     128 white           8\n 7            62             0.66        0.48     128 white           8\n 8            68             0.26        0.42     105 white           8\n 9            67             0.23        0.31     107 white           8\n10            67             0.23        0.31     107 white           8\n# ℹ 1,196 more rows\n# ℹ 8 more variables: fixed_acidity_mean &lt;dbl&gt;, fixed_acidity_stdev &lt;dbl&gt;,\n#   volatile_acidity_mean &lt;dbl&gt;, volatile_acidity_stdev &lt;dbl&gt;,\n#   citric_acid_mean &lt;dbl&gt;, citric_acid_stdev &lt;dbl&gt;, alcohol_mean &lt;dbl&gt;,\n#   alcohol_stdev &lt;dbl&gt;"
  },
  {
    "objectID": "homeworks/Homework_7.html#separate-hw---no-quarto",
    "href": "homeworks/Homework_7.html#separate-hw---no-quarto",
    "title": "Homework 7",
    "section": "Separate HW - No Quarto",
    "text": "Separate HW - No Quarto"
  },
  {
    "objectID": "homeworks/Homework_2.html#task-1-basic-vector-practice",
    "href": "homeworks/Homework_2.html#task-1-basic-vector-practice",
    "title": "Homework 2",
    "section": "Task 1: Basic Vector Practice",
    "text": "Task 1: Basic Vector Practice\n\n1. Pre and Post treatment vectors\n\npre_treatment &lt;- c(120, 151, 125, 126, 115, 132, 132, 129, 134, 139, 127, 122, 127, 135, 133, 128, 147, 138, 140, 132)\n\npost_treatment &lt;- c(127, 145, 135, 122, 115, 122, 123, 126, 126, 129, 132, 146, 120, 114, 121, 120, 128, 120, 133, 115)\n\n\n\n2. Renamed each\n\nnames(pre_treatment) &lt;- paste(\"Subject\", 1:length(pre_treatment), sep = \"_\")\nnames(post_treatment) &lt;- paste(\"Subject\", 1:length(post_treatment), sep = \"_\")\n\npre_treatment\n\n Subject_1  Subject_2  Subject_3  Subject_4  Subject_5  Subject_6  Subject_7 \n       120        151        125        126        115        132        132 \n Subject_8  Subject_9 Subject_10 Subject_11 Subject_12 Subject_13 Subject_14 \n       129        134        139        127        122        127        135 \nSubject_15 Subject_16 Subject_17 Subject_18 Subject_19 Subject_20 \n       133        128        147        138        140        132 \n\npost_treatment\n\n Subject_1  Subject_2  Subject_3  Subject_4  Subject_5  Subject_6  Subject_7 \n       127        145        135        122        115        122        123 \n Subject_8  Subject_9 Subject_10 Subject_11 Subject_12 Subject_13 Subject_14 \n       126        126        129        132        146        120        114 \nSubject_15 Subject_16 Subject_17 Subject_18 Subject_19 Subject_20 \n       121        120        128        120        133        115 \n\n\n\n\n3. Difference from pre -&gt; post treatment\n\ndelta &lt;- pre_treatment - post_treatment\n\n\n\n4. Average change - positive value (positive outcome, blood pressure decreased on average by this amount)\n\nmean(delta)\n\n[1] 5.65\n\n\n\n\n5. Which subjects had a decreased blood pressure?\n\ndecrease &lt;- names(which(delta &gt; 0))\ndecrease\n\n [1] \"Subject_2\"  \"Subject_4\"  \"Subject_6\"  \"Subject_7\"  \"Subject_8\" \n [6] \"Subject_9\"  \"Subject_10\" \"Subject_13\" \"Subject_14\" \"Subject_15\"\n[11] \"Subject_16\" \"Subject_17\" \"Subject_18\" \"Subject_19\" \"Subject_20\"\n\n\n\n\n6. Which subjects had an decrease in blood pressure ( positive change, but as a subset vector)?\n\ndecrease_vector &lt;- delta[delta &gt; 0]\ndecrease_vector\n\n Subject_2  Subject_4  Subject_6  Subject_7  Subject_8  Subject_9 Subject_10 \n         6          4         10          9          3          8         10 \nSubject_13 Subject_14 Subject_15 Subject_16 Subject_17 Subject_18 Subject_19 \n         7         21         12          8         19         18          7 \nSubject_20 \n        17 \n\n\n\n\n7. What is the average decrease of blood pressure of those that had the positive change?\n\nmean(decrease_vector)\n\n[1] 10.6"
  },
  {
    "objectID": "homeworks/Homework_2.html#task-2-basic-data-frame-practice",
    "href": "homeworks/Homework_2.html#task-2-basic-data-frame-practice",
    "title": "Homework 2",
    "section": "Task 2: Basic Data Frame Practice",
    "text": "Task 2: Basic Data Frame Practice\n\n1. Create dataframe\n\ndata &lt;- data.frame(\n  patient = names(pre_treatment),\n  pre_bp = pre_treatment,\n  post_bp = post_treatment,\n  diff_bp = delta,\n  row.names=NULL\n)\nhead(data, 1)\n\n    patient pre_bp post_bp diff_bp\n1 Subject_1    120     127      -7\n\n\n\n\n2. Show where diff_bp is negative\n\ndata[data$diff_bp &lt; 0,]\n\n      patient pre_bp post_bp diff_bp\n1   Subject_1    120     127      -7\n3   Subject_3    125     135     -10\n11 Subject_11    127     132      -5\n12 Subject_12    122     146     -24\n\n\n\n\n3. Add new column where post_bp is less than 120 (T/F)\n\ndata$\"post_bp &lt; 120\" = data$post_bp &lt; 120\ndata\n\n      patient pre_bp post_bp diff_bp post_bp &lt; 120\n1   Subject_1    120     127      -7         FALSE\n2   Subject_2    151     145       6         FALSE\n3   Subject_3    125     135     -10         FALSE\n4   Subject_4    126     122       4         FALSE\n5   Subject_5    115     115       0          TRUE\n6   Subject_6    132     122      10         FALSE\n7   Subject_7    132     123       9         FALSE\n8   Subject_8    129     126       3         FALSE\n9   Subject_9    134     126       8         FALSE\n10 Subject_10    139     129      10         FALSE\n11 Subject_11    127     132      -5         FALSE\n12 Subject_12    122     146     -24         FALSE\n13 Subject_13    127     120       7         FALSE\n14 Subject_14    135     114      21          TRUE\n15 Subject_15    133     121      12         FALSE\n16 Subject_16    128     120       8         FALSE\n17 Subject_17    147     128      19         FALSE\n18 Subject_18    138     120      18         FALSE\n19 Subject_19    140     133       7         FALSE\n20 Subject_20    132     115      17          TRUE\n\n\n\n\n4. Pretty print view using provided function\n\nknitr::kable(data, align='c', caption = \"Patient Treatment BP effect\")\n\n\nPatient Treatment BP effect\n\n\npatient\npre_bp\npost_bp\ndiff_bp\npost_bp &lt; 120\n\n\n\n\nSubject_1\n120\n127\n-7\nFALSE\n\n\nSubject_2\n151\n145\n6\nFALSE\n\n\nSubject_3\n125\n135\n-10\nFALSE\n\n\nSubject_4\n126\n122\n4\nFALSE\n\n\nSubject_5\n115\n115\n0\nTRUE\n\n\nSubject_6\n132\n122\n10\nFALSE\n\n\nSubject_7\n132\n123\n9\nFALSE\n\n\nSubject_8\n129\n126\n3\nFALSE\n\n\nSubject_9\n134\n126\n8\nFALSE\n\n\nSubject_10\n139\n129\n10\nFALSE\n\n\nSubject_11\n127\n132\n-5\nFALSE\n\n\nSubject_12\n122\n146\n-24\nFALSE\n\n\nSubject_13\n127\n120\n7\nFALSE\n\n\nSubject_14\n135\n114\n21\nTRUE\n\n\nSubject_15\n133\n121\n12\nFALSE\n\n\nSubject_16\n128\n120\n8\nFALSE\n\n\nSubject_17\n147\n128\n19\nFALSE\n\n\nSubject_18\n138\n120\n18\nFALSE\n\n\nSubject_19\n140\n133\n7\nFALSE\n\n\nSubject_20\n132\n115\n17\nTRUE"
  },
  {
    "objectID": "homeworks/Homework_2.html#task-3-list-practice",
    "href": "homeworks/Homework_2.html#task-3-list-practice",
    "title": "Homework 2",
    "section": "Task 3: List Practice",
    "text": "Task 3: List Practice\n\n1. Create similar dataframe to Task 2\n\ndf &lt;- data.frame(\n  patient = paste(\"Subject\", 1:10, sep = \"_\"),\n  pre_bp = c(138, 135, 147, 117, 152, 134, 114, 121, 131, 130),\n  post_bp = c(105, 136, 123, 130, 134, 143, 135, 139, 120, 124),\n  row.names = NULL\n)\ndf$diff_bp &lt;- df$pre_bp - df$post_bp\ndf$\"post_bp &lt; 120\" &lt;- df$post_bp &lt; 120\nrbind(data_subj = head(data, 2), df_subj = head(df, 2))\n\n              patient pre_bp post_bp diff_bp post_bp &lt; 120\ndata_subj.1 Subject_1    120     127      -7         FALSE\ndata_subj.2 Subject_2    151     145       6         FALSE\ndf_subj.1   Subject_1    138     105      33          TRUE\ndf_subj.2   Subject_2    135     136      -1         FALSE\n\n\n\n\n2. Store the 2 data frames into a list.\n\nmy_list &lt;- list(treatment=data, placebo=df)\nmy_list\n\n$treatment\n      patient pre_bp post_bp diff_bp post_bp &lt; 120\n1   Subject_1    120     127      -7         FALSE\n2   Subject_2    151     145       6         FALSE\n3   Subject_3    125     135     -10         FALSE\n4   Subject_4    126     122       4         FALSE\n5   Subject_5    115     115       0          TRUE\n6   Subject_6    132     122      10         FALSE\n7   Subject_7    132     123       9         FALSE\n8   Subject_8    129     126       3         FALSE\n9   Subject_9    134     126       8         FALSE\n10 Subject_10    139     129      10         FALSE\n11 Subject_11    127     132      -5         FALSE\n12 Subject_12    122     146     -24         FALSE\n13 Subject_13    127     120       7         FALSE\n14 Subject_14    135     114      21          TRUE\n15 Subject_15    133     121      12         FALSE\n16 Subject_16    128     120       8         FALSE\n17 Subject_17    147     128      19         FALSE\n18 Subject_18    138     120      18         FALSE\n19 Subject_19    140     133       7         FALSE\n20 Subject_20    132     115      17          TRUE\n\n$placebo\n      patient pre_bp post_bp diff_bp post_bp &lt; 120\n1   Subject_1    138     105      33          TRUE\n2   Subject_2    135     136      -1         FALSE\n3   Subject_3    147     123      24         FALSE\n4   Subject_4    117     130     -13         FALSE\n5   Subject_5    152     134      18         FALSE\n6   Subject_6    134     143      -9         FALSE\n7   Subject_7    114     135     -21         FALSE\n8   Subject_8    121     139     -18         FALSE\n9   Subject_9    131     120      11         FALSE\n10 Subject_10    130     124       6         FALSE\n\n\n\n\n3. Access the first item 3 different ways.\n\nhead(my_list[1], 1) # keeps as list (will show entire item)\n\n$treatment\n      patient pre_bp post_bp diff_bp post_bp &lt; 120\n1   Subject_1    120     127      -7         FALSE\n2   Subject_2    151     145       6         FALSE\n3   Subject_3    125     135     -10         FALSE\n4   Subject_4    126     122       4         FALSE\n5   Subject_5    115     115       0          TRUE\n6   Subject_6    132     122      10         FALSE\n7   Subject_7    132     123       9         FALSE\n8   Subject_8    129     126       3         FALSE\n9   Subject_9    134     126       8         FALSE\n10 Subject_10    139     129      10         FALSE\n11 Subject_11    127     132      -5         FALSE\n12 Subject_12    122     146     -24         FALSE\n13 Subject_13    127     120       7         FALSE\n14 Subject_14    135     114      21          TRUE\n15 Subject_15    133     121      12         FALSE\n16 Subject_16    128     120       8         FALSE\n17 Subject_17    147     128      19         FALSE\n18 Subject_18    138     120      18         FALSE\n19 Subject_19    140     133       7         FALSE\n20 Subject_20    132     115      17          TRUE\n\nhead(my_list[[1]], 1) # grabs the value at the list position, giving a dataframe - head prints out the first item of df\n\n    patient pre_bp post_bp diff_bp post_bp &lt; 120\n1 Subject_1    120     127      -7         FALSE\n\nhead(my_list$treatment, 1) # same thing, different way of getting the dataframe\n\n    patient pre_bp post_bp diff_bp post_bp &lt; 120\n1 Subject_1    120     127      -7         FALSE\n\n\n\n\n4. From list created in question 2, access pre_bp column of placebo list data. Maintaining as df column, as opposed to $pre_bp vector.\n\nmy_list$placebo[\"pre_bp\"]\n\n   pre_bp\n1     138\n2     135\n3     147\n4     117\n5     152\n6     134\n7     114\n8     121\n9     131\n10    130"
  }
]