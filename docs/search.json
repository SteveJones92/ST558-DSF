[
  {
    "objectID": "homeworks/Homework_1.html",
    "href": "homeworks/Homework_1.html",
    "title": "Homework 1",
    "section": "",
    "text": "What do you think being a data scientist is about?\nA data scientist is someone who focuses on the process of integrating computers with statistics and business needs. They have a specialization of computing software to be able to gain insights from data, many times in an automated fashion for use with software.\n\n\nWhat differences/similarities do you see between data scientists and statisticians?\nI view it as starting on the same path and diverging at some point. The root is in statistics, but a statistician will continue with more of the rigor of the field directly, whereas a data scientist will begin to branch off more into the software/development process and application side of things.\nSimilarities:\n\nFoundational Knowledge\nTool Use\n\nDifferences:\n\nSpecialized Knowledge\nDevelopment Process\n\n\n\nHow do you view yourself in relation to these two areas?\nI am much closer to a data scientist. I have exposure to statistics, but as portions of CSC courses. I have had many courses on directly attributed data science topics and I work in software.\n\n\nSetting y variable using a column of the iris dataset and density function\n\ny &lt;- density(iris$Petal.Width)\n\n\n\n\nChecking the class, type, and structure of y\n\nclass(y)\n\n[1] \"density\"\n\ntypeof(y)\n\n[1] \"list\"\n\nstr(y)\n\nList of 8\n $ x         : num [1:512] -0.656 -0.648 -0.64 -0.633 -0.625 ...\n $ y         : num [1:512] 0.00161 0.00178 0.00197 0.00217 0.00239 ...\n $ bw        : num 0.252\n $ n         : int 150\n $ old.coords: logi FALSE\n $ call      : language density.default(x = iris$Petal.Width)\n $ data.name : chr \"iris$Petal.Width\"\n $ has.na    : logi FALSE\n - attr(*, \"class\")= chr \"density\"\n\n\n\n\n\nPlotting y, with code hidden with echo=FALSE"
  },
  {
    "objectID": "homeworks/Homework_3.html#load-data-from-data-folder",
    "href": "homeworks/Homework_3.html#load-data-from-data-folder",
    "title": "Homework 3",
    "section": "Load data from data folder",
    "text": "Load data from data folder\n\nload(\"../data/hw3/hw2_list.rda\")"
  },
  {
    "objectID": "homeworks/Homework_3.html#task-1-control-flow-practice",
    "href": "homeworks/Homework_3.html#task-1-control-flow-practice",
    "title": "Homework 3",
    "section": "Task 1: Control Flow Practice",
    "text": "Task 1: Control Flow Practice\n\nCreate the status column in both.\n\nbp_list$treatment$status &lt;- character(nrow(bp_list$treatment))\nbp_list$placebo$status &lt;- character(nrow(bp_list$placebo))\n\n\n\nFill the treatment with appropriate strings for status\n\nfor (i in 1:nrow(bp_list$treatment)) {\n  val &lt;- bp_list$treatment[i, \"post_bp\"]\n  bp_str &lt;- \"\"\n  if (val &lt;= 120) {\n    bp_str &lt;- \"optimal\"\n  } else if (val &lt;= 130) {\n    bp_str &lt;- \"borderline\"\n  } else {\n    bp_str &lt;- \"high\"\n  }\n  bp_list$treatment[i, \"status\"] &lt;- bp_str\n}\nbp_list$treatment$status\n\n [1] \"borderline\" \"high\"       \"high\"       \"borderline\" \"optimal\"   \n [6] \"borderline\" \"borderline\" \"borderline\" \"borderline\" \"borderline\"\n[11] \"high\"       \"high\"       \"optimal\"    \"optimal\"    \"borderline\"\n[16] \"optimal\"    \"borderline\" \"optimal\"    \"high\"       \"optimal\"   \n\n\n\n\nFill the placebo with the appropriate string for status\n\nbp_list$placebo$status &lt;- ifelse(bp_list$placebo$post_bp &lt;= 120, \"optimal\", ifelse(bp_list$placebo$post_bp &lt;= 130, \"borderline\", \"high\"))\nbp_list$placebo$status\n\n [1] \"optimal\"    \"high\"       \"borderline\" \"borderline\" \"high\"      \n [6] \"high\"       \"high\"       \"high\"       \"optimal\"    \"borderline\""
  },
  {
    "objectID": "homeworks/Homework_3.html#task-2-function-writing",
    "href": "homeworks/Homework_3.html#task-2-function-writing",
    "title": "Homework 3",
    "section": "Task 2: Function Writing",
    "text": "Task 2: Function Writing\n\nBuild a useful function for the previous usage\n\nmy_func &lt;- function(lst, summary_func=\"mean\") {\n  # lst needs to be a list with 2 dataframes\n  if (!all(is.list(lst), length(lst) == 2, all(sapply(lst, is.data.frame)))) {\n    stop(\"Not a list of 2 data frames\")\n  }\n  # summary_func needs to be one of a set of summary functions (var, sd, min, max, mean)\n  summary_funcs &lt;- c(\"var\", \"sd\", \"min\", \"max\", \"mean\")\n  if (!(summary_func %in% summary_funcs)) {\n    stop(\"Not a function\")\n  }\n  summary_function &lt;- get(summary_func)\n  \n  # lists need to contain pre, post, and diff columns\n  cols &lt;- c(\"pre_bp\", \"post_bp\", \"diff_bp\")\n  if (!all(sapply(lst, function(df) all(cols %in% colnames(df))))) {\n    stop(\"Dataframes don't have the required columns of pre_bp, post_bp, and diff_bp\")\n  }\n  \n  return(lapply(lst, function(df) {\n    result &lt;-sapply(df[cols], summary_function)\n    names(result) &lt;- paste(names(result), summary_func, sep=\"_\")\n    return(result)\n  }))\n}\n\n\n\nApply the function to bp_list with default param, and the other summary funcs\n\nprint(\"default: mean\")\n\n[1] \"default: mean\"\n\nmy_func(bp_list)\n\n$treatment\n pre_bp_mean post_bp_mean diff_bp_mean \n      131.60       125.95         5.65 \n\n$placebo\n pre_bp_mean post_bp_mean diff_bp_mean \n       131.9        128.9          3.0 \n\nfor (summary_func in c(\"var\", \"sd\", \"min\", \"max\")) {\n  print(summary_func)\n  print(my_func(bp_list, summary_func))\n}\n\n[1] \"var\"\n$treatment\n pre_bp_var post_bp_var diff_bp_var \n   75.72632    78.99737   117.81842 \n\n$placebo\n pre_bp_var post_bp_var diff_bp_var \n   149.8778    124.9889    341.3333 \n\n[1] \"sd\"\n$treatment\n pre_bp_sd post_bp_sd diff_bp_sd \n  8.702087   8.888046  10.854419 \n\n$placebo\n pre_bp_sd post_bp_sd diff_bp_sd \n  12.24246   11.17984   18.47521 \n\n[1] \"min\"\n$treatment\n pre_bp_min post_bp_min diff_bp_min \n        115         114         -24 \n\n$placebo\n pre_bp_min post_bp_min diff_bp_min \n        114         105         -21 \n\n[1] \"max\"\n$treatment\n pre_bp_max post_bp_max diff_bp_max \n        151         146          21 \n\n$placebo\n pre_bp_max post_bp_max diff_bp_max \n        152         143          33"
  },
  {
    "objectID": "homeworks/Homework_4.html",
    "href": "homeworks/Homework_4.html",
    "title": "Homework 4",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "homeworks/Homework_4.html#task-1-conceptual-questions",
    "href": "homeworks/Homework_4.html#task-1-conceptual-questions",
    "title": "Homework 4",
    "section": "Task 1: Conceptual Questions",
    "text": "Task 1: Conceptual Questions\n\nIf your working directory is myfolder/homework/, what relative path would you specify to get the file located at myfolder/MyDate.csv?\n\n\nYou would back out of the /homework/ folder with .. and you would be looking at the myfolder directory where MyData.csv is located.\n\n\nWhat are the major benefits of using R projects?\n\n\nAn R project allows creating a structured R directory that can be easier to work with and share with others. The entire directory can simply be loaded and ran by others.\n\n\nWhat is git and what is github?\n\n\ngit is version control. github is an online repository that uses git for version control. This allows for much better code and file editing that will preserve prior work and also allows collaborating with others much easier.\n\n\nWhat are the two main differences between a tibble and a data.frame?\n\n\nA data.frame is a BaseR structure. A tibble is tidyverse structure that is like a dataframe, but has more complaining and more limitations.\n\n\nRewrite the following nested function call, using BaseR’s chaining operator:\n\narrange(filter(select(as_tibble(iris), starts_with(\"Petal\"), Species), Petal.Length &lt; 1.55), Species)\n\niris |&gt;\n  as_tibble() |&gt;\n  select(starts_with(\"Petal\"), Species) |&gt;\n  filter(Petal.Length &lt; 1.55) |&gt;\n  arrange(Species)\n\n# A tibble: 37 × 3\n   Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n 1          1.4         0.2 setosa \n 2          1.4         0.2 setosa \n 3          1.3         0.2 setosa \n 4          1.5         0.2 setosa \n 5          1.4         0.2 setosa \n 6          1.4         0.3 setosa \n 7          1.5         0.2 setosa \n 8          1.4         0.2 setosa \n 9          1.5         0.1 setosa \n10          1.5         0.2 setosa \n# ℹ 27 more rows"
  },
  {
    "objectID": "homeworks/Homework_4.html#task-2-reading-delimited-data",
    "href": "homeworks/Homework_4.html#task-2-reading-delimited-data",
    "title": "Homework 4",
    "section": "Task 2: Reading Delimited Data",
    "text": "Task 2: Reading Delimited Data\n\nGlass Data\nRead in the csv file, adding the given column names.\n\n# glass_data &lt;- read_csv(\"../data/hw4/glass.data\", col_names = c(\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\"))\nglass_data &lt;- read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/glass.data\", col_names = c(\"Id\", \"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\", \"Type\"), show_col_types = FALSE)\nglass_data\n\n# A tibble: 214 × 11\n      Id    RI    Na    Mg    Al    Si     K    Ca    Ba    Fe  Type\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1  1.52  13.6  4.49  1.1   71.8  0.06  8.75     0  0        1\n 2     2  1.52  13.9  3.6   1.36  72.7  0.48  7.83     0  0        1\n 3     3  1.52  13.5  3.55  1.54  73.0  0.39  7.78     0  0        1\n 4     4  1.52  13.2  3.69  1.29  72.6  0.57  8.22     0  0        1\n 5     5  1.52  13.3  3.62  1.24  73.1  0.55  8.07     0  0        1\n 6     6  1.52  12.8  3.61  1.62  73.0  0.64  8.07     0  0.26     1\n 7     7  1.52  13.3  3.6   1.14  73.1  0.58  8.17     0  0        1\n 8     8  1.52  13.2  3.61  1.05  73.2  0.57  8.24     0  0        1\n 9     9  1.52  14.0  3.58  1.37  72.1  0.56  8.3      0  0        1\n10    10  1.52  13    3.6   1.36  73.0  0.57  8.4      0  0.11     1\n# ℹ 204 more rows\n\n\nChain update the glass_data.\n\nglass_data_updated &lt;- glass_data |&gt;\n  mutate(Type = case_when(\n    Type == 1 ~ \"building_windows_float_processed\",\n    Type == 2 ~ \"building_windows_non_float_processed\",\n    Type == 3 ~ \"vehicle_windows_float_processed\",\n    Type == 4 ~ \"vehicle_windows_non_float_processed\",\n    Type == 5 ~ \"containers\",\n    Type == 6 ~ \"tableware\",\n    Type == 7 ~ \"headlamps\"\n  )) |&gt;\n  filter(Fe &lt; 0.2, Type %in% c(\"tableware\", \"headlamps\"))\nglass_data_updated\n\n# A tibble: 38 × 11\n      Id    RI    Na    Mg    Al    Si     K    Ca    Ba    Fe Type     \n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    \n 1   177  1.52  14    2.39  1.56  72.4  0     9.57  0        0 tableware\n 2   178  1.52  13.8  2.41  1.19  72.8  0     9.77  0        0 tableware\n 3   179  1.52  14.5  2.24  1.62  72.4  0     9.26  0        0 tableware\n 4   180  1.52  14.1  2.19  1.66  72.7  0     9.32  0        0 tableware\n 5   181  1.51  14.4  1.74  1.54  74.6  0     7.59  0        0 tableware\n 6   182  1.52  15.0  0.78  1.74  72.5  0     9.95  0        0 tableware\n 7   183  1.52  14.2  0     2.09  72.7  0    10.9   0        0 tableware\n 8   184  1.52  14.6  0     0.56  73.5  0    11.2   0        0 tableware\n 9   185  1.51  17.4  0     0.34  75.4  0     6.65  0        0 tableware\n10   186  1.51  13.7  3.2   1.81  72.8  1.76  5.43  1.19     0 headlamps\n# ℹ 28 more rows\n\n\n\n\nYeast Data\nRead in the fixed width file, adding given column names.\n\n# yeast_data &lt;- read_fwf(\"../data/hw4/yeast.data\", fwf_widths(c(12,6,6,6,6,6,6,6,6,6), c(\"seq_nam\", \"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\", \"class\")))\nyeast_data &lt;- read_fwf(\"https://www4.stat.ncsu.edu/~online/datasets/yeast.data\", fwf_widths(c(12,6,6,6,6,6,6,6,6,6), c(\"seq_nam\", \"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\", \"class\")), show_col_types = FALSE)\nyeast_data\n\n# A tibble: 1,484 × 10\n   seq_nam      mcg   gvh   alm   mit   erl   pox   vac   nuc class\n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n 1 ADT1_YEAST  0.58  0.61  0.47  0.13   0.5   0    0.48  0.22 MIT  \n 2 ADT2_YEAST  0.43  0.67  0.48  0.27   0.5   0    0.53  0.22 MIT  \n 3 ADT3_YEAST  0.64  0.62  0.49  0.15   0.5   0    0.53  0.22 MIT  \n 4 AAR2_YEAST  0.58  0.44  0.57  0.13   0.5   0    0.54  0.22 NUC  \n 5 AATM_YEAST  0.42  0.44  0.48  0.54   0.5   0    0.48  0.22 MIT  \n 6 AATC_YEAST  0.51  0.4   0.56  0.17   0.5   0.5  0.49  0.22 CYT  \n 7 ABC1_YEAST  0.5   0.54  0.48  0.65   0.5   0    0.53  0.22 MIT  \n 8 BAF1_YEAST  0.48  0.45  0.59  0.2    0.5   0    0.58  0.34 NUC  \n 9 ABF2_YEAST  0.55  0.5   0.66  0.36   0.5   0    0.49  0.22 MIT  \n10 ABP1_YEAST  0.4   0.39  0.6   0.15   0.5   0    0.58  0.3  CYT  \n# ℹ 1,474 more rows\n\n\nChain update the yeast_data.\n\nyeast_data_updated &lt;- yeast_data |&gt;\n  select(-seq_nam & -nuc) |&gt;\n  group_by(class) |&gt;\n  mutate(across(where(is.numeric), list(mean=mean, median=median), .names = \"{.col}_{.fn}\"))\nyeast_data_updated\n\n# A tibble: 1,484 × 22\n# Groups:   class [10]\n     mcg   gvh   alm   mit   erl   pox   vac class mcg_mean mcg_median gvh_mean\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.58  0.61  0.47  0.13   0.5   0    0.48 MIT      0.521       0.51    0.533\n 2  0.43  0.67  0.48  0.27   0.5   0    0.53 MIT      0.521       0.51    0.533\n 3  0.64  0.62  0.49  0.15   0.5   0    0.53 MIT      0.521       0.51    0.533\n 4  0.58  0.44  0.57  0.13   0.5   0    0.54 NUC      0.452       0.45    0.456\n 5  0.42  0.44  0.48  0.54   0.5   0    0.48 MIT      0.521       0.51    0.533\n 6  0.51  0.4   0.56  0.17   0.5   0.5  0.49 CYT      0.481       0.48    0.470\n 7  0.5   0.54  0.48  0.65   0.5   0    0.53 MIT      0.521       0.51    0.533\n 8  0.48  0.45  0.59  0.2    0.5   0    0.58 NUC      0.452       0.45    0.456\n 9  0.55  0.5   0.66  0.36   0.5   0    0.49 MIT      0.521       0.51    0.533\n10  0.4   0.39  0.6   0.15   0.5   0    0.58 CYT      0.481       0.48    0.470\n# ℹ 1,474 more rows\n# ℹ 11 more variables: gvh_median &lt;dbl&gt;, alm_mean &lt;dbl&gt;, alm_median &lt;dbl&gt;,\n#   mit_mean &lt;dbl&gt;, mit_median &lt;dbl&gt;, erl_mean &lt;dbl&gt;, erl_median &lt;dbl&gt;,\n#   pox_mean &lt;dbl&gt;, pox_median &lt;dbl&gt;, vac_mean &lt;dbl&gt;, vac_median &lt;dbl&gt;"
  },
  {
    "objectID": "homeworks/Homework_4.html#task-3-combining-excel-and-delimited-data",
    "href": "homeworks/Homework_4.html#task-3-combining-excel-and-delimited-data",
    "title": "Homework 4",
    "section": "Task 3: Combining Excel and Delimited Data",
    "text": "Task 3: Combining Excel and Delimited Data\nRead in the excel first sheet for white wine.\n\nwhite_wine_data &lt;- read_excel(\"../data/hw4/white-wine.xlsx\", sheet = 1)\nwhite_wine_data\n\n# A tibble: 4,898 × 12\n   `fixed acidity` `volatile acidity` `citric acid` `residual sugar` chlorides\n             &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1               7               0.27          0.36             20.7     0.045\n 2              63               0.3           0.34              1.6     0.049\n 3              81               0.28          0.4               6.9     0.05 \n 4              72               0.23          0.32              8.5     0.058\n 5              72               0.23          0.32              8.5     0.058\n 6              81               0.28          0.4               6.9     0.05 \n 7              62               0.32          0.16              7       0.045\n 8               7               0.27          0.36             20.7     0.045\n 9              63               0.3           0.34              1.6     0.049\n10              81               0.22          0.43              1.5     0.044\n# ℹ 4,888 more rows\n# ℹ 7 more variables: `free sulfur dioxide` &lt;dbl&gt;,\n#   `total sulfur dioxide` &lt;dbl&gt;, density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;,\n#   alcohol &lt;dbl&gt;, quality &lt;dbl&gt;\n\n\nFix the column names from the second sheet.\n\ncol_names &lt;- read_excel(\"../data/hw4/white-wine.xlsx\", sheet = 2) |&gt; pull()\ncolnames(white_wine_data) &lt;- col_names\nwhite_wine_data\n\n# A tibble: 4,898 × 12\n   fixed_acidity volatile_acidity citric_acid residual_sugar chlorides\n           &lt;dbl&gt;            &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1             7             0.27        0.36           20.7     0.045\n 2            63             0.3         0.34            1.6     0.049\n 3            81             0.28        0.4             6.9     0.05 \n 4            72             0.23        0.32            8.5     0.058\n 5            72             0.23        0.32            8.5     0.058\n 6            81             0.28        0.4             6.9     0.05 \n 7            62             0.32        0.16            7       0.045\n 8             7             0.27        0.36           20.7     0.045\n 9            63             0.3         0.34            1.6     0.049\n10            81             0.22        0.43            1.5     0.044\n# ℹ 4,888 more rows\n# ℹ 7 more variables: free_sulfur_dioxide &lt;dbl&gt;, total_sulfur_dioxide &lt;dbl&gt;,\n#   density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;, alcohol &lt;dbl&gt;, quality &lt;dbl&gt;\n\n\nAdd white column.\n\nwhite_wine_data$wine_type &lt;- \"white\"\n\nRead in delimited data for red wine.\n\nred_wine_data &lt;- readr::read_delim(\"../data/hw4/red-wine.csv\", delim=';', show_col_types = FALSE)\nred_wine_data\n\n# A tibble: 1,599 × 12\n   `fixed acidity` `volatile acidity` `citric acid` `residual sugar` chlorides\n             &lt;dbl&gt;              &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1             7.4               0.7           0                 1.9     0.076\n 2             7.8               0.88          0                 2.6     0.098\n 3             7.8               0.76          0.04              2.3     0.092\n 4            11.2               0.28          0.56              1.9     0.075\n 5             7.4               0.7           0                 1.9     0.076\n 6             7.4               0.66          0                 1.8     0.075\n 7             7.9               0.6           0.06              1.6     0.069\n 8             7.3               0.65          0                 1.2     0.065\n 9             7.8               0.58          0.02              2       0.073\n10             7.5               0.5           0.36              6.1     0.071\n# ℹ 1,589 more rows\n# ℹ 7 more variables: `free sulfur dioxide` &lt;dbl&gt;,\n#   `total sulfur dioxide` &lt;dbl&gt;, density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;,\n#   alcohol &lt;dbl&gt;, quality &lt;dbl&gt;\n\n\nUpdate the column names and add the red column.\n\ncolnames(red_wine_data) &lt;- col_names\nred_wine_data$wine_type &lt;- \"red\"\nred_wine_data\n\n# A tibble: 1,599 × 13\n   fixed_acidity volatile_acidity citric_acid residual_sugar chlorides\n           &lt;dbl&gt;            &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1           7.4             0.7         0               1.9     0.076\n 2           7.8             0.88        0               2.6     0.098\n 3           7.8             0.76        0.04            2.3     0.092\n 4          11.2             0.28        0.56            1.9     0.075\n 5           7.4             0.7         0               1.9     0.076\n 6           7.4             0.66        0               1.8     0.075\n 7           7.9             0.6         0.06            1.6     0.069\n 8           7.3             0.65        0               1.2     0.065\n 9           7.8             0.58        0.02            2       0.073\n10           7.5             0.5         0.36            6.1     0.071\n# ℹ 1,589 more rows\n# ℹ 8 more variables: free_sulfur_dioxide &lt;dbl&gt;, total_sulfur_dioxide &lt;dbl&gt;,\n#   density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;, alcohol &lt;dbl&gt;, quality &lt;dbl&gt;,\n#   wine_type &lt;chr&gt;\n\n\nCombine the datasets into one wine dataset.\n\nwine_data &lt;- dplyr::bind_rows(white_wine_data, red_wine_data)\nwine_data\n\n# A tibble: 6,497 × 13\n   fixed_acidity volatile_acidity citric_acid residual_sugar chlorides\n           &lt;dbl&gt;            &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1             7             0.27        0.36           20.7     0.045\n 2            63             0.3         0.34            1.6     0.049\n 3            81             0.28        0.4             6.9     0.05 \n 4            72             0.23        0.32            8.5     0.058\n 5            72             0.23        0.32            8.5     0.058\n 6            81             0.28        0.4             6.9     0.05 \n 7            62             0.32        0.16            7       0.045\n 8             7             0.27        0.36           20.7     0.045\n 9            63             0.3         0.34            1.6     0.049\n10            81             0.22        0.43            1.5     0.044\n# ℹ 6,487 more rows\n# ℹ 8 more variables: free_sulfur_dioxide &lt;dbl&gt;, total_sulfur_dioxide &lt;dbl&gt;,\n#   density &lt;dbl&gt;, pH &lt;dbl&gt;, sulphates &lt;dbl&gt;, alcohol &lt;dbl&gt;, quality &lt;dbl&gt;,\n#   wine_type &lt;chr&gt;\n\n\nChain update new wine data.\n\nwine_data_updated &lt;- wine_data |&gt;\n  filter(quality &gt; 6.5, alcohol &lt; 132) |&gt;\n  arrange(desc(quality)) |&gt;\n  select(contains(\"acid\"), alcohol, wine_type, quality) |&gt;\n  group_by(quality) |&gt;\n  mutate(across(where(is.numeric), list(mean=mean, stdev=sd), .names = \"{.col}_{.fn}\"))\nwine_data_updated\n\n# A tibble: 1,206 × 14\n# Groups:   quality [3]\n   fixed_acidity volatile_acidity citric_acid alcohol wine_type quality\n           &lt;dbl&gt;            &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1            91             0.27        0.45     104 white           9\n 2            66             0.36        0.29     124 white           9\n 3            74             0.24        0.36     125 white           9\n 4            69             0.36        0.34     127 white           9\n 5            71             0.26        0.49     129 white           9\n 6            62             0.66        0.48     128 white           8\n 7            62             0.66        0.48     128 white           8\n 8            68             0.26        0.42     105 white           8\n 9            67             0.23        0.31     107 white           8\n10            67             0.23        0.31     107 white           8\n# ℹ 1,196 more rows\n# ℹ 8 more variables: fixed_acidity_mean &lt;dbl&gt;, fixed_acidity_stdev &lt;dbl&gt;,\n#   volatile_acidity_mean &lt;dbl&gt;, volatile_acidity_stdev &lt;dbl&gt;,\n#   citric_acid_mean &lt;dbl&gt;, citric_acid_stdev &lt;dbl&gt;, alcohol_mean &lt;dbl&gt;,\n#   alcohol_stdev &lt;dbl&gt;"
  },
  {
    "objectID": "homeworks/Homework_2.html#task-1-basic-vector-practice",
    "href": "homeworks/Homework_2.html#task-1-basic-vector-practice",
    "title": "Homework 2",
    "section": "Task 1: Basic Vector Practice",
    "text": "Task 1: Basic Vector Practice\n\n1. Pre and Post treatment vectors\n\npre_treatment &lt;- c(120, 151, 125, 126, 115, 132, 132, 129, 134, 139, 127, 122, 127, 135, 133, 128, 147, 138, 140, 132)\n\npost_treatment &lt;- c(127, 145, 135, 122, 115, 122, 123, 126, 126, 129, 132, 146, 120, 114, 121, 120, 128, 120, 133, 115)\n\n\n\n2. Renamed each\n\nnames(pre_treatment) &lt;- paste(\"Subject\", 1:length(pre_treatment), sep = \"_\")\nnames(post_treatment) &lt;- paste(\"Subject\", 1:length(post_treatment), sep = \"_\")\n\npre_treatment\n\n Subject_1  Subject_2  Subject_3  Subject_4  Subject_5  Subject_6  Subject_7 \n       120        151        125        126        115        132        132 \n Subject_8  Subject_9 Subject_10 Subject_11 Subject_12 Subject_13 Subject_14 \n       129        134        139        127        122        127        135 \nSubject_15 Subject_16 Subject_17 Subject_18 Subject_19 Subject_20 \n       133        128        147        138        140        132 \n\npost_treatment\n\n Subject_1  Subject_2  Subject_3  Subject_4  Subject_5  Subject_6  Subject_7 \n       127        145        135        122        115        122        123 \n Subject_8  Subject_9 Subject_10 Subject_11 Subject_12 Subject_13 Subject_14 \n       126        126        129        132        146        120        114 \nSubject_15 Subject_16 Subject_17 Subject_18 Subject_19 Subject_20 \n       121        120        128        120        133        115 \n\n\n\n\n3. Difference from pre -&gt; post treatment\n\ndelta &lt;- pre_treatment - post_treatment\n\n\n\n4. Average change - positive value (positive outcome, blood pressure decreased on average by this amount)\n\nmean(delta)\n\n[1] 5.65\n\n\n\n\n5. Which subjects had a decreased blood pressure?\n\ndecrease &lt;- names(which(delta &gt; 0))\ndecrease\n\n [1] \"Subject_2\"  \"Subject_4\"  \"Subject_6\"  \"Subject_7\"  \"Subject_8\" \n [6] \"Subject_9\"  \"Subject_10\" \"Subject_13\" \"Subject_14\" \"Subject_15\"\n[11] \"Subject_16\" \"Subject_17\" \"Subject_18\" \"Subject_19\" \"Subject_20\"\n\n\n\n\n6. Which subjects had an decrease in blood pressure ( positive change, but as a subset vector)?\n\ndecrease_vector &lt;- delta[delta &gt; 0]\ndecrease_vector\n\n Subject_2  Subject_4  Subject_6  Subject_7  Subject_8  Subject_9 Subject_10 \n         6          4         10          9          3          8         10 \nSubject_13 Subject_14 Subject_15 Subject_16 Subject_17 Subject_18 Subject_19 \n         7         21         12          8         19         18          7 \nSubject_20 \n        17 \n\n\n\n\n7. What is the average decrease of blood pressure of those that had the positive change?\n\nmean(decrease_vector)\n\n[1] 10.6"
  },
  {
    "objectID": "homeworks/Homework_2.html#task-2-basic-data-frame-practice",
    "href": "homeworks/Homework_2.html#task-2-basic-data-frame-practice",
    "title": "Homework 2",
    "section": "Task 2: Basic Data Frame Practice",
    "text": "Task 2: Basic Data Frame Practice\n\n1. Create dataframe\n\ndata &lt;- data.frame(\n  patient = names(pre_treatment),\n  pre_bp = pre_treatment,\n  post_bp = post_treatment,\n  diff_bp = delta,\n  row.names=NULL\n)\nhead(data, 1)\n\n    patient pre_bp post_bp diff_bp\n1 Subject_1    120     127      -7\n\n\n\n\n2. Show where diff_bp is negative\n\ndata[data$diff_bp &lt; 0,]\n\n      patient pre_bp post_bp diff_bp\n1   Subject_1    120     127      -7\n3   Subject_3    125     135     -10\n11 Subject_11    127     132      -5\n12 Subject_12    122     146     -24\n\n\n\n\n3. Add new column where post_bp is less than 120 (T/F)\n\ndata$\"post_bp &lt; 120\" = data$post_bp &lt; 120\ndata\n\n      patient pre_bp post_bp diff_bp post_bp &lt; 120\n1   Subject_1    120     127      -7         FALSE\n2   Subject_2    151     145       6         FALSE\n3   Subject_3    125     135     -10         FALSE\n4   Subject_4    126     122       4         FALSE\n5   Subject_5    115     115       0          TRUE\n6   Subject_6    132     122      10         FALSE\n7   Subject_7    132     123       9         FALSE\n8   Subject_8    129     126       3         FALSE\n9   Subject_9    134     126       8         FALSE\n10 Subject_10    139     129      10         FALSE\n11 Subject_11    127     132      -5         FALSE\n12 Subject_12    122     146     -24         FALSE\n13 Subject_13    127     120       7         FALSE\n14 Subject_14    135     114      21          TRUE\n15 Subject_15    133     121      12         FALSE\n16 Subject_16    128     120       8         FALSE\n17 Subject_17    147     128      19         FALSE\n18 Subject_18    138     120      18         FALSE\n19 Subject_19    140     133       7         FALSE\n20 Subject_20    132     115      17          TRUE\n\n\n\n\n4. Pretty print view using provided function\n\nknitr::kable(data, align='c', caption = \"Patient Treatment BP effect\")\n\n\nPatient Treatment BP effect\n\n\npatient\npre_bp\npost_bp\ndiff_bp\npost_bp &lt; 120\n\n\n\n\nSubject_1\n120\n127\n-7\nFALSE\n\n\nSubject_2\n151\n145\n6\nFALSE\n\n\nSubject_3\n125\n135\n-10\nFALSE\n\n\nSubject_4\n126\n122\n4\nFALSE\n\n\nSubject_5\n115\n115\n0\nTRUE\n\n\nSubject_6\n132\n122\n10\nFALSE\n\n\nSubject_7\n132\n123\n9\nFALSE\n\n\nSubject_8\n129\n126\n3\nFALSE\n\n\nSubject_9\n134\n126\n8\nFALSE\n\n\nSubject_10\n139\n129\n10\nFALSE\n\n\nSubject_11\n127\n132\n-5\nFALSE\n\n\nSubject_12\n122\n146\n-24\nFALSE\n\n\nSubject_13\n127\n120\n7\nFALSE\n\n\nSubject_14\n135\n114\n21\nTRUE\n\n\nSubject_15\n133\n121\n12\nFALSE\n\n\nSubject_16\n128\n120\n8\nFALSE\n\n\nSubject_17\n147\n128\n19\nFALSE\n\n\nSubject_18\n138\n120\n18\nFALSE\n\n\nSubject_19\n140\n133\n7\nFALSE\n\n\nSubject_20\n132\n115\n17\nTRUE"
  },
  {
    "objectID": "homeworks/Homework_2.html#task-3-list-practice",
    "href": "homeworks/Homework_2.html#task-3-list-practice",
    "title": "Homework 2",
    "section": "Task 3: List Practice",
    "text": "Task 3: List Practice\n\n1. Create similar dataframe to Task 2\n\ndf &lt;- data.frame(\n  patient = paste(\"Subject\", 1:10, sep = \"_\"),\n  pre_bp = c(138, 135, 147, 117, 152, 134, 114, 121, 131, 130),\n  post_bp = c(105, 136, 123, 130, 134, 143, 135, 139, 120, 124),\n  row.names = NULL\n)\ndf$diff_bp &lt;- df$pre_bp - df$post_bp\ndf$\"post_bp &lt; 120\" &lt;- df$post_bp &lt; 120\nrbind(data_subj = head(data, 2), df_subj = head(df, 2))\n\n              patient pre_bp post_bp diff_bp post_bp &lt; 120\ndata_subj.1 Subject_1    120     127      -7         FALSE\ndata_subj.2 Subject_2    151     145       6         FALSE\ndf_subj.1   Subject_1    138     105      33          TRUE\ndf_subj.2   Subject_2    135     136      -1         FALSE\n\n\n\n\n2. Store the 2 data frames into a list.\n\nmy_list &lt;- list(treatment=data, placebo=df)\nmy_list\n\n$treatment\n      patient pre_bp post_bp diff_bp post_bp &lt; 120\n1   Subject_1    120     127      -7         FALSE\n2   Subject_2    151     145       6         FALSE\n3   Subject_3    125     135     -10         FALSE\n4   Subject_4    126     122       4         FALSE\n5   Subject_5    115     115       0          TRUE\n6   Subject_6    132     122      10         FALSE\n7   Subject_7    132     123       9         FALSE\n8   Subject_8    129     126       3         FALSE\n9   Subject_9    134     126       8         FALSE\n10 Subject_10    139     129      10         FALSE\n11 Subject_11    127     132      -5         FALSE\n12 Subject_12    122     146     -24         FALSE\n13 Subject_13    127     120       7         FALSE\n14 Subject_14    135     114      21          TRUE\n15 Subject_15    133     121      12         FALSE\n16 Subject_16    128     120       8         FALSE\n17 Subject_17    147     128      19         FALSE\n18 Subject_18    138     120      18         FALSE\n19 Subject_19    140     133       7         FALSE\n20 Subject_20    132     115      17          TRUE\n\n$placebo\n      patient pre_bp post_bp diff_bp post_bp &lt; 120\n1   Subject_1    138     105      33          TRUE\n2   Subject_2    135     136      -1         FALSE\n3   Subject_3    147     123      24         FALSE\n4   Subject_4    117     130     -13         FALSE\n5   Subject_5    152     134      18         FALSE\n6   Subject_6    134     143      -9         FALSE\n7   Subject_7    114     135     -21         FALSE\n8   Subject_8    121     139     -18         FALSE\n9   Subject_9    131     120      11         FALSE\n10 Subject_10    130     124       6         FALSE\n\n\n\n\n3. Access the first item 3 different ways.\n\nhead(my_list[1], 1) # keeps as list (will show entire item)\n\n$treatment\n      patient pre_bp post_bp diff_bp post_bp &lt; 120\n1   Subject_1    120     127      -7         FALSE\n2   Subject_2    151     145       6         FALSE\n3   Subject_3    125     135     -10         FALSE\n4   Subject_4    126     122       4         FALSE\n5   Subject_5    115     115       0          TRUE\n6   Subject_6    132     122      10         FALSE\n7   Subject_7    132     123       9         FALSE\n8   Subject_8    129     126       3         FALSE\n9   Subject_9    134     126       8         FALSE\n10 Subject_10    139     129      10         FALSE\n11 Subject_11    127     132      -5         FALSE\n12 Subject_12    122     146     -24         FALSE\n13 Subject_13    127     120       7         FALSE\n14 Subject_14    135     114      21          TRUE\n15 Subject_15    133     121      12         FALSE\n16 Subject_16    128     120       8         FALSE\n17 Subject_17    147     128      19         FALSE\n18 Subject_18    138     120      18         FALSE\n19 Subject_19    140     133       7         FALSE\n20 Subject_20    132     115      17          TRUE\n\nhead(my_list[[1]], 1) # grabs the value at the list position, giving a dataframe - head prints out the first item of df\n\n    patient pre_bp post_bp diff_bp post_bp &lt; 120\n1 Subject_1    120     127      -7         FALSE\n\nhead(my_list$treatment, 1) # same thing, different way of getting the dataframe\n\n    patient pre_bp post_bp diff_bp post_bp &lt; 120\n1 Subject_1    120     127      -7         FALSE\n\n\n\n\n4. From list created in question 2, access pre_bp column of placebo list data. Maintaining as df column, as opposed to $pre_bp vector.\n\nmy_list$placebo[\"pre_bp\"]\n\n   pre_bp\n1     138\n2     135\n3     147\n4     117\n5     152\n6     134\n7     114\n8     121\n9     131\n10    130"
  },
  {
    "objectID": "homeworks/Homework_5.html",
    "href": "homeworks/Homework_5.html",
    "title": "Homework 5",
    "section": "",
    "text": "library(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nread_method_1 &lt;- function() {\n  d1 &lt;- read.table(\"../../data/hw5/student-mat.csv\", sep=\";\", header=TRUE)\n  d2 &lt;- read.table(\"../../data/hw5/student-por.csv\", sep=\";\", header=TRUE)\n\n  d3 &lt;- merge(d1,d2,by=c(\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"))\n  return (d3)\n}\n\nread_method_2 &lt;- function() {\n  d1 &lt;- read_delim(\"../../data/hw5/student-mat.csv\", delim=\";\")\n  d2 &lt;- read_delim(\"../../data/hw5/student-por.csv\", delim=\";\")\n\n  join_on_columns &lt;- names(d1)[!names(d1) %in% c(\"G1\", \"G2\", \"G3\", \"paid\", \"absences\")]\n  d3 &lt;- inner_join(d1, d2, join_on_columns)\n  return (d3)\n}\n\n\n\n\nWarning in inner_join(d1, d2, by = variables) :\n  Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 79 of `x` matches multiple rows in `y`.\nℹ Row 79 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to silence this\n  warning.\nThis inner_join() creates way more data than expected or desired. This is because the data is not unique for that row. It is matching many rows from the other data set. Joining the data here means the student is likely the same student found in both data sets (they have the same attributes for things like age, sex, address, etc.). The given variables are fairly specific, but not enough to make the rows unique."
  },
  {
    "objectID": "homeworks/Homework_5.html#task-1-read-in-the-data-and-modify",
    "href": "homeworks/Homework_5.html#task-1-read-in-the-data-and-modify",
    "title": "Homework 5",
    "section": "Task 1: Read in the Data and Modify",
    "text": "Task 1: Read in the Data and Modify\n\nReading in data\n\nModify the provided code to read in the data and combine.\nRead in and combine using tidyverse and inner_join().\n\n\nlibrary(\"tidyverse\")\n\nread_method_1 &lt;- function(file1, file2) {\n  d1 &lt;- read.table(file1, sep=\";\", header=TRUE)\n  d2 &lt;- read.table(file2, sep=\";\", header=TRUE)\n\n  d3 &lt;- merge(d1,d2,by=c(\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"))\n  return (d3)\n}\n\nread_method_2 &lt;- function(file1, file2) {\n  d1 &lt;- read_delim(file1, delim=\";\", show_col_types = FALSE)\n  d2 &lt;- read_delim(file2, delim=\";\", show_col_types = FALSE)\n\n  join_on_columns &lt;- names(d1)[!names(d1) %in% c(\"G1\", \"G2\", \"G3\", \"paid\", \"absences\")]\n  d3 &lt;- inner_join(d1, d2, join_on_columns, suffix = c(\"_math\", \"_lang\"))\n  return (list(d1=d1, d2=d2, combined=d3))\n}\n\nModified code for reading in.\n\nstr(read_method_1(\"../data/hw5/student-mat.csv\", \"../data/hw5/student-por.csv\"))\n\n'data.frame':   382 obs. of  53 variables:\n $ school      : chr  \"GP\" \"GP\" \"GP\" \"GP\" ...\n $ sex         : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ age         : int  15 15 15 15 15 15 15 15 15 15 ...\n $ address     : chr  \"R\" \"R\" \"R\" \"R\" ...\n $ famsize     : chr  \"GT3\" \"GT3\" \"GT3\" \"GT3\" ...\n $ Pstatus     : chr  \"T\" \"T\" \"T\" \"T\" ...\n $ Medu        : int  1 1 2 2 3 3 3 2 3 3 ...\n $ Fedu        : int  1 1 2 4 3 4 4 2 1 3 ...\n $ Mjob        : chr  \"at_home\" \"other\" \"at_home\" \"services\" ...\n $ Fjob        : chr  \"other\" \"other\" \"other\" \"health\" ...\n $ reason      : chr  \"home\" \"reputation\" \"reputation\" \"course\" ...\n $ nursery     : chr  \"yes\" \"no\" \"yes\" \"yes\" ...\n $ internet    : chr  \"yes\" \"yes\" \"no\" \"yes\" ...\n $ guardian.x  : chr  \"mother\" \"mother\" \"mother\" \"mother\" ...\n $ traveltime.x: int  2 1 1 1 2 1 2 2 2 1 ...\n $ studytime.x : int  4 2 1 3 3 3 3 2 4 4 ...\n $ failures.x  : int  1 2 0 0 2 0 2 0 0 0 ...\n $ schoolsup.x : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ famsup.x    : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ paid.x      : chr  \"yes\" \"no\" \"yes\" \"yes\" ...\n $ activities.x: chr  \"yes\" \"no\" \"yes\" \"yes\" ...\n $ higher.x    : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ romantic.x  : chr  \"no\" \"yes\" \"no\" \"no\" ...\n $ famrel.x    : int  3 3 4 4 4 4 4 4 4 4 ...\n $ freetime.x  : int  1 3 3 3 2 3 2 1 4 3 ...\n $ goout.x     : int  2 4 1 2 1 2 2 3 2 3 ...\n $ Dalc.x      : int  1 2 1 1 2 1 2 1 2 1 ...\n $ Walc.x      : int  1 4 1 1 3 1 2 3 3 1 ...\n $ health.x    : int  1 5 2 5 3 5 5 4 3 4 ...\n $ absences.x  : int  2 2 8 2 8 2 0 2 12 10 ...\n $ G1.x        : int  7 8 14 10 10 12 12 8 16 10 ...\n $ G2.x        : int  10 6 13 9 10 12 0 9 16 11 ...\n $ G3.x        : int  10 5 13 8 10 11 0 8 16 11 ...\n $ guardian.y  : chr  \"mother\" \"mother\" \"mother\" \"mother\" ...\n $ traveltime.y: int  2 1 1 1 2 1 2 2 2 1 ...\n $ studytime.y : int  4 2 1 3 3 3 3 2 4 4 ...\n $ failures.y  : int  0 0 0 0 0 0 0 0 0 0 ...\n $ schoolsup.y : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ famsup.y    : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ paid.y      : chr  \"yes\" \"no\" \"no\" \"no\" ...\n $ activities.y: chr  \"yes\" \"no\" \"yes\" \"yes\" ...\n $ higher.y    : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ romantic.y  : chr  \"no\" \"yes\" \"no\" \"no\" ...\n $ famrel.y    : int  3 3 4 4 4 4 4 4 4 4 ...\n $ freetime.y  : int  1 3 3 3 2 3 2 1 4 3 ...\n $ goout.y     : int  2 4 1 2 1 2 2 3 2 3 ...\n $ Dalc.y      : int  1 2 1 1 2 1 2 1 2 1 ...\n $ Walc.y      : int  1 4 1 1 3 1 2 3 3 1 ...\n $ health.y    : int  1 5 2 5 3 5 5 4 3 4 ...\n $ absences.y  : int  4 2 8 2 2 2 0 0 6 10 ...\n $ G1.y        : int  13 13 14 10 13 11 10 11 15 10 ...\n $ G2.y        : int  13 11 13 11 13 12 11 10 15 10 ...\n $ G3.y        : int  13 11 12 10 13 12 12 11 15 10 ...\n\n\nUsing inner_join() with all variables other than G1, G2, G3, paid, and absences.\n\ndata &lt;- read_method_2(\"../data/hw5/student-mat.csv\", \"../data/hw5/student-por.csv\")\nstr(data$combined, give.attr = FALSE)\n\nspc_tbl_ [320 × 38] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ school       : chr [1:320] \"GP\" \"GP\" \"GP\" \"GP\" ...\n $ sex          : chr [1:320] \"F\" \"F\" \"F\" \"F\" ...\n $ age          : num [1:320] 18 17 15 16 16 16 17 15 15 15 ...\n $ address      : chr [1:320] \"U\" \"U\" \"U\" \"U\" ...\n $ famsize      : chr [1:320] \"GT3\" \"GT3\" \"GT3\" \"GT3\" ...\n $ Pstatus      : chr [1:320] \"A\" \"T\" \"T\" \"T\" ...\n $ Medu         : num [1:320] 4 1 4 3 4 2 4 3 3 4 ...\n $ Fedu         : num [1:320] 4 1 2 3 3 2 4 2 4 4 ...\n $ Mjob         : chr [1:320] \"at_home\" \"at_home\" \"health\" \"other\" ...\n $ Fjob         : chr [1:320] \"teacher\" \"other\" \"services\" \"other\" ...\n $ reason       : chr [1:320] \"course\" \"course\" \"home\" \"home\" ...\n $ guardian     : chr [1:320] \"mother\" \"father\" \"mother\" \"father\" ...\n $ traveltime   : num [1:320] 2 1 1 1 1 1 2 1 1 1 ...\n $ studytime    : num [1:320] 2 2 3 2 2 2 2 2 2 2 ...\n $ failures     : num [1:320] 0 0 0 0 0 0 0 0 0 0 ...\n $ schoolsup    : chr [1:320] \"yes\" \"no\" \"no\" \"no\" ...\n $ famsup       : chr [1:320] \"no\" \"yes\" \"yes\" \"yes\" ...\n $ paid_math    : chr [1:320] \"no\" \"no\" \"yes\" \"yes\" ...\n $ activities   : chr [1:320] \"no\" \"no\" \"yes\" \"no\" ...\n $ nursery      : chr [1:320] \"yes\" \"no\" \"yes\" \"yes\" ...\n $ higher       : chr [1:320] \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ internet     : chr [1:320] \"no\" \"yes\" \"yes\" \"no\" ...\n $ romantic     : chr [1:320] \"no\" \"no\" \"yes\" \"no\" ...\n $ famrel       : num [1:320] 4 5 3 4 5 4 4 4 5 3 ...\n $ freetime     : num [1:320] 3 3 2 3 4 4 1 2 5 3 ...\n $ goout        : num [1:320] 4 3 2 2 2 4 4 2 1 3 ...\n $ Dalc         : num [1:320] 1 1 1 1 1 1 1 1 1 1 ...\n $ Walc         : num [1:320] 1 1 1 2 2 1 1 1 1 2 ...\n $ health       : num [1:320] 3 3 5 5 5 3 1 1 5 2 ...\n $ absences_math: num [1:320] 6 4 2 4 10 0 6 0 0 0 ...\n $ G1_math      : num [1:320] 5 5 15 6 15 12 6 16 14 10 ...\n $ G2_math      : num [1:320] 6 5 14 10 15 12 5 18 15 8 ...\n $ G3_math      : num [1:320] 6 6 15 10 15 11 6 19 15 9 ...\n $ paid_lang    : chr [1:320] \"no\" \"no\" \"no\" \"no\" ...\n $ absences_lang: num [1:320] 4 2 0 0 6 0 2 0 0 2 ...\n $ G1_lang      : num [1:320] 0 9 14 11 12 13 10 15 12 14 ...\n $ G2_lang      : num [1:320] 11 11 14 13 12 12 13 16 12 14 ...\n $ G3_lang      : num [1:320] 11 11 14 13 13 13 13 17 13 14 ...\n\n\n\n\nNote: When using the same variables from the given merge code, this is warning is seen.\n\nWarning in inner_join(d1, d2, by = variables) :\n  Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 79 of `x` matches multiple rows in `y`.\nℹ Row 79 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to silence this\n  warning.\nThis inner_join() creates way more data than expected or desired. This is because the data is not unique rows for that variable set. It is matching multiple rows from the other data set. Joining the data here means the student is likely the same student found in both data sets for different classes (they have the same attributes for things like age, sex, address, etc.). The given variables are fairly specific, but not enough to make the rows unique.\n\n\n\nFor the math data, Portuguese, and combined, choose four categorical variables and convert those into factor variables.\n\nVariables: “internet”, “Pstatus”, “famsize”, “sex”\n\n\nvariables_chosen &lt;- c(\"internet\", \"Pstatus\", \"famsize\", \"sex\")\nstr(data$combined[,variables_chosen], give.attr = FALSE)\n\ntibble [320 × 4] (S3: tbl_df/tbl/data.frame)\n $ internet: chr [1:320] \"no\" \"yes\" \"yes\" \"no\" ...\n $ Pstatus : chr [1:320] \"A\" \"T\" \"T\" \"T\" ...\n $ famsize : chr [1:320] \"GT3\" \"GT3\" \"GT3\" \"GT3\" ...\n $ sex     : chr [1:320] \"F\" \"F\" \"F\" \"F\" ...\n\ndata$d1 &lt;- data$d1 |&gt; mutate(across(all_of(variables_chosen), as.factor))\ndata$d2 &lt;- data$d2 |&gt; mutate(across(all_of(variables_chosen), as.factor))\ndata$combined &lt;- data$combined |&gt; mutate(across(all_of(variables_chosen), as.factor))\nstr(data$combined[,variables_chosen], give.attr = FALSE)\n\ntibble [320 × 4] (S3: tbl_df/tbl/data.frame)\n $ internet: Factor w/ 2 levels \"no\",\"yes\": 1 2 2 1 2 2 1 2 2 2 ...\n $ Pstatus : Factor w/ 2 levels \"A\",\"T\": 1 2 2 2 2 2 1 1 2 2 ...\n $ famsize : Factor w/ 2 levels \"GT3\",\"LE3\": 1 1 1 1 2 2 1 2 1 1 ...\n $ sex     : Factor w/ 2 levels \"F\",\"M\": 1 1 1 1 2 2 1 2 2 1 ..."
  },
  {
    "objectID": "homeworks/Homework_5.html#task-2-summarize-the-data-very-basic-eda",
    "href": "homeworks/Homework_5.html#task-2-summarize-the-data-very-basic-eda",
    "title": "Homework 5",
    "section": "Task 2: Summarize the Data (Very Basic EDA)",
    "text": "Task 2: Summarize the Data (Very Basic EDA)\n\nLook at how the data is stored and see if everything makes sense.\n\nLooking at students.txt from the zip file for further descriptions of the variables, we see:\n\nstr(data$combined[c(\"Medu\",\"Fedu\",\"traveltime\",\"studytime\",\"failures\",\"famrel\",\"freetime\",\"goout\",\"Dalc\",\"Walc\",\"health\",\"G1_math\",\"G2_lang\")])\n\ntibble [320 × 13] (S3: tbl_df/tbl/data.frame)\n $ Medu      : num [1:320] 4 1 4 3 4 2 4 3 3 4 ...\n $ Fedu      : num [1:320] 4 1 2 3 3 2 4 2 4 4 ...\n $ traveltime: num [1:320] 2 1 1 1 1 1 2 1 1 1 ...\n $ studytime : num [1:320] 2 2 3 2 2 2 2 2 2 2 ...\n $ failures  : num [1:320] 0 0 0 0 0 0 0 0 0 0 ...\n $ famrel    : num [1:320] 4 5 3 4 5 4 4 4 5 3 ...\n $ freetime  : num [1:320] 3 3 2 3 4 4 1 2 5 3 ...\n $ goout     : num [1:320] 4 3 2 2 2 4 4 2 1 3 ...\n $ Dalc      : num [1:320] 1 1 1 1 1 1 1 1 1 1 ...\n $ Walc      : num [1:320] 1 1 1 2 2 1 1 1 1 2 ...\n $ health    : num [1:320] 3 3 5 5 5 3 1 1 5 2 ...\n $ G1_math   : num [1:320] 5 5 15 6 15 12 6 16 14 10 ...\n $ G2_lang   : num [1:320] 11 11 14 13 12 12 13 16 12 14 ...\n\n\n\nMedu/Fedu - Education levels that are bucketed (2 is 5th to 9th grade).\ntraveltime - Unequal bucketing of time data. It has 15 min intervals that switches to 30 minute interval, and finishes with a single value of 1 hour.\nstudytime - 1hr, 3hr, and 5hr intervals and a single value of 10hrs.\nfailures - n if 1&lt;=n&lt;3, else 4 (a lot of values are 0, so those are really 4)\nfamrel, freetime, goout, Dalc, Walc, health - these are ratings 1-5 and shouldn’t be numerically summarized (a 1 and a 5 don’t necessarily average to a 3, and two 1’s from two people aren’t necessarily the same)\nG1, G2 - No issues, but for some reason the source site lists them as categorical\n\n\n\nDocument the missing values in the data.\n\nThe data claims to have no missing values on the source site.\n\ncolSums(is.na(data$combined))\n\n       school           sex           age       address       famsize \n            0             0             0             0             0 \n      Pstatus          Medu          Fedu          Mjob          Fjob \n            0             0             0             0             0 \n       reason      guardian    traveltime     studytime      failures \n            0             0             0             0             0 \n    schoolsup        famsup     paid_math    activities       nursery \n            0             0             0             0             0 \n       higher      internet      romantic        famrel      freetime \n            0             0             0             0             0 \n        goout          Dalc          Walc        health absences_math \n            0             0             0             0             0 \n      G1_math       G2_math       G3_math     paid_lang absences_lang \n            0             0             0             0             0 \n      G1_lang       G2_lang       G3_lang \n            0             0             0 \n\n\n\nIt seems to check out, all 0’s.\n\n\n\nCategorical Variables\n\n\nVariables: “internet”, “Pstatus”, “famsize”, “sex”\n\nContingency table.\n\nOne-way\n\n\ntable(data$combined$Pstatus)\n\n\n  A   T \n 31 289 \n\n\nFor most of the data, we see that the parents live together.\n\nTwo-way\n\n\ntable(data$combined$sex, data$combined$Pstatus)\n\n   \n      A   T\n  F  18 156\n  M  13 133\n\n\nBetween sex, there seems to be little to no difference in parent’s living together or apart.\n\nThree-way\n\n\ntable(data$combined$sex, data$combined$Pstatus, data$combined$famsize)\n\n, ,  = GT3\n\n   \n      A   T\n  F  12 118\n  M   4  96\n\n, ,  = LE3\n\n   \n      A   T\n  F   6  38\n  M   9  37\n\n\nSurprisingly, the numbers for those with 3 children or greater are much higher than those 3 or less. The less than 3 children seems to have a higher ratio of parent’s not living together.\nConditional two-way table.\n\nMethod 1\n\n\ntable(data$combined$sex, data$combined$famsize, data$combined$Pstatus)[1,,]\n\n     \n        A   T\n  GT3  12 118\n  LE3   6  38\n\n\n\nMethod 2\n\n\nwith(data$combined |&gt; filter(sex == \"M\"), table(famsize, Pstatus))\n\n       Pstatus\nfamsize  A  T\n    GT3  4 96\n    LE3  9 37\n\n\nThese two methods show the Female and Male counts of family size/parental living situation. Comparing the 2, the only major difference is the GT3 and LE3 for apart living parents flips. This doesn’t necessarily mean anything, though.\n\nMethod 3\n\n\nplot_data &lt;- data$combined |&gt;\n  group_by(internet, famsize) |&gt;\n  summarize(count = n()) |&gt;\n  pivot_wider(names_from=internet, values_from=count)\n\n`summarise()` has grouped output by 'internet'. You can override using the\n`.groups` argument.\n\n\nThe ratio of larger families having internet is much larger than that of smaller families.\nStacked bar graph.\n\nggplot(data$combined, aes(x = famsize, fill = internet)) + geom_bar() + labs(x=\"Family Size\", y=\"Has Internet\", title=\"Family Size to Internet Ratios\", fill=\"Has Internet\")\n\n\n\n\n\n\n\n\nThis graphically displays the previous comparison of family size and internet.\n\nggplot(data$combined, aes(x = famsize, fill = internet)) + geom_bar(position=\"dodge\") + labs(x=\"Family Size\", y=\"Has Internet\", title=\"Family Size to Internet Ratios\", fill=\"Has Internet\")\n\n\n\n\n\n\n\n\nFinally a non-stacked version of the plot is shown.\n\n\nNumerical Variables\n\n\nVariables: “age”, “absences”, “G1”, “G2”, “G3”\n\n\nMeasures of center and spread\n\n\ndata$combined |&gt;\n  select(age, starts_with(\"absences\"), starts_with(\"G3\")) |&gt;\n  summarize(across(everything(), list(\"mean\"=mean, \"med\"=median, \"sd\"=sd, \"IQR\"=IQR), .names = \"{.fn}_{.col}\")) |&gt;\n  str()\n\ntibble [1 × 20] (S3: tbl_df/tbl/data.frame)\n $ mean_age          : num 16.5\n $ med_age           : num 16\n $ sd_age            : num 1.14\n $ IQR_age           : num 1\n $ mean_absences_math: num 5.41\n $ med_absences_math : num 4\n $ sd_absences_math  : num 7.84\n $ IQR_absences_math : num 7.25\n $ mean_absences_lang: num 3.25\n $ med_absences_lang : num 2\n $ sd_absences_lang  : num 4.56\n $ IQR_absences_lang : num 4\n $ mean_G3_math      : num 11\n $ med_G3_math       : num 11\n $ sd_G3_math        : num 4.3\n $ IQR_G3_math       : num 5\n $ mean_G3_lang      : num 12.9\n $ med_G3_lang       : num 13\n $ sd_G3_lang        : num 2.89\n $ IQR_G3_lang       : num 4\n\n\nThis shows the mean, sd, and IQR of each numeric variable. The language class has a higher mean and smaller standard deviation than the math class for final grade.\n\nRepeated with subset of not having internet.\n\n\ndata$combined |&gt;\n  filter(internet == \"no\") |&gt;\n  select(age, starts_with(\"absences\"), starts_with(\"G3\")) |&gt;\n  summarize(across(everything(), list(\"mean\"=mean, \"med\"=median, \"sd\"=sd, \"IQR\"=IQR), .names = \"{.fn}_{.col}\")) |&gt;\n  str()\n\ntibble [1 × 20] (S3: tbl_df/tbl/data.frame)\n $ mean_age          : num 16.6\n $ med_age           : num 17\n $ sd_age            : num 1.06\n $ IQR_age           : num 1\n $ mean_absences_math: num 4.02\n $ med_absences_math : num 3.5\n $ sd_absences_math  : num 3.99\n $ IQR_absences_math : num 4.25\n $ mean_absences_lang: num 2.75\n $ med_absences_lang : num 2\n $ sd_absences_lang  : num 2.76\n $ IQR_absences_lang : num 4\n $ mean_G3_math      : num 9.69\n $ med_G3_math       : num 10\n $ sd_G3_math        : num 4.12\n $ IQR_G3_math       : num 4\n $ mean_G3_lang      : num 12.2\n $ med_G3_lang       : num 12.5\n $ sd_G3_lang        : num 3.53\n $ IQR_G3_lang       : num 3\n\n\nWe see not having internet has had a negative effect. The means have gone down. The spread is wider.\n\nCenter and spread for a grouping of those with parents separated or not.\n\n\ndata$combined |&gt;\n  select(age, starts_with(\"absences\"), starts_with(\"G3\"), Pstatus) |&gt;\n  group_by(Pstatus) |&gt;\n  summarize(across(everything(), list(\"mean\"=mean, \"med\"=median, \"sd\"=sd, \"IQR\"=IQR), .names = \"{.fn}_{.col}\")) |&gt;\n  str()\n\ntibble [2 × 21] (S3: tbl_df/tbl/data.frame)\n $ Pstatus           : Factor w/ 2 levels \"A\",\"T\": 1 2\n $ mean_age          : num [1:2] 16.4 16.5\n $ med_age           : num [1:2] 16 16\n $ sd_age            : num [1:2] 1.2 1.14\n $ IQR_age           : num [1:2] 2 1\n $ mean_absences_math: num [1:2] 10.03 4.92\n $ med_absences_math : num [1:2] 6 3\n $ sd_absences_math  : num [1:2] 13.98 6.72\n $ IQR_absences_math : num [1:2] 9 6\n $ mean_absences_lang: num [1:2] 4.1 3.16\n $ med_absences_lang : num [1:2] 2 2\n $ sd_absences_lang  : num [1:2] 5.56 4.44\n $ IQR_absences_lang : num [1:2] 6 4\n $ mean_G3_math      : num [1:2] 11.9 10.9\n $ med_G3_math       : num [1:2] 11 11\n $ sd_G3_math        : num [1:2] 3.61 4.37\n $ IQR_G3_math       : num [1:2] 4.5 5\n $ mean_G3_lang      : num [1:2] 13.5 12.8\n $ med_G3_lang       : num [1:2] 13 13\n $ sd_G3_lang        : num [1:2] 2.22 2.95\n $ IQR_G3_lang       : num [1:2] 3 4\n\n\nIt looks like parents separated or not has little effect on means but seems to increase the variability.\n\nCenter and spread, two grouping of internet (y/n) and parents (together,apart)\n\n\ndata$combined |&gt;\n  select(age, starts_with(\"absences\"), starts_with(\"G3\"), Pstatus, internet) |&gt;\n  group_by(Pstatus, internet) |&gt;\n  summarize(across(everything(), list(\"mean\"=mean, \"sd\"=sd, \"IQR\"=IQR), .names = \"{.fn}_{.col}\")) |&gt;\n  str()\n\n`summarise()` has grouped output by 'Pstatus'. You can override using the\n`.groups` argument.\n\n\ngropd_df [4 × 17] (S3: grouped_df/tbl_df/tbl/data.frame)\n $ Pstatus           : Factor w/ 2 levels \"A\",\"T\": 1 1 2 2\n $ internet          : Factor w/ 2 levels \"no\",\"yes\": 1 2 1 2\n $ mean_age          : num [1:4] 16.6 16.3 16.7 16.5\n $ sd_age            : num [1:4] 1.14 1.23 1.07 1.15\n $ IQR_age           : num [1:4] 1 2 1 1\n $ mean_absences_math: num [1:4] 8.4 10.35 3.51 5.16\n $ sd_absences_math  : num [1:4] 6.07 15.1 3.43 7.11\n $ IQR_absences_math : num [1:4] 4 9.5 4 7\n $ mean_absences_lang: num [1:4] 4.4 4.04 2.56 3.26\n $ sd_absences_lang  : num [1:4] 3.85 5.9 2.59 4.68\n $ IQR_absences_lang : num [1:4] 4 5.5 4 4\n $ mean_G3_math      : num [1:4] 8.2 12.62 9.86 11.14\n $ sd_G3_math        : num [1:4] 2.59 3.36 4.25 4.37\n $ IQR_G3_math       : num [1:4] 5 4 3.5 5\n $ mean_G3_lang      : num [1:4] 11.8 13.8 12.3 12.9\n $ sd_G3_lang        : num [1:4] 2.17 2.12 3.67 2.8\n $ IQR_G3_lang       : num [1:4] 3 3.5 3 4\n - attr(*, \"groups\")= tibble [2 × 2] (S3: tbl_df/tbl/data.frame)\n  ..$ Pstatus: Factor w/ 2 levels \"A\",\"T\": 1 2\n  ..$ .rows  : list&lt;int&gt; [1:2] \n  .. ..$ : int [1:2] 1 2\n  .. ..$ : int [1:2] 3 4\n  .. ..@ ptype: int(0) \n  ..- attr(*, \".drop\")= logi TRUE\n\n\nThe highest mean outcome seems to be parents apart and with internet. The variability generally goes down a bit too, but it depends on math vs language course.\n\nCorrelation matrix\n\n\ndata$combined |&gt;\n  select(age, starts_with(\"absences\"), starts_with(\"G3\")) |&gt;\n  cor() |&gt;\n  round(3)\n\n                 age absences_math absences_lang G3_math G3_lang\nage            1.000         0.144         0.047  -0.206  -0.009\nabsences_math  0.144         1.000         0.564  -0.028  -0.136\nabsences_lang  0.047         0.564         1.000  -0.117  -0.071\nG3_math       -0.206        -0.028        -0.117   1.000   0.476\nG3_lang       -0.009        -0.136        -0.071   0.476   1.000\n\n\nThe largest correlation effect to a final grade is age, but it is a minor negative correlation.\n\nPlots\n\nHistogram\n\n\n\nggplot(data$combined) +\n  geom_histogram(aes(x=G1_math, fill=internet), binwidth=1) +\n  labs(title=\"Math Score by Internet\", x=\"Math Score\", y=\"Count\", fill=\"Internet\")\n\n\n\n\n\n\n\nggplot(data$combined) +\n  geom_histogram(aes(x=G1_lang, fill=internet), binwidth=1) +\n  labs(title=\"Language Score by Internet\", x=\"Language Score\", y=\"Count\", fill=\"Internet\")\n\n\n\n\n\n\n\n\nBetween the two plots of math and language, it looks like generally the scores are higher in language. It’s hard to tell if internet had any effect.\n\nKernel Density\n\n\nggplot(data$combined) +\n  geom_density(aes(x=G2_math, fill=internet)) +\n  labs(title=\"Math Score by Internet\", x=\"Math Score\", y=\"Density\", fill=\"Internet\")\n\n\n\n\n\n\n\nggplot(data$combined) +\n  geom_density(aes(x=G2_lang, fill=internet)) +\n  labs(title=\"Language Score by Internet\", x=\"Language Score\", y=\"Density\", fill=\"Internet\")\n\n\n\n\n\n\n\n\nThe same density plot of math vs language tell sthe same story (the axis shifted some). It’s a little more clear from this plot that internet had a negative effect on math, but no clear effect on language.\n\nBoxplot\n\n\nggplot(data$combined) +\n  geom_boxplot(aes(y=G3_math, fill=internet)) +\n  labs(title=\"Math Score by Internet\", x=NULL, y=\"Math Score\", fill=\"Internet\")\n\n\n\n\n\n\n\nggplot(data$combined) +\n  geom_boxplot(aes(y=G3_lang, fill=internet)) +\n  labs(title=\"Language Score by Internet\", x=NULL, y=\"Language Score\", fill=\"Internet\")\n\n\n\n\n\n\n\n\nThe boxplots show the same story, but a little better for language to see some slight negative effect of no internet and decreased variability.\n\nScatterPlots\n\nOne - Absences in math to math score, colored by internet (y/n)\n\n\n\nggplot(data$combined) +\n  geom_point(aes(x=absences_math, y=G3_math, color=internet), position=\"jitter\") +\n  labs(title=\"Absences vs Math Score by (internet)\", x=\"Absences\", y=\"Math Score\")\n\n\n\n\n\n\n\n\nIt does look like the higher absences may tend to be those with internet, but it’s unclear from this what the score effect would be.\n\nTwo - The same, but for language.\n\n\nggplot(data$combined) +\n  geom_point(aes(x=absences_lang, y=G3_lang, color=internet), position=\"jitter\") +\n  labs(title=\"Absences vs Language Score by (internet)\", x=\"Absences\", y=\"Language Score\")\n\n\n\n\n\n\n\n\nThis agrees well with the previous view of higher absence holders are those with internet.\n\nFaceting\n\nOne - This takes a look at study time effect on score, covered over sex.\n\n\n\nggplot(data$combined, aes(x=studytime, y=G3_math)) +\n  geom_point(position=\"jitter\") +\n  geom_smooth(method=\"lm\") +\n  facet_wrap(~ sex) +\n  labs(title=\"Study Time vs Math Score by (sex)\", x=\"Study Time\", y=\"Math Score\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThere is not a clear effect either way. It’s surprising to see study time is having such little effect.\n\nTwo - The same as previous, but for language.\n\n\nggplot(data$combined, aes(x=studytime, y=G3_lang)) +\n  geom_point(position=\"jitter\") +\n  geom_smooth(method=\"lm\") +\n  facet_wrap(~ sex) +\n  labs(title=\"Study Time vs Language Score by (sex)\", x=\"Study Time\", y=\"Language Score\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThere seems to be a small positive effect of study time on language, but it does not visibly differ between sex.\n\nFaceting again, but over 2 variables.\n\nThe effect of having school support (y/n), and whether the address is urban/rural (U/R).\n\n\n\nggplot(data$combined, aes(x=age, y=G3_math)) +\n  geom_point(position=\"jitter\") +\n  geom_smooth(method=\"lm\") +\n  facet_wrap(~ schoolsup + address) +\n  labs(title=\"Age vs Math Score by (school support and address)\", x=\"Age\", y=\"Math Score\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThere seems to be a general downward trend on age. But having school support can help somewhat. The low data points item is unreliable (rural with support).\n\nThe same as previous but for language.\n\n\nggplot(data$combined, aes(x=age, y=G3_lang)) +\n  geom_point(position=\"jitter\") +\n  geom_smooth(method=\"lm\") +\n  facet_wrap(~ schoolsup + address) +\n  labs(title=\"Age vs Language Score by (school support and address)\", x=\"Age\", y=\"Language Score\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFor language, it seems there may be a positive effect of urban vs rural, but not so much from school support."
  },
  {
    "objectID": "homeworks/Homework_6.html",
    "href": "homeworks/Homework_6.html",
    "title": "Homework 6",
    "section": "",
    "text": "What is the purpose of the lapply() function? What is the equivalent purrr function?\n\n\nlapply stands for list apply. It is used to apply a function to each list item, similar to having a for loop and running the function over each element in a list. The equivalent purrr function is map.\n\n\nSuppose we have a list called my_list. Each element of the list is a numeric data frame (all columns are numeric). We want to use lapply() to run the code cor(numeric_matrix, method = \"kendall\") on each element of the list. Write code to do this below! (I’m really trying to ask you how you specify method = \"kendall\" when calling lapply())\n\n\nlapply(my_list, cor, method = “kendall”)\n\n\nWhat are two advantages of using purrr functions instead of the BaseR apply family?\n\n\npurrr functions allow shorthand notation and are more consistent in their input/output.\n\n\nWhat is a side-effect function?\n\n\nA side-effect function is one that performs an operation, some thing, but isn’t really about manipulating data. A good example is simply printing something out. It wouldn’t return data, but it uses the data. This is not very useful for chaining.\n\n\nWhy can you name a variable sd in a function and not cause any issues with the sd function?\n\n\nThe scope inside the function is local to that function."
  },
  {
    "objectID": "homeworks/Homework_6.html#task-1-conceptual-questions",
    "href": "homeworks/Homework_6.html#task-1-conceptual-questions",
    "title": "Homework 6",
    "section": "Task 1: Conceptual Questions",
    "text": "Task 1: Conceptual Questions\n\nWhat is the purpose of the lapply() function? What is the equivalent purrr function?\n\n\nlapply stands for list apply. It is used to apply a function to each list item, similar to having a for loop and running the function over each element in a list. The equivalent purrr function is map.\n\n\nSuppose we have a list called my_list. Each element of the list is a numeric data frame (all columns are numeric). We want to use lapply() to run the code cor(numeric_matrix, method = \"kendall\") on each element of the list. Write code to do this below! (I’m really trying to ask you how you specify method = \"kendall\" when calling lapply())\n\n\nlapply(my_list, cor, method = “kendall”)\n\n\nWhat are two advantages of using purrr functions instead of the BaseR apply family?\n\n\npurrr functions allow shorthand notation and are more consistent in their input/output.\n\n\nWhat is a side-effect function?\n\n\nA side-effect function is one that performs an operation, some thing, but isn’t really about manipulating data. A good example is simply printing something out. It wouldn’t return data, but it uses the data. This is not very useful for chaining.\n\n\nWhy can you name a variable sd in a function and not cause any issues with the sd function?\n\n\nThe scope inside the function is local to that function."
  },
  {
    "objectID": "homeworks/Homework_6.html#task-2-writing-r-functions",
    "href": "homeworks/Homework_6.html#task-2-writing-r-functions",
    "title": "Homework 6",
    "section": "Task 2: Writing R Functions",
    "text": "Task 2: Writing R Functions\n\nNote* - Provided code will be used for multiple steps of Task 2\n\n\n# provided code for hw6 Task 2\nset.seed(10)\nn &lt;- 100\nx &lt;- runif(n)\nresp &lt;- 3 + 10 * x + rnorm(n)\npred &lt;- predict(lm(resp ~ x), data.frame(x))\n\n\n# show results of provided code\nn\nhead(resp, 5)\nhead(pred, 5)\n\n[1] 100\n[1]  7.674144  5.733128  8.637031 12.068788  4.357179\n        1         2         3         4         5 \n 8.148104  6.053163  7.307135 10.085585  3.739836 \n\n\n\n# copy resp from provided code and put 2 NA_real_ values into the vector\nrand_idx &lt;- sample(seq_along(resp), 2)\nresp_with_na &lt;- resp\nresp_with_na[rand_idx] &lt;- NA_real_\nresp\nresp_with_na\n\n  [1]  7.674144  5.733128  8.637031 12.068788  4.357179  6.040709  4.843093\n  [8]  6.255948  8.512399  7.587703  8.278962  8.221201  3.304767  9.299369\n [15]  7.646876  8.504220  4.254724  5.160568  7.550652 10.115022 12.028134\n [22]  7.723097  9.702653  6.337183  5.568563 11.239175  9.903050  4.965503\n [29]  9.656077  8.081564  8.948798  3.708220  5.410925 12.714925  7.666618\n [36] 10.636295 11.886290 14.767056  8.670500  7.931076  5.338484  5.097557\n [43]  3.213884 11.444994  6.093762  3.192188  1.563749  8.753929  4.177170\n [50] 12.242498  5.781476 12.783701  4.418721  8.442989  4.282396  9.395394\n [57]  8.255719  6.016290  8.026494  9.180810  2.038727  5.273544  7.225220\n [64]  6.654107 12.260485 10.688362  9.773488  8.216967  5.093565  6.142304\n [71]  3.274337  8.547150  9.381826  7.061813  4.016495  7.543794  6.976389\n [78] 11.550401  5.209433  3.872522 13.043037  8.277356  3.231859  8.553664\n [85]  4.576422  2.213665 11.475262  6.469006  5.333390  5.656304  6.209727\n [92]  8.908905  6.956097  9.642321  7.188749 12.413663  6.020730  8.507994\n [99] 11.776177  3.387353\n  [1]  7.674144  5.733128  8.637031 12.068788  4.357179  6.040709  4.843093\n  [8]  6.255948  8.512399  7.587703  8.278962        NA  3.304767        NA\n [15]  7.646876  8.504220  4.254724  5.160568  7.550652 10.115022 12.028134\n [22]  7.723097  9.702653  6.337183  5.568563 11.239175  9.903050  4.965503\n [29]  9.656077  8.081564  8.948798  3.708220  5.410925 12.714925  7.666618\n [36] 10.636295 11.886290 14.767056  8.670500  7.931076  5.338484  5.097557\n [43]  3.213884 11.444994  6.093762  3.192188  1.563749  8.753929  4.177170\n [50] 12.242498  5.781476 12.783701  4.418721  8.442989  4.282396  9.395394\n [57]  8.255719  6.016290  8.026494  9.180810  2.038727  5.273544  7.225220\n [64]  6.654107 12.260485 10.688362  9.773488  8.216967  5.093565  6.142304\n [71]  3.274337  8.547150  9.381826  7.061813  4.016495  7.543794  6.976389\n [78] 11.550401  5.209433  3.872522 13.043037  8.277356  3.231859  8.553664\n [85]  4.576422  2.213665 11.475262  6.469006  5.333390  5.656304  6.209727\n [92]  8.908905  6.956097  9.642321  7.188749 12.413663  6.020730  8.507994\n [99] 11.776177  3.387353\n\n\n\n\nTASKS\n\nRMSE function and simple test usage.\n\n\n\n\nAttaching package: 'purrr'\n\n\nThe following object is masked from 'package:jsonlite':\n\n    flatten\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\n\nAttaching package: 'hms'\n\n\nThe following object is masked from 'package:lubridate':\n\n    hms\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\ngetRMSE\n\nfunction(responses, predictions, ...) {\n  # takes in a vector of responses and predictions and returns RMSE\n  if (!is.vector(responses) | !is.vector(predictions)) {\n    stop(\"Both inputs must be vectors\")\n  }\n  RMSE &lt;- sqrt(mean((responses - predictions)^2, ...))\n  return (RMSE)\n}\n\n\n\nvec1 &lt;- c(1, 2, 3, 4, 5)\nvec2 &lt;- c(2, 3, 4, 5, 6)\nvec1_with_na &lt;- c(1, 2, 3, 4, NA)\nvec2_with_na &lt;- c(2, 3, NA, 5, 6)\ngetRMSE(vec1, vec2)\ngetRMSE(vec1_with_na, vec2_with_na, na.rm=TRUE)\n\n[1] 1\n[1] 1\n\n\n\nRun provided code (already prepared) and test RMSE on resp and resp with NA’s.\n\n\ngetRMSE(resp, pred)\ngetRMSE(resp_with_na, pred)\ngetRMSE(resp_with_na, pred, na.rm=TRUE)\n\n[1] 0.9581677\n[1] NA\n[1] 0.9659906\n\n\n\nMAE function and simple test usage (reuse prior).\n\n\ngetMAE\n\nfunction(responses, predictions, ...) {\n  # takes in a vector of responses and predictions and returns MAE\n  if (!is.vector(responses) | !is.vector(predictions)) {\n    stop(\"Both inputs must be vectors\")\n  }\n\n  MAE &lt;- mean(abs(responses - predictions), ...)\n  return (MAE)\n}\n\n\n\ngetMAE(vec1, vec2)\ngetMAE(vec1_with_na, vec2_with_na, na.rm=TRUE)\n\n[1] 1\n[1] 1\n\n\n\nRun the provided code (reuse already prepared) and test MAE on resp and resp with NA’s.\n\n\ngetMAE(resp, pred)\ngetMAE(resp_with_na, pred)\ngetMAE(resp_with_na, pred, na.rm=TRUE)\n\n[1] 0.8155776\n[1] NA\n[1] 0.8242225\n\n\n\nWrapper function for either/both of MAE and RMSE and extra validation.\n\n\nget_metrics\n\nfunction(responses, predictions, metrics=\"rmse,mae\", ...) {\n  if (!all(\n    is.numeric(responses), is.numeric(predictions),\n    is.atomic(responses), is.atomic(predictions),\n    is.vector(responses), is.vector(predictions)\n  )) {\n    stop(\"Both inputs must be atomic numeric vectors\")\n  }\n\n  ret &lt;- list()\n  # RMSE\n  if (any(grepl(\"rmse\", metrics, ignore.case=TRUE))) {\n    RMSE &lt;- getRMSE(responses, predictions, ...)\n    ret$RMSE &lt;- RMSE\n  }\n  # MAE\n  if (any(grepl(\"mae\", metrics, ignore.case=TRUE))) {\n    MAE &lt;- getMAE(responses, predictions, ...)\n    ret$MAE &lt;- MAE\n  }\n\n  return (ret)\n}\n\n\n\nRun the provided code (reuse already prepared) and test wrapper on resp, resp with NA’s, various choice metrics, and invalid input.\n\n\n# both\nget_metrics(resp, pred)\nget_metrics(resp_with_na, pred)\nget_metrics(resp_with_na, pred, na.rm=TRUE)\n\n$RMSE\n[1] 0.9581677\n\n$MAE\n[1] 0.8155776\n\n$RMSE\n[1] NA\n\n$MAE\n[1] NA\n\n$RMSE\n[1] 0.9659906\n\n$MAE\n[1] 0.8242225\n\n\n\n# RMSE\nget_metrics(resp, pred, \"rmse\")\nget_metrics(resp_with_na, pred, \"rmse\")\nget_metrics(resp_with_na, pred, \"rmse\", na.rm=TRUE)\n\n$RMSE\n[1] 0.9581677\n\n$RMSE\n[1] NA\n\n$RMSE\n[1] 0.9659906\n\n\n\n# MAE\nget_metrics(resp, pred, \"mae\")\nget_metrics(resp_with_na, pred, \"mae\")\nget_metrics(resp_with_na, pred, \"mae\", na.rm=TRUE)\n\n$MAE\n[1] 0.8155776\n\n$MAE\n[1] NA\n\n$MAE\n[1] 0.8242225\n\n\n\n# invalid input, giving dataframe\ndf &lt;- data.frame(pred, resp)\n# throws stop error, need try-to avoid error in render\ntry(get_metrics(resp, df))\ntry(get_metrics(df, pred))\n\nError in get_metrics(resp, df) : \n  Both inputs must be atomic numeric vectors\nError in get_metrics(df, pred) : \n  Both inputs must be atomic numeric vectors"
  },
  {
    "objectID": "homeworks/Homework_6.html#task-3-querying-an-api-and-a-tidy-style-function",
    "href": "homeworks/Homework_6.html#task-3-querying-an-api-and-a-tidy-style-function",
    "title": "Homework 6",
    "section": "Task 3: Querying an API and a Tidy-Style Function",
    "text": "Task 3: Querying an API and a Tidy-Style Function\n\nStep 1-3: Create the GET request to the news API, get articles from the response, and build make a function for the operation of searching for news.\n\n# function created, with defaults as the interesting topic\nget_news_api_data\n\nfunction(api_key, subject=\"esports\", time_period=\"2024-10-01\") {\n  BASE_URL &lt;- glue(\"https://newsapi.org/v2/everything?q={subject}&from={time_period}&sortBy=publishedAt&apiKey={api_key}\")\n\n  data &lt;- httr::GET(BASE_URL) |&gt;\n    content(\"text\") |&gt;\n    fromJSON(flatten = TRUE, simplifyDataFrame = TRUE) |&gt;\n    pluck(\"articles\")\n\n    return (data)\n}\n\n\n\n# resulting data, using default of esports articles\ndata &lt;- get_news_api_data(API_KEY)\n# print the top 5 titles\nhead(data$title, 5)\n\n[1] \"Opportunity Knocks For India's Esports Athletes To Compete At FIFAe WC\"                                    \n[2] \"東京メトロ第3回 TOKYO METRO CUP OVERWATCH 2を開催します！\"                                                 \n[3] \"No Controllers Allowed! Malaysia Hosts APAC Predator League 2025. Get your tickets with exclusive goodies!\"\n[4] \"Can an AI coach help your esports team clinch the championship?\"                                           \n[5] \"Dragon Ball: Sparking! Zero reporta ventas millonarias en un día\"                                          \n\n\n\nUse the function twice to grab some data. Summarize the source field.\n\n\ncsc_data &lt;- get_news_api_data(API_KEY, subject=\"computer%20science\")\ndata_science_data &lt;- get_news_api_data(API_KEY, subject=\"data%20science\")\n\n# csc\ntable(csc_data$source.name)\n\n\n                                         [Removed] \n                                                 3 \n                                          ABC News \n                                                 4 \n                                         Acast.com \n                                                 1 \n                                           Acm.org \n                                                 2 \n                                      Adafruit.com \n                                                16 \n                                        Amazon.com \n                                                 2 \n                                       AndroidGuys \n                                                 1 \n                             Bengreenfieldlife.com \n                                                 1 \n                                       Blog.google \n                                                 1 \n                                            blogTO \n                                                 1 \n                                 Business Standard \n                                                 1 \n                                          CBC News \n                                                 1 \n                                          CBS News \n                                                 1 \n                                              CNET \n                                                 2 \n                                         Digitimes \n                                                 1 \n                                 Economictimes.com \n                                                 1 \n                                    ETF Daily News \n                                                 2 \n                                            Forbes \n                                                 6 \n                                           Fortune \n                                                 2 \n                                  Freerepublic.com \n                                                 1 \n                           Futurity: Research News \n                                                 1 \n                                     GlobeNewswire \n                                                 4 \n                                          Habr.com \n                                                 2 \nHarvard School of Engineering and Applied Sciences \n                                                 1 \n                                     Investing.com \n                                                 2 \n                                       Lillian.com \n                                                 1 \n                                          Livemint \n                                                 1 \n                                         Lse.ac.uk \n                                                 1 \n                                Medical News Today \n                                                 1 \n                                Messynessychic.com \n                                                 1 \n                                Mindtheproduct.com \n                                                 1 \n                             MIT Technology Review \n                                                 1 \n                                           Mit.edu \n                                                 1 \n                                         Msurya.in \n                                                 1 \n                                              NASA \n                                                 1 \n                     National Institutes of Health \n                                                 4 \n                                          NBC News \n                                                 1 \n                                New Zealand Herald \n                                                 1 \n                                          Newsweek \n                                                 1 \n                                   Next Big Future \n                                                 1 \n                                     Nlppeople.com \n                                                 1 \n                                          Plos.org \n                                                 3 \n                                          PoPville \n                                                 1 \n                               Retractionwatch.com \n                                                 1 \n                                      Ritholtz.com \n                                                 1 \n                                     Science Daily \n                                                 3 \n                               Scientific American \n                                                 2 \n                                     seattlepi.com \n                                                 1 \n                              Sqlservercentral.com \n                                                 1 \n                               Süddeutsche Zeitung \n                                                 2 \n                                      The Atlantic \n                                                 1 \n                                The Times of India \n                                                 1 \n                                         The Verge \n                                                 1 \n                                          TheBlaze \n                                                 1 \n                                   TheStranger.com \n                                                 1 \n                                             Wired \n                                                 1 \n\n# data science\ntable(data_science_data$source.name)\n\n\n                                         [Removed] \n                                                 8 \n                                          ABC News \n                                                 4 \n                                     ABC News (AU) \n                                                 2 \n                                           Acm.org \n                                                 1 \n                                        Amazon.com \n                                                 1 \n                               Americanthinker.com \n                                                 1 \n                             Bloodinthemachine.com \n                                                 1 \n                                  Business Insider \n                                                 1 \n                                 Business Standard \n                                                 1 \n                                      BusinessLine \n                                                 1 \n                            Catholicnewsagency.com \n                                                 1 \n                                        CBS Sports \n                                                 1 \n                                     CleanTechnica \n                                                 1 \n                                            Crikey \n                                                 1 \n                                    ETF Daily News \n                                                 4 \n                                    Financial Post \n                                                 2 \n                                            Forbes \n                                                 3 \n                                          Futurism \n                                                 1 \n                                     GlobeNewswire \n                                                 6 \n                                          Habr.com \n                                                 1 \nHarvard School of Engineering and Applied Sciences \n                                                 1 \n                               Hurriyet Daily News \n                                                 1 \n                                     Investing.com \n                                                 8 \n                                   Lewrockwell.com \n                                                 1 \n                                       Mercola.com \n                                                 1 \n                                Mindtheproduct.com \n                                                 1 \n                                           Mit.edu \n                                                 2 \n                                      Ms. Magazine \n                                                 1 \n                                              NASA \n                                                 1 \n                                         NDTV News \n                                                 1 \n                                         New Atlas \n                                                 1 \n                                          Newsweek \n                                                 2 \n                                     Nlppeople.com \n                                                 2 \n                                        Nvidia.com \n                                                 1 \n                                      OilPrice.com \n                                                 1 \n                                    Pauljorion.com \n                                                 1 \n                                    PR Newswire UK \n                                                 1 \n                              Princeton University \n                                                 1 \n                                      Pycoders.com \n                                                 1 \n                                     Science Daily \n                                                 1 \n                                      ScienceAlert \n                                                 2 \n                                     seattlepi.com \n                                                 2 \n                              Sqlservercentral.com \n                                                 1 \n                                     Statetimes.in \n                                                 1 \n                                           The BMJ \n                                                 5 \n                           The Conversation Africa \n                                                 2 \n                            The National Interest  \n                                                 1 \n                                  The New Republic \n                                                 1 \n                                The Times of India \n                                                 2 \n                                       Tistory.com \n                                                 1 \n                                   Trendhunter.com \n                                                 1 \n                                        Tubefilter \n                                                 2 \n                                 Twistedsifter.com \n                                                 1 \n                                         Upenn.edu \n                                                 1 \n                                               Vox \n                                                 1 \n                                Washington Monthly \n                                                 1 \n                                        Www.gov.uk \n                                                 1 \n                                         Www.vg.no \n                                                 1 \n                               Yahoo Entertainment \n                                                 1 \n\n\n\nConvert publishedAt columns to a date column. Sort by this column. Then create a pub_diff column that is a difference of the 2.\n\n\n# function made for doing this, also creates a better print string column for the 2\nget_dates_publish_diff\n\nfunction(data) {\n  data_with_dates_and_diff &lt;- data |&gt;\n    mutate(publishedAt = ymd_hms(publishedAt, tz=\"UTC\")) |&gt;\n    arrange(desc(publishedAt)) |&gt;\n    mutate(pub_diff = lag(publishedAt, 1) - publishedAt) |&gt;\n    mutate(publishedAt_str = as_datetime(publishedAt, tz=\"EST\"), pub_diff_str = as.character(as_hms(pub_diff)))\n\n  return (data_with_dates_and_diff)\n}\n\n\n\ncsc_data_dates &lt;- get_dates_publish_diff(csc_data)\nds_data_dates &lt;- get_dates_publish_diff(data_science_data)\n\ncsc_data_dates |&gt;\n  select(source.name, publishedAt_str, pub_diff_str) |&gt;\n  head(10)\n\n            source.name     publishedAt_str pub_diff_str\n1         Investing.com 2024-10-16 01:12:05         &lt;NA&gt;\n2        ETF Daily News 2024-10-16 00:44:05     00:28:00\n3             Acast.com 2024-10-16 00:00:49     00:43:16\n4    Mindtheproduct.com 2024-10-16 00:00:00     00:00:49\n5     Economictimes.com 2024-10-15 23:58:31     00:01:29\n6              TheBlaze 2024-10-15 21:14:55     02:43:36\n7          Adafruit.com 2024-10-15 21:05:24     00:09:31\n8     Business Standard 2024-10-15 21:04:32     00:00:52\n9             [Removed] 2024-10-15 19:36:35     01:27:57\n10 Sqlservercentral.com 2024-10-15 19:00:52     00:35:43\n\nds_data_dates |&gt;\n  select(source.name, publishedAt_str, pub_diff_str) |&gt;\n  head(10)\n\n             source.name     publishedAt_str pub_diff_str\n1           ScienceAlert 2024-10-16 01:33:59         &lt;NA&gt;\n2           ScienceAlert 2024-10-16 01:33:59     00:00:00\n3         ETF Daily News 2024-10-16 01:33:00     00:00:59\n4          Statetimes.in 2024-10-16 01:31:32     00:01:28\n5         ETF Daily News 2024-10-16 01:16:54     00:14:38\n6          Investing.com 2024-10-16 01:12:05     00:04:49\n7              New Atlas 2024-10-16 01:07:02     00:05:03\n8  Bloodinthemachine.com 2024-10-16 00:47:02     00:20:00\n9         ETF Daily News 2024-10-16 00:44:05     00:02:57\n10        ETF Daily News 2024-10-16 00:43:27     00:00:38\n\n\n\nInteresting, computer science results are less frequent than data science.\n\n\nSubset the variables for publishedAt and pub_diff and find the mean/med/sd of the columns using map.\n\n\nmap(csc_data_dates |&gt; select(publishedAt, pub_diff), \\(x) list(mean=mean(x, na.rm=TRUE), median=median(x, na.rm=TRUE), sd=sd(x, na.rm=TRUE)))\n\n$publishedAt\n$publishedAt$mean\n[1] \"2024-10-15 15:57:12 UTC\"\n\n$publishedAt$median\n[1] \"2024-10-15 15:11:47 UTC\"\n\n$publishedAt$sd\n[1] 20163\n\n\n$pub_diff\n$pub_diff$mean\nTime difference of 843.2323 secs\n\n$pub_diff$median\nTime difference of 359 secs\n\n$pub_diff$sd\n[1] 1360.857\n\nmap(ds_data_dates |&gt; select(publishedAt, pub_diff), \\(x) list(mean=mean(x, na.rm=TRUE), median=median(x, na.rm=TRUE), sd=sd(x, na.rm=TRUE)))\n\n$publishedAt\n$publishedAt$mean\n[1] \"2024-10-16 00:04:33 UTC\"\n\n$publishedAt$median\n[1] \"2024-10-15 23:18:52 UTC\"\n\n$publishedAt$sd\n[1] 14135.55\n\n\n$pub_diff\n$pub_diff$mean\nTime difference of 438.7778 secs\n\n$pub_diff$median\nTime difference of 209 secs\n\n$pub_diff$sd\n[1] 556.8747\n\n\n\nFrom looking at the results of the summary statistics, we see what generally looked true from the first 10 values at a glance. Data science must be more popular than computer science."
  }
]